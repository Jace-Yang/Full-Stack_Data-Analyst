{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "faf0af10-14b5-4cd7-93e1-a16b921570b4",
   "metadata": {},
   "source": [
    "# Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5646c5-aa75-4aaa-8311-ff8a9cf87141",
   "metadata": {},
   "source": [
    "## 背景\n",
    "\n",
    "### Sophisticated Input \n",
    "\n",
    "Input可以看做 / Ouput可以分成这几类\n",
    "\n",
    "> CNN里面还特别强调了CV输入的图片**大小都是一样**的，那现在假设每次我们Model输入的不一样就叫Sequence，Sequence的长度都不一样\n",
    "\n",
    "- Vector-Vector: 输入是一个向量，然后我们的输出,可能是一个**数值**,这个是**Regression**,可能是一个**类别**,这是**Classification**\n",
    "- Vector-Sequence: 比如Image captioning——input图像，output一句话\n",
    "    <center><img src=\"https://cdn.mathpix.com/snip/images/sYKqUUS2O3e9dwthw1t1qznDv_P_PyLHEB_zdAm-ah0.original.fullsize.png\" width=\"45%\"/></center>\n",
    "\n",
    "    \n",
    "- Sequence-Vector: 比如输入Movie Review，输出评价\n",
    "- Sequence- Sequence：比如机器翻译\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c064558-41b9-4391-abc4-4879ade03f5b",
   "metadata": {},
   "source": [
    "### 把Sequence转换成input的方法\n",
    "\n",
    "- 文字：\n",
    "\n",
    "    - one-hot：开一个很长很长的向量,这个向量的长度跟世界上存在的词汇的数目是一样多的,每一个维度对应到一个词汇,Apple就是100,Bag就是010,Cat就是001,以此类推\n",
    "\n",
    "        - 但是这样子的表示方法有一个非常严重的问题,它假设所有的**词汇彼此之间都是没有关係**的,从这个向量裡面你看不到：Cat跟Dog都是动物所以他们比较接近,Cat跟Apple一个动物一个植物,所以他们比较不相像。这个向量裡面,没有任何语义的资讯\n",
    "\n",
    "    - 另外一个方法叫做**Word Embedding**：给每一个词汇一个向量,而这个**向量是有语义的资讯的**\n",
    "\n",
    "        - 如果你把Word Embedding画出来的话,你会发现,所有的动物可能聚集成一团,所有的植物可能聚集成一团,所有的动词可能聚集成一团等等\n",
    "\n",
    "        - Word Embedding,会给每一个词汇一个向量,而**一个句子就是一排长度不一的向量**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c7f115-9a75-4609-bc1e-47ecac977be6",
   "metadata": {},
   "source": [
    "- 声音信号：声音讯号其实是一排向量，我们会把一段声音讯号取一个范围叫**Window**\n",
    "\n",
    "    \n",
    "\n",
    "    - 把这个Window面的信息描述成一个向量，就叫做一个Frame，语音上会把**一个向量叫做一个Frame**\n",
    "    \n",
    "        - 通常这个Window的长度就是25个Millisecond\n",
    "\n",
    "    - 一小段25个Millisecond里面的语音讯号,為了要描述一整段的声音讯号,你会把这个**Window往右移一点**，从而形成了一段向量\n",
    "    \n",
    "        - 通常移动的大小是10个Millisecond"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217f0ee9-2631-4563-9639-fbe0461e6eaa",
   "metadata": {},
   "source": [
    "- 图：一个Graph/图也是一堆向量，如Social Network\n",
    "\n",
    "    - 在Social Network上面**每一个节点就是一个人**,然后**节点跟节点之间的edge就是他们两个的关系连接**,比如说是不是朋友等等\n",
    "    - 而**每一个节点可以看作是一个向量**,你可以拿每一个人的,比如说他的Profile裡面的资讯啊,他的性别啊 他的年龄啊,他的工作啊 他讲过的话啊等等,把这些资讯用一个向量来表示\n",
    "    - 所以一个Social Network 一个Graph,你也可以看做是一堆的向量所组成的\n",
    "\n",
    "- 分子信息：一个分子也可以看作是一个Graph\n",
    "\n",
    "    - **一个分子可以看作是一个Graph**,分子上面的每一个球,也就是**每一个原子，可以表述成一个向量**\n",
    "\n",
    "    - 一个**原子可以用One-Hot Vector**来表示,氢就是1000,碳就是0100,然后这个氧就是0010,所以一个分子就是一个Graph,它就是一堆向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8226d1-e071-40f8-91cc-962d86b2792a",
   "metadata": {},
   "source": [
    "### 输出Output\n",
    "\n",
    "- 每一个向量都有一个对应的Label：输入是四个向量的时候,它就要输出四个Label,而每一个Label,它可能是一个数值,那就是Regression的问题,如果每个Label是一个Class,那就是一个Classification的问题<br>\n",
    "\n",
    "    - 文字处理：假设你今天要做的是**POS Tagging**,POS Tagging就是词性标註,你要让机器自动决定每一个词汇 它是什麼样的词性,它是名词 还是动词 还是形容词等等\n",
    "\n",
    "        这个任务啊,其实并没有很容易,举例来说,你现在看到一个句子,I saw a saw，这并不是打错,并不是“我看一个看”,而是“我看到一个锯子”,这个第二个saw当名词用的时候,它是锯子，那所以机器要知道,第一个saw是个动词,第二个saw虽然它也是个saw,但它是名词,但是每一个输入的词汇,都要有一个对应的输出的词性，这个任务就是,输入跟输出的长度是一样的Case,这个就是属於第一个类型的输出\n",
    "\n",
    "    - 语音：每个vector来看音标\n",
    "\n",
    "    - Social Network：决定每个节点的特性，比如说他会不会买某一个商品,这样我们才知道说,要不要推荐某一个商品给他,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d87616-416b-42f2-932e-5dd2a0c59f30",
   "metadata": {},
   "source": [
    "- 一整个Sequence，只需要输出一个Label\n",
    "\n",
    "    - 文字：Sentiment Analysis给机器看一段话,它要**决定说这段话是正面的还是负面的**\n",
    "\n",
    "    - 语音：机器要听一段声音,然后决定他是谁讲的\n",
    "\n",
    "    - Graph：给一个分子,然后要预测说这个分子,比如说它有没有毒性,或者是它的亲水性如何\n",
    "\n",
    "- 机器要自己决定,应该要输出多少个Label<br>\n",
    "  我们不知道应该输出多少个Label,机器要自己决定,应该要输出多少个Label,可能你输入是N个向量,输出可能是N'个Label,為什麼是N',机器自己决定，这种任务又叫做**sequence to sequence**的任务！\n",
    "\n",
    "    - 翻译就是sequence to sequence的任务,因為输入输出是不同的语言,它们的词汇的数目本来就不会一样多\n",
    "    - 或者是语音辨识也是,真正的语音辨识也是一个sequence to sequence的任务,输入一句话,然后输出一段文字,这也是一个sequence to sequence的任务"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60134e80-32c9-4ea9-8c32-c04e5c971132",
   "metadata": {},
   "source": [
    "### Sequence Labeling\n",
    "\n",
    "输入跟输出数目一样多的状况又叫做**Sequence Labeling**,你要给Sequence裡面的每一个向量,都给它一个Label。\n",
    "\n",
    "- 直觉的想法1: 拿个**Fully-Connected的Network**，但对、词性标记的问题，你给机器一个句子,I saw a saw,对Fully-Connected Network来说,**后面这一个saw跟前面这个saw完全一模一样**,它们是同一个词汇啊，所以会输出一样的东西！\n",
    "\n",
    "- 直觉的想法2: 所以，要让**让Fully-Connected的Network,考虑context,就**把前后几个向量都串起来,一起丢到Fully-Connected的Network**\n",
    "\n",
    "    - 但是**这样子的方法还是有极限**，比如对于需要**考虑一整个Sequence**才能够解决的任务，由于Sequence有长有短，不能通过继续开大Window来做！或者是开一个比最大Sequence大一点的Window\n",
    "    - 但是你开一个这麼大的Window,意味著说你的Fully-Connected的Network需要非常多的参数,那可能不只**运算量很大,可能还容易Overfitting**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb17446-a445-41c3-88f8-61c17aeb4434",
   "metadata": {},
   "source": [
    "## Self-Attention过程\n",
    "\n",
    "### 整体的运作效果\n",
    "\n",
    "\n",
    "Self-Attention的运作方式就是,**Self-Attention会吃一整个Sequence的资讯**，输入4个Vector,它就Output 4个Vector，这4个Vector,他们都是考虑一整个Sequence以后才得到的**，然后再进Fully-Connected的Network决定要输出什麼样的结果，这个就是Self-Attention。\n",
    "\n",
    "- **Self-Attention不是只能用一次,你可以叠加很多次**\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "- **可以把Fully-Connected的Network,跟Self-Attention交替使用**\n",
    "\n",
    "    - Self-Attention处理整个Sequence的资讯，Fully-Connected的Network,专注於处理某一个位置的资讯\n",
    "    - 再用Self-Attention,再把整个Sequence资讯再处理一次\n",
    "\n",
    "有关Self-Attention，最知名的相关的文章,就是《Attention is all you need》也就是提出了**Transformer**的Network架构！"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f0fec1b-25c5-407d-9dd8-0c963d945ba7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 普通Self-Attention\n",
    "\n",
    "那接下来呢就是要跟大家说明,**怎麼產生$b^1$这个向量**,那你知道怎麼產生$b^1$这个向量以后,你就知道怎麼產生剩下$b^1 b^2 b^3 b^4$剩下的向量\n",
    "\n",
    "\n",
    "- 我们需要根据根据$a^1$这个向量，找出整个很长的sequence裡面哪些部分跟判断$a^1$是哪一个label是有关係的\n",
    "\n",
    "- 每一个向量跟$a^1$的关联的程度,用一个数值叫α来表示。Transformer里面用的是**dot product**,输入的这两个向量分别乘上两个不同的矩阵，再做element-wise 的相乘后全部加起来以后就得到一个scalar，这个scalar就是α\n",
    "    <center><img src=\"../../images/DL_selfattention_1.png\" width=\"30%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100e3be0-5b1d-4080-aa89-81522870daab",
   "metadata": {},
   "source": [
    "<mark style=\"background-color:#c3dbfc;\">计算出$b_1$</mark>\n",
    "\n",
    "- Step1：先算出一个Input sequence中的关联性再取Soft-max，从而知道了整个Sequence里面**哪些跟$\\alpha_{1}$是最相关的**——`attention score`\n",
    "    <center><img src=\"../../images/DL_selfattention_2.png\" width=\"80%\"/></center>\n",
    "    \n",
    "    - 需要α的人出$q$，其他人出$k$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f159e3e1-d8ea-4fe8-a9f5-2e0feb101d13",
   "metadata": {},
   "source": [
    "- Step2：从attention score中进一步抽取资讯：用attention score来weighted sum 四个value\n",
    "    <center><img src=\"../../images/DL_selfattention_3.png\" width=\"80%\"/></center>\n",
    "\n",
    "    - 如果说某个向量它得到的分数越高，比如：\n",
    "    \n",
    "        - $a^1$跟$a^2$的关联性很强⇒$α'_{1, 2}$就会很大得到的值<br>⇒在Weighted Sum中$α'_{1, 2}$dominate⇒得到的$b^1$的值会比较接近$v^2$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86094caa-4da3-4b86-aac5-4e5353e43dac",
   "metadata": {},
   "source": [
    "<mark style=\"background-color:#c3dbfc;\">计算出$b_2$</mark>：也是一样的步骤\n",
    "\n",
    "- Step 1 / 2：先算出一个Input sequence中的关联性再取Soft-max，从而知道了整个Sequence里面**哪些跟$\\alpha_{2}$是最相关的**，然后再用这些attention score来weighted sum四个value\n",
    "    <center><img src=\"../../images/DL_selfattention_4.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6298b30d-6276-4fae-bb64-597a9ae83151",
   "metadata": {},
   "source": [
    "<mark style=\"background-color:#c3dbfc;\">矩阵并行计算出四个$b$</mark>\n",
    "\n",
    "整体过程：I乘W得到QKV、K乘Q得到Attention Matrix、V乘Attention Matrix得到O，也就是\n",
    "\n",
    "$$Z=\\operatorname{softmax}\\left(\\frac{Q \\cdot K^{T}}{\\sqrt{\\text { Dimension of vector } Q, K \\text { or } V}}\\right) \\cdot V$$\n",
    "\n",
    "> 这里的 $\\sqrt{\\text { Dimension of vector } Q, K \\text { or } V}$ 是Transformer增加的一个对dot-product的scaling\n",
    "\n",
    "\n",
    "<center><img src=\"../../images/DL_selfattention_9.png\" width=\"80%\"/></center>\n",
    "\n",
    "- \n",
    "    - 只有W需要学习\n",
    "\n",
    "- <mark style=\"background-color:#e1e1e1;\">Step 1：转换输入</mark>——输入Sequence中的每一个$a$拼成$I$后分别乘$W$ $\\rightarrow$ $Q、K、V$\n",
    "    <center><img src=\"../../images/DL_selfattention_5.png\" width=\"80%\"/></center>\n",
    "    \n",
    "- <mark style=\"background-color:#e1e1e1;\">Step 2：$K$和$Q$得到attention score矩阵$A$</mark>\n",
    "    <center><img src=\"../../images/DL_selfattention_7.png\" width=\"80%\"/></center>\n",
    "    \n",
    "- <mark style=\"background-color:#e1e1e1;\">Step 3：用$\\alpha^{\\prime}$当权平均$v$得到$B$</mark>\n",
    "    <center><img src=\"../../images/DL_selfattention_8.png\" width=\"80%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31db428-7952-4990-9c3c-688ded0b030b",
   "metadata": {},
   "source": [
    "### Multi-head Self-attention\n",
    "\n",
    "Self-attention用q去找相关的k，但是相关会有不同的形式，我们可能需要多个q，**不同的 q 负责不同种类的相关性**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84a4c3a-fa70-4d16-b8fc-ab964b1f99c0",
   "metadata": {},
   "source": [
    "核心区别点：b有多个"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d311e275-883f-4a16-b4ae-30f41113a8a5",
   "metadata": {},
   "source": [
    "<mark style=\"background-color:#c3dbfc;\">计算出$b_i$</mark>\n",
    "\n",
    "- Step 1：计算出每个head对应的b\n",
    "\n",
    "<center><img src=\"../../images/DL_selfattention_10.png\" width=\"45%\"/><img src=\"../../images/DL_selfattention_11.png\" width=\"45%\"/></center>\n",
    "\n",
    "- Step 2：再用一个矩阵得到b\n",
    "\n",
    "<center><img src=\"../../images/DL_selfattention_12.png\" width=\"30%\"/></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e428b-6904-49c4-a22f-e0bedcce8962",
   "metadata": {},
   "source": [
    "## Positional Encoding \n",
    "\n",
    "### No position information in self-attention\n",
    "\n",
    "Self-attention的layer它少了位置的概念，input中的a1 a2 a3其实完全没有差别，做的操作是一摸一样的——所有的位置之间的距离都是一样的：没有任何一个位置距离比较远、没有任何位置距离比较近、没有谁在整个 sequence 的最前面,也没有谁在整个 sequence 的最后面\n",
    "\n",
    "但是这样子设计可能会有一些问题,因為有时候位置的资讯也许很重要,举例来说,我们在做这个 POS tagging,就是词性标记的时候,也许你知道说**动词比较不容易出现在句首**,所以如果我们知道说,某一个词汇它是放在句首的,那它是动词的可能性可能就比较低,这样子的位置的资讯往往也是有用的！\n",
    "\n",
    "### Each positon has a unique positional vector $e^i$\n",
    "\n",
    "可是在我们到目前為止,讲的 Self-attention 的操作裡面,根本就没有位置的资讯,所以怎麼办呢,所以你做 Self-attention 的时候,如果你觉得位置的资讯是一个重要的事情,那你可以把位置的资讯把它塞进去,怎麼把位置的资讯塞进去呢,这边就要用到一个叫做,**positional encoding** 的技术\n",
    "\n",
    "<center><img src=\"../../images/DL_selfattention_13.png\" width=\"30%\"/></center>\n",
    "\n",
    "你為每一个位置设定一个 vector,叫做 positional vector,这边**用 $e^i$ 来表示,上标 i 代表是位置,每一个不同的位置**,就有不同的 vector,就是 $e^1$ 是一个 vector,$e^2$ 是一个vector,$e^{128}$ 是一个vector,不同的位置都有一个它专属的 e,然后把这个 e 加到 $a^i$ 上面,就结束了\n",
    "\n",
    "就是告诉你的 Self-attention,位置的资讯,如果它看到说 $a^i$ 好像有被加上 $ e^i$,它就知道说现在出现的位置,应该是在 i 这个位置"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43437d94-c516-4032-8109-1b61d37dfa24",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 参考文献\n",
    "\n",
    "- [DeepLearning_LHY21_Notes](https://github.com/unclestrong/DeepLearning_LHY21_Notes)\n",
    "\n",
    "- [HUNG-YI LEE (李宏毅)MACHINE LEARNING 2021 SPRING](https://speech.ee.ntu.edu.tw/~hylee/ml/2021-spring.php)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc-autonumbering": false,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
