
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>基础 &#8212; 全栈DS/DA养成手册</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="有监督学习" href="SupervisedML.html" />
    <link rel="prev" title="因果推理方法" href="../Causal_Inference/2_methods.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo2.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">全栈DS/DA养成手册</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  多元分析
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/Business.html">
   商业分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/DA.html">
   数据分析
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/STAT.html">
   统计分析
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  因果推断
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/README.html">
   基础
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/1_AB_testing.html">
   AB Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/2_methods.html">
   因果推理方法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  机器学习
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   基础
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="SupervisedML.html">
   有监督学习
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="UnsupervisedML.html">
   无监督学习
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  深度学习
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../DL/Basics/README.html">
   基础
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DL/NLP/README.html">
   NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/Self-attention.html">
     Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/Transformer.html">
     Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/BERT.html">
     BERT
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DL/NN_compression/README.html">
   神经网络压缩
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../DL/NN_compression/KD.html">
     知识蒸馏
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
    <label for="toctree-checkbox-3">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../DL/NN_compression/Distill_Bert.html">
       Distill Bert
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../DL/NN_compression/Quantize.html">
     量化
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../DL/NN_compression/QBert.html">
       Q-BERT
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  数据仓库
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../DE/README.html">
   基础
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DE/SQL.html">
   SQL
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DE/BigData.html">
   大数据
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DE/Data_cleaning/README.html">
   数据清洗与处理
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
  <label for="toctree-checkbox-5">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../DE/Data_cleaning/Regex.html">
     正则表达式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DE/Data_cleaning/pandas.html">
     Pandas
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  联系方式
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://www.linkedin.com/in/jinhang-yang/">
   LinkedIn
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  By <a href="https://github.com/Jace-Yang">Jace Yang</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ML/README.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst/issues/new?title=Issue%20on%20page%20%2FML/README.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   机器学习分类
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   模型的评测指标
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     <strong>
      回归指标
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     分类指标
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       准确率和错误率
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix">
       Confusion Matrix / 评价指标
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#precision-vs-recall">
         Precision VS Recall
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#metric-choosing">
         Metric Choosing的问题
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       曲线指标
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#receiver-operating-curve-roc-area-under-curve-auc">
         Receiver Operating Curve (ROC) ⇒ Area Under Curve (AUC)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#precision-recall-pr-curve">
         Precision-Recall (PR) Curve
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         对比
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       其他指标
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       多分类问题
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     广告场景
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     推荐场景
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   参考
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>基础</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   机器学习分类
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id3">
   模型的评测指标
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     <strong>
      回归指标
     </strong>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     分类指标
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       准确率和错误率
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#confusion-matrix">
       Confusion Matrix / 评价指标
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#precision-vs-recall">
         Precision VS Recall
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#metric-choosing">
         Metric Choosing的问题
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id7">
       曲线指标
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#receiver-operating-curve-roc-area-under-curve-auc">
         Receiver Operating Curve (ROC) ⇒ Area Under Curve (AUC)
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#precision-recall-pr-curve">
         Precision-Recall (PR) Curve
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id8">
         对比
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id9">
       其他指标
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id10">
       多分类问题
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id11">
     广告场景
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id12">
     推荐场景
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id13">
   参考
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>基础<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<div class="section" id="id2">
<h2>机器学习分类<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<img src="../images/(null)-20220724132314070.(null)" alt="img" style="width: 33%;" />
<ul>
<li><p>根据label的类型来分</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">Supervised</span> <span class="pre">learning</span> </code> algorithms： Learn a function that maps inputs to an output from a set of <strong>labeled</strong> training data.</p>
<ul>
<li><p>Downside: getting labeled data is pretty costly. Hard to have clean labeled data.</p></li>
<li><p>生成模型（常见的生成方法有LDA主题模型、朴素贝叶斯 算法和隐式马尔科夫模型等）：对判别式模型来说求得 <span class="math notranslate nohighlight">\(P(Y \mid X)\)</span>, 对末见示例 <span class="math notranslate nohighlight">\(X\)</span>, 根据 <span class="math notranslate nohighlight">\(P(Y \mid X)\)</span> 可以求得标记Y，即可以直接判别出来, 如上图的左边所示, 实际是就是直接得到了判别边界</p></li>
<li><p>判别模型（ 常见的判别方法有SVM、LR等）：而生成式模型求得P(Y,X)，对于未见示例X，你要求出X与不同标记之间的联合概率分布，然后大的获胜，如上图右边所示，并没有什么边界存在</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Unsupervised</span> <span class="pre">Learning</span></code>: learn patterns from <strong>unlabeled</strong> data samples.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Reinforcement</span> <span class="pre">Learning</span></code>: The computer employs trial and error to come up with a solution to the problem. To get the machine to do what the programmer wants, the artificial intelligence <strong>gets either rewards or penalties</strong> for the <strong>actions</strong> it performs. Its goal is to <strong>maximize the total reward</strong>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Deep</span> <span class="pre">Learning</span></code>: a class of ML algorithms that uses multiple layers to progressively extract <strong>higher-level features/abstractions</strong> from raw inputs.</p>
<ul>
<li><p>本质上也是create 很多features that you think is important</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>其他特定的学习方式</strong></p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Active</span> <span class="pre">Learning</span></code>：不是exposed to all training data, but we can ask for the label</p>
<ul class="simple">
<li><p>可以减少对label的依赖！</p></li>
<li><p>Create a human annotator, and makes tha ML ask for human to label</p></li>
</ul>
<blockquote>
<div><p><a class="reference external" href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)">https://en.wikipedia.org/wiki/Active_learning_(machine_learning)</a></p>
<p>A learning algorithm can interactively query a user (or some other information source) to <strong>label new data points with the desired outputs</strong></p>
</div></blockquote>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Self-supervised</span> <span class="pre">Learning</span></code>: Trying to predict a label based on unlabeled data</p>
<ul>
<li><p>Self-supervised learning techniques are generally used as pre-train tasks to <em>generate labels for other downstream tasks</em>.</p>
<ul class="simple">
<li><p>e.g 补全单词预测——因为补全句子这种你用来补全的context words也不算labeled</p></li>
<li><p>word2vec，autoencoder这类明明没标签却能够造出目标函数，使用凸优化方法求解，无中生有</p></li>
</ul>
</li>
<li><p>The learning model <strong>trains itself by leveraging one part of the data</strong> to <strong>predict the other part</strong> and generate labels accurately. In the end, this learning method <em><strong>converts an unsupervised learning problem into a supervised one</strong></em></p></li>
<li><p><strong>区分定义</strong></p>
<ul>
<li><p>Self-supervised learning vs semi-supervised learning：<u>自监督是完全没标签，半监督其实就是有部分标签的时候带了一些数据生产规则的有监督</u></p>
<ul>
<li><p>Semi-supervised learning uses <strong>manually</strong> labeled training data for supervised learning and unsupervised learning approaches for unlabeled data to generate a model that leverages existing labels but builds a model that can <strong>make predictions beyond the labeled data.</strong></p>
<ul>
<li><blockquote>
<div><p><strong>一个semi-supervised的</strong><a class="reference external" href="https://zhuanlan.zhihu.com/p/33196506">例子</a>：简单自训练**（simple self-training）：用有标签数据训练一个分类器，然后用这个分类器对无标签数据进行分类，这样就会产生伪标签（pseudo label）或软标签（soft label），挑选你认为分类正确的无标签样本（此处应该有一个<strong>挑选准则</strong>），把选出来的无标签样本用来训练分类器。</p>
</div></blockquote>
</li>
</ul>
</li>
<li><p>Self-supervised learning <strong>relies completely on data</strong> that lacks manually generated labels.</p></li>
</ul>
</li>
<li><p>Self-supervised learning vs unsupervised learning：<u>自监督的目标是监督学习，无监督不是</u></p>
<ul class="simple">
<li><p>Self-supervised learning is similar to unsupervised learning because both techniques work with datasets that don’t have manually added labels. In some sources, self-supervised learning is addressed as a subset of unsupervised learning. However, unsupervised learning <strong>concentrates on clustering, grouping, and dimensionality reduction</strong>,</p></li>
<li><p>while self-supervised learning aims to draw conclusions for regression and classification tasks.</p></li>
</ul>
</li>
<li><p>Hybrid Approaches vs. Self-supervised Learning：<u>自监督学习和人类混合的差别是自监督是全自动的</u></p>
<ul class="simple">
<li><p>There are also hybrid approaches that combine automated data labeling tools with supervised learning. In such methods, computers can label data points that are easier-to-label relying on their training data and <strong>leave the complex ones to humans.</strong> Or, they can label all data points automatically but need human approval.</p></li>
<li><p>In self-supervised learning, <strong>automated data labeling is embedded</strong> in the training model. The <em>dataset is labeled as part of the learning processes</em>; thus, it doesn’t ask for human approval or only label the simple data points.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Transfer</span> <span class="pre">Learning</span></code>：pre-trained models are used as the starting point on computer vision and natural language processing tasks</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id3">
<h2>模型的评测指标<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h2>
<p>metric主要用来评测机器学习模型的好坏程度，不同的任务应该选择不同的评价指标。分类，回归和排序问题应该选择不同的评价函数。</p>
<p>Evaluation Metrics</p>
<ul class="simple">
<li><p>Evaluation metrics are generally used to measure the performance of an ML model.</p></li>
<li><p>Evaluation metrics indicate how well the models would do when deployed</p></li>
<li><p>The choice of metrics is very task-speciﬁc and determines what the model learns</p>
<ul>
<li><p>can direct your model to learn specific things based on the evaluation metric</p></li>
</ul>
</li>
<li><p>It is important to know what you are willing to <strong>trade oﬀ</strong> when training ML models for a task</p></li>
</ul>
<div class="section" id="id4">
<h3><strong>回归指标</strong><a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<ul>
<li><p>平均绝对误差(MAE)，又称L1范数损失：</p>
<div class="math notranslate nohighlight">
\[MAE=\frac{1}{n}\sum_{i=1}^{n}|y_i-\hat{y}_i|\]</div>
<ul class="simple">
<li><p>MAE虽能较好衡量回归模型的好坏，但是绝对值的存在导致<strong>函数不光滑</strong>，在某些点上不能求导，</p></li>
<li><p>可以考虑将绝对值改为残差的平方，这就是均方误差。</p></li>
</ul>
</li>
<li><p>均方误差(MSE)，又被称为 L2范数损失 。</p>
<div class="math notranslate nohighlight">
\[M S E=\frac{1}{n} \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\]</div>
<ul class="simple">
<li><p>由于MSE与我们的目标变量的量纲不一致，为了保证量纲一致性，我们需要对MSE进行开方 得到RMSE</p></li>
<li><p>Outlier多时会被push得非常高, MSE会让model去predict outlier right 所以要么tune outlier再用MSE，要么就用MAE</p></li>
</ul>
</li>
<li><p>均方根误差(RMSE)</p>
<div class="math notranslate nohighlight">
\[RMSE=\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2} \]</div>
</li>
<li><p><span class="math notranslate nohighlight">\(R^{2}\)</span>又称决定系数，表示反应因变量的全部变异能通过数学模型被自变量解释的比例</p>
<div class="math notranslate nohighlight">
\[R^{2} =1-\frac{\sum^n_{i}\left(y_{i}-\hat{y}\right)^{2} / n}{\sum^n_{i}\left(y_{i}-\bar{y}\right)^{2} / n}=1-\frac{M S E}{\operatorname{Var}}  \]</div>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(y\)</span>表示实际销量, <span class="math notranslate nohighlight">\(\hat{y}\)</span>表示预测销量, <span class="math notranslate nohighlight">\(\bar{y}\)</span>表示实际销量的均值, <span class="math notranslate nohighlight">\(n\)</span>表示样本数, <span class="math notranslate nohighlight">\(i\)</span>表示第<span class="math notranslate nohighlight">\(i\)</span>个样本, <span class="math notranslate nohighlight">\(Var\)</span>表示实际值的方差，也就是销量的变异情况。</p></li>
<li><p><span class="math notranslate nohighlight">\(R2_{score}\)</span>越大，模型准确率越好。</p></li>
<li><p><span class="math notranslate nohighlight">\(MSE\)</span>表示均方误差，为残差平方和的均值,该部分不能能被数学模型解释的部分,属于不可解释性变异。</p>
<ul>
<li><p>因此： $<span class="math notranslate nohighlight">\(可解释性变异占比 = 1-\frac{不可解释性变异}{整体变异}= 1-\frac{M S E}{\operatorname{Var}} = R2_score \tag{5} \)</span>$</p></li>
</ul>
</li>
</ul>
</li>
<li><p>Mean Absolute Percentage Error (MAPE): <span class="math notranslate nohighlight">\(\frac{100}{n} \sum_{i=1}^{n} \mid \frac{y_{i}-\hat{y}_{i}}{y_{i}}\)</span>，特点是跟value本身大小也有关系</p>
<ul class="simple">
<li><p>Intuition：y范围很大时候 大y当然会带来大的error, 所以不make sense</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id5">
<h3>分类指标<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h3>
<p><strong>分类</strong></p>
<ul class="simple">
<li><p>Threshold-based metrics</p>
<ul>
<li><p>Classiﬁcation Accuracy</p></li>
<li><p>Precision, Recall &amp; F1-score</p></li>
</ul>
</li>
<li><p>Ranking-based metrics</p>
<ul>
<li><p>Average Precision (AP)</p></li>
<li><p>Area Under Curve (AUC)</p></li>
</ul>
</li>
</ul>
<div class="section" id="id6">
<h4>准确率和错误率<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h4>
<div class="math notranslate nohighlight">
\[Acc(y,\hat{y})=\frac{1}{n}\sum_{i=1}^{n}y_i=\hat{y_i} \]</div>
<div class="math notranslate nohighlight">
\[ Error(y, \hat{y})=1-acc(y,\hat{y}) \tag{7} \]</div>
<ul class="simple">
<li><p>Acc与Error平等对待每个类别，即<strong>每一个样本判对 (0) 和判错 (1) 的代价都是一样的</strong>。</p></li>
<li><p>使用Acc与Error作为衡量指标时，需要考虑样本不均衡问题以及实际业务中好样本与坏样本的重要程度。</p></li>
</ul>
</div>
<div class="section" id="confusion-matrix">
<h4>Confusion Matrix / 评价指标<a class="headerlink" href="#confusion-matrix" title="Permalink to this headline">¶</a></h4>
<p>对于二分类问题,可将样例根据其真是类别与学习器预测类别的组合划分为</p>
<ul class="simple">
<li><p>真正例(true positive, TP):预测为 1，预测正确，即实际 1</p></li>
<li><p>假正例(false positive, FP):预测为 1，预测错误，即实际 0</p></li>
<li><p>真反例(ture negative, TN):预测为 0，预测正确，即实际 0</p></li>
<li><p>假反例(false negative, FN):预测为 0，预测错误，即实际 1</p></li>
</ul>
<img src="../images/(null)-20220726100557307.(null)" alt="img" style="width:50%;" />
<blockquote>
<div><p><strong>通常把minority当作Positive</strong> <strong>:</strong> Minority class is considered positive as best practice——因为希望learn minority class well（如果要learn majority class就直接预测大多数就好了）</p>
</div></blockquote>
<ul class="simple">
<li><p>刚刚的$<span class="math notranslate nohighlight">\(Accuracy=\frac{\sum_{i=1}^{n} I_{\hat{y_{i}}=y_{i}}}{n} = \frac{\colorbox{#eaf1f5}{TN+TP}}{TN+TP+FP+FN}\)</span>$</p>
<ul>
<li><p>could be misleading in case of imbalance datasets</p></li>
<li><p>accuracy paradox: higher the accuracy does not necessarily mean a better model.</p>
<ul>
<li><p>比如风控直接说大家都是正常的 accuracy一样很高</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>Normalize by y_true</strong></p></th>
<th class="head"><p><strong>Normalize by y_pred</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><img src="../images/(null)-20220726101304187.(null)" alt="img" style="width:33%;" /></p></td>
<td><p><img src="../images/(null)-20220726101304176.(null)" alt="img" style="width:33%;" /></p></td>
</tr>
<tr class="row-odd"><td><p>True Positive Rate / <strong>Recall</strong> / Sensitivity = $<span class="math notranslate nohighlight">\(\frac{\colorbox{#c9e8ee}{TP}}{\colorbox{#c9e8ee}{TP}+FN}=\frac{TP}{所有Positive样本}\)</span><span class="math notranslate nohighlight">\(：the fraction of relevant instances that were retrieved &lt;br&gt; False Positive Rate = \)</span><span class="math notranslate nohighlight">\(\frac{\colorbox{#d9ed8a}{FP}}{\colorbox{#d9ed8a}{FP}+TN}=\frac{FP}{所有Negative样本}\)</span>$</p></td>
<td><p>Precision= $<span class="math notranslate nohighlight">\(\frac{\colorbox{#c39dc6}{TP}}{\colorbox{#c39dc6}{TP}+FP}=\frac{TP}{所有Positive预测}\)</span>$：the fraction of relevant instances <em>among retrieved</em> instances</p></td>
</tr>
<tr class="row-even"><td><p>能把癌症的人中的多少检测出来</p></td>
<td><p>判定成spam中有多少是实锤，下结论的时候有多precise</p></td>
</tr>
<tr class="row-odd"><td><p>$<span class="math notranslate nohighlight">\(\text{F1-Score} =2 \times \frac{\text { Precision*Recall }}{\text { Precision+Recall }}\)</span>$：harmonic mean of precision &amp; recall 当两边都在意的时候用F1！</p></td>
<td><p></p></td>
</tr>
</tbody>
</table>
<div class="section" id="precision-vs-recall">
<h5>Precision VS Recall<a class="headerlink" href="#precision-vs-recall" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p>准确率（查准率） <code class="docutils literal notranslate"><span class="pre">Precision</span></code>：分类器<strong>预测的正样本中预测正确的比例</strong>，取值范围为[0,1]，取值越大，模型预测能力越好。 $<span class="math notranslate nohighlight">\( P=\frac{TP}{TP+FP} \tag{8} \)</span>$</p></li>
<li><p>召回率（查全率）<code class="docutils literal notranslate"><span class="pre">Recall</span></code>：Recall 是分类器所预测正确的正样本占所有正样本的比例，取值范围为[0,1]，取值越大，模型预测能力越好。 $<span class="math notranslate nohighlight">\( R=\frac{TP}{TP+FN} \tag{9} \)</span>$</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">F1</span> <span class="pre">Score</span></code>：Precision和Recall 是互相影响的，理想情况下肯定是做到两者都高，但是一般情况下Precision高、Recall 就低， Recall 高、Precision就低。为了均衡两个指标，我们可以采用Precision和Recall的加权调和平均（weighted harmonic mean）来衡量，即</p>
<div class="math notranslate nohighlight">
\[ \frac{1}{F_1}=\frac{1}{2} \cdot (\frac{1}{P}+\frac{1}{R}) \tag{10} $$, $$ F_1=\frac{2*P*R}{P+R} \tag{11} \]</div>
</li>
<li><p>Averaging Metrics</p>
<ul>
<li><div class="math notranslate nohighlight">
\[\text{Macro Recall} = \frac{1}{|L|} \sum_{l \in L} R\left(y_{l}, \hat{y}_{l}\right)\]</div>
<p>Average over recall <strong>per class equally</strong> ⇔ <span class="math notranslate nohighlight">\(\text{Balanced Accuracy}= \frac{1}{2} \left(\frac{T P}{T P+F N}+\frac{T N}{T N+F P}\right)\)</span></p>
</li>
<li><div class="math notranslate nohighlight">
\[\text{Weighted Recall}= \frac{1}{n} \sum_{l \in L} n_{l} R\left(y_{l}, \hat{y}_{l}\right)\]</div>
<p>Weighted average (by class size) over recall per class ⇔ Accuracy</p>
<ul class="simple">
<li><p>Imbalanced 的数据不用！不然会give a higher weight to the majority class.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>计算举例：</strong></p>
<img src="../images/(null)-20220726101620779.(null)" alt="img" style="width:50%;" />
<ul>
<li><p>全局：$<span class="math notranslate nohighlight">\(Accuracy = \frac{23+2184}{23+2184+3+27} = 0.9865\)</span>$</p></li>
<li><p>Minority Class：</p>
<ul>
<li><div class="math notranslate nohighlight">
\[Recall = \frac{23}{23+27} = 0.46\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[Precision = \frac{23}{23+3} = 0.8846\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[F1\text{-}score = 2 \times \frac{0.8846 * 0.46}{0.8846 + 0.46} = 0.60526\]</div>
</li>
</ul>
</li>
<li><p>Averaging Metrics:</p>
<ul>
<li><div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} \text{Macro Recall} &amp;= \frac{1}{2} (\frac{23}{23+27} + \frac{2184}{2184+3})= 0.7293 \\ &amp;= \text{Balanced Accuracy} \end{aligned}\end{split}\]</div>
</li>
<li><div class="math notranslate nohighlight">
\[\begin{split}\begin{aligned} \text{Weighted Recall} &amp;= \frac{1}{2184+3+27+23} ((23+27) \times \frac{23}{23+27} + (2184+3) \times \frac{2184}{2184+3}))  \\  &amp;= \frac{23+2184 }{2184+3+27+23} = 0.9865\\ &amp;= \text{Accuracy}  \end{aligned}\end{split}\]</div>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="metric-choosing">
<h5>Metric Choosing的问题<a class="headerlink" href="#metric-choosing" title="Permalink to this headline">¶</a></h5>
<p>原则：</p>
<ul class="simple">
<li><p>Problem-speciﬁc</p></li>
<li><p>Balanced accuracy better than accuracy (most of the times)</p></li>
<li><p>Cost associated with misclassiﬁcation</p></li>
</ul>
<p>两种场景：</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="head"><p><strong>场景</strong></p></th>
<th class="head"><p><strong>第一类错误（Reject True H0｜拒真｜</strong><code class="docutils literal notranslate"><span class="pre">FP</span></code><strong>）成本高</strong></p></th>
<th class="head"><p><strong>第二类错误（Accept False H0｜取伪｜</strong><code class="docutils literal notranslate"><span class="pre">FN</span></code><strong>）成本高</strong></p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>Metric</strong></p></td>
<td><p>Choose <code class="docutils literal notranslate"><span class="pre">precision</span></code> $<span class="math notranslate nohighlight">\(=\frac{TP}{TP+\colorbox{#a8b6e0}{FP}}\)</span>$</p></td>
<td><p>Choose <code class="docutils literal notranslate"><span class="pre">recall</span></code>$<span class="math notranslate nohighlight">\(=\frac{TP}{TP+\colorbox{#a8b6e0}{FN}}\)</span>$</p></td>
</tr>
<tr class="row-odd"><td><p><strong>例子</strong></p></td>
<td><p>Predicting an email as spam when it is not (false positive) has higher cost than predicting email as not spam <strong>“邮件False Positive第一类错误成本高，要非常小心precisely地给Positive预测，所以预测positive里面的TP要高⇒precision要高”</strong></p></td>
<td><p>Predicting that an individual has no cancer when he/she has cancer (false negative) is far more costlier than the other way round <strong>“癌症False Negative第二类错误成本高，要尽量recall回所有的Positive=1 sample⇒recall要高”</strong></p></td>
</tr>
<tr class="row-even"><td><p><strong>做法</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">提高threshold</span></code>：让每个y_pred_positive都是很sure的结果，牺牲recall但更加precise <img alt="img" src="../_images/(null)-20220726102205607.(null)" /></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">降低threshold</span></code>：多召回多预测出positive（predict negative的时候我非常sure），可以牺牲precision但提高recall y_true_positive的占比 <img alt="img" src="../_images/(null)-20220726102205600.(null)" /></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="id7">
<h4>曲线指标<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h4>
<div class="section" id="receiver-operating-curve-roc-area-under-curve-auc">
<h5>Receiver Operating Curve (ROC) ⇒ Area Under Curve (AUC)<a class="headerlink" href="#receiver-operating-curve-roc-area-under-curve-auc" title="Permalink to this headline">¶</a></h5>
<ul>
<li><p><strong>定义</strong>：ROC全称是”受试者工作特征”(Receiver Operating Characteristic)曲线，ROC曲线为 <strong>FPR 与 TPR</strong> 之间的关系曲线，这个组合以 FPR 对 TPR，即是以代价 (costs) 对收益 (benefits)，显然收益越高，代价越低，模型的性能就越好。</p>
<ul>
<li><p>y 轴为真阳性率（TPR）（正样本Recall）：在所有的正样本中，分类器预测正确的比例</p>
<div class="math notranslate nohighlight">
\[ TPR=\frac{TP}{TP+FN} \tag{12} \]</div>
</li>
<li><p>x 轴为假阳性率（FPR）（负样本的1-recall）：在所有的负样本中，分类器预测错误的比例</p>
<div class="math notranslate nohighlight">
\[ FPR=\frac{FP}{TN+FP} \tag{13} \]</div>
</li>
</ul>
</li>
<li><p><strong>绘制过程</strong>：对有限个(真正例率,假正例率)坐标对：</p>
<ul class="simple">
<li><p>给定<span class="math notranslate nohighlight">\(m^+\)</span>个正例和<span class="math notranslate nohighlight">\(m^-\)</span>个反例,根据学习器预测结果对样例进行排序,然后将分类阈值设为最大,此时真正例率和假正例率都为0,坐标在(0,0)处,标记一个点.</p></li>
<li><p>将分类阈值依次设为每个样本的预测值,即依次将每个样本划分为正例.</p></li>
<li><p>假设前一个坐标点是(x,y),若当前为真正例,则对应坐标为<span class="math notranslate nohighlight">\((x,y+\frac{1}{m^+})\)</span>, 若是假正例,则对应坐标为<span class="math notranslate nohighlight">\((x+\frac{1}{m^-}, y)\)</span></p></li>
<li><p>线段连接相邻的点.</p></li>
</ul>
</li>
<li><p><strong>AUC</strong>：对于二分类问题，预测模型会对每一个样本预测一个得分s或者一个概率p。 然后，可以选取一个阈值t，让得分s&gt;t的样本预测为正，而得分s&lt;t的样本预测为负。 这样一来，根据预测的结果和实际的标签可以把样本分为4类,则有混淆矩阵：</p>
<ul class="simple">
<li><p>随着阈值t选取的不同，这四类样本的比例各不相同。定义真正例率TPR和假正例率FPR为： $<span class="math notranslate nohighlight">\( \begin{array}{l} \mathrm{TPR}=\frac{\mathrm{TP}}{\mathrm{TP}+\mathrm{FN}} \ \mathrm{FPR}=\frac{\mathrm{FP}}{\mathrm{FP}+\mathrm{TN}} \end{array} \tag{14} \)</span>$ 随着阈值t的变化，TPR和FPR在坐标图上形成一条曲线，这条曲线就是ROC曲线。 显然，如果模型是随机的，模型得分对正负样本没有区分性，那么得分大于t的样本中，正负样本比例和总体的正负样本比例应该基本一致。</p></li>
<li><p>实际的模型的ROC曲线则是一条上凸的曲线，介于随机和理想的ROC曲线之间。而ROC曲线下的面积，即为AUC！</p></li>
<li><p>这里的x和y分别对应TPR和FPR，也是ROC曲线的横纵坐标。 $<span class="math notranslate nohighlight">\( \mathrm{AUC}=\int_{t=\infty}^{-\infty} y(t) d x(t) \tag{15} \)</span>$</p></li>
</ul>
</li>
<li><p><strong>端点解读</strong>：</p>
<img src="../images/(null)-20220726103010432.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">(1,</span> <span class="pre">1)</span></code>当recall (y轴的True Positive Rate)为1的时候，相当于召回全部正样本，类似threshold=0.01，那么这个时候所有的负样本都给你搞成Positive了没有TN，False Positive Rate = $<span class="math notranslate nohighlight">\(\frac{\colorbox{#d9ed8a}{FP}}{\colorbox{#d9ed8a}{FP}+TN}=\frac{FP}{所有Negative样本}=\frac{所有Negative样本}{所有Negative样本}=1\)</span>$</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">（0，</span> <span class="pre">0）</span></code>当recall (y轴的True Positive Rate)为0的时候，相当于什么正样本都不召回，类似threshold=0.99，那么这个时候根本没有错的Positive，False Positive Rate = $<span class="math notranslate nohighlight">\(\frac{\colorbox{#d9ed8a}{FP}}{\colorbox{#d9ed8a}{FP}+TN}=\frac{FP}{所有Negative样本}=\frac{0}{所有Negative样本}=0\)</span>$</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="precision-recall-pr-curve">
<h5>Precision-Recall (PR) Curve<a class="headerlink" href="#precision-recall-pr-curve" title="Permalink to this headline">¶</a></h5>
<ul class="simple">
<li><p>A precision-recall curve shows the relationship between <code class="docutils literal notranslate"><span class="pre">precision</span></code> and <code class="docutils literal notranslate"><span class="pre">recall</span></code> at every cut-oﬀ point.</p></li>
<li><p>Visualize eﬀect of selected threshold on performance.</p></li>
</ul>
<img src="../images/(null)-20220726102916189.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">（0，</span> <span class="pre">1）</span></code>当recall为0的时候，相当于没有一个正样本被召回， ⇒全部预测不是Fraud(Negative)了，也就没有错误的Positive，因此 $<span class="math notranslate nohighlight">\(precision=\frac{TP}{TP+0}=1\)</span>$</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">（1，</span> <span class="pre">0.93）</span></code>当recall为1的时候，相当于我为了把所有正样本召回，threshold为0⇒我全部当Fraud打(预测Positive)，那么这时候毫无precise可言，因此 $<span class="math notranslate nohighlight">\(precision=\frac{TP}{n}=precision_{min}\)</span>$</p></li>
</ul>
</div>
<div class="section" id="id8">
<h5>对比<a class="headerlink" href="#id8" title="Permalink to this headline">¶</a></h5>
<p>首先，两个都是both are ranking metrics：如果一个模型预测的probability是之前的一半，AUC和AP都不会改变！log-loss之类的才会改变</p>
<img src="../images/(null)-20220726015315694.(null)" alt="img" style="width:50%;" />
<ul>
<li><p><strong>Precision-Recall PR Curve ⇒ Average Precision(AP)</strong></p>
<ul>
<li><p>好处是imbalance datasets表现更好make more sense： In case of imbalance datasets, AP is a better estimate indicative of model</p>
<ul>
<li><p>AUC will still be very high even the model is bad! 没给你true picture：主要是AUC曲线横坐标是False Positive Rate也就是FP/所有负样本，分母是很大的，但TN没有价值（比如正确预测一个贷款的人不会违约）</p>
<img src="../images/(null)-20220726015315595.(null)" alt="img" style="width: 67%;" />
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Receiver Operating Curve(ROC) ⇒ Area Unver ROC (AUROC / AUC)</strong></p>
<ul class="simple">
<li><p>AUROC measures whether the model is able to <em>rank positive examples higher than negative samples</em></p></li>
<li><p>根据probability来rank prediction：</p>
<ul>
<li><p>如果全（就是正确地把positive都放上面）的情况下：从threshold=1 recall=0 慢慢下降threshold的过程中不会有False Positive出现，所以在FPR=0垂直往上走，然后等threshold卡完所有positive继续往下走才因为threshold过低出现False Positive，但这个时候所有的P positive都被检测了，所以在recall = 1的位置水平往右走</p></li>
</ul>
</li>
<li><p>好处是有Benchmark: random prediction ⇒ 0.5</p>
<ul>
<li><p>easier to know how well the model is performing than random using AUROC than AP</p></li>
<li><p>因为这样移动threshold的时候会按sample的比例一边丢一个</p></li>
<li><p>If you get a score of 0 that means the classifier is perfectly incorrect, it is predicting the incorrect choice 100% of the time.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id9">
<h4>其他指标<a class="headerlink" href="#id9" title="Permalink to this headline">¶</a></h4>
<p><strong>KS值(Kolmogorov-Smirnov)</strong></p>
<img src="../images/1353331-20190628225817455-978692269.png" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>模型中用于<strong>区分预测正负样本分隔程度</strong>的评价指标，一般应用于金融风控领域。</p></li>
<li><p>与ROC曲线相似：</p>
<ul>
<li><p>ROC是以FPR作为横坐标，TPR作为纵坐标，通过改变不同阈值，从而得到ROC曲线。</p></li>
<li><p>ks曲线为TPR-FPR，ks曲线的最大值通常为ks值。可以理解TPR是收益，FPR是代价，ks值是收益最大。图中绿色线是TPR、蓝色线是FPR。</p></li>
</ul>
</li>
</ul>
<p>KS的计算步骤如下：</p>
<ol class="simple">
<li><p>按照模型的结果对每个样本进行打分</p></li>
<li><p>所有样本按照评分排序，从小到大分为10组（或20组）</p></li>
<li><p>计算每个评分区间的好坏样本数。</p></li>
<li><p>计算每个评分区间的累计好样本数占总好账户数比率(good%)和累计坏样本数占总坏样本数比率(bad%)。</p></li>
<li><p>计算每个评分区间累计坏样本占比与累计好样本占比差的绝对值（累计bad%-累计good%），然后对这些绝对值取最大值即得此评分模型的K-S值。</p></li>
</ol>
<p>注意：K-S值仅仅代表模型的分割样本的能力，不能表示分割的是否准确，即便好坏客户完全分错，K-S值依然可以很高</p>
</div>
<div class="section" id="id10">
<h4>多分类问题<a class="headerlink" href="#id10" title="Permalink to this headline">¶</a></h4>
<p>多分类时都一样，除了AUC</p>
<img src="../images/(null)-20220726015221534.(null)" alt="img" style="width:50%;" />
</div>
</div>
<div class="section" id="id11">
<h3>广告场景<a class="headerlink" href="#id11" title="Permalink to this headline">¶</a></h3>
<p><strong>CTR（Click-Through-Rate）</strong></p>
<ul class="simple">
<li><p>点击通过率,是互联网广告常用的术语,指网络广告（图片广告/文字广告/关键词广告/排名广告/视频广告等）的点击到达率,即该广告的实际点击次数（严格的来说,可以是到达目标页面的数量）除以广告的展现量(Show content). $<span class="math notranslate nohighlight">\( ctr=\frac{点击次数}{展示量}　\tag{16} \)</span>$</p></li>
</ul>
<p>**CVR (Conversion Rate)，CVR即转化率。**是一个衡量CPA广告效果的指标</p>
<ul class="simple">
<li><p>用户点击广告到成为一个有效激活或者注册甚至付费用户的转化率. $<span class="math notranslate nohighlight">\( cvr=\frac{点击量}{转化量}　\tag{17} \)</span>$</p></li>
</ul>
</div>
<div class="section" id="id12">
<h3>推荐场景<a class="headerlink" href="#id12" title="Permalink to this headline">¶</a></h3>
<p><strong>评估维度</strong></p>
<ul class="simple">
<li><p>覆盖率 = 指算法向用户推荐的文章占能符合露出条件文章的比例</p></li>
<li><p>多样性和新颖性：常见的问题是用户如果大量长时间的点击同一个主题或者是分类，其后推荐的资讯会呈现漏斗状，限制了用户的阅读。这时候就需要推荐系统进行猎奇的多样、新颖推荐以弥补这些缺陷</p></li>
<li><p><strong>挖掘长尾的能力</strong>：推荐系统的一个重要价值就是发现长尾(长尾理论是 ChrisAnderson 提出的,不熟悉该理论的读者可以自行百度或者看 ChrisAnderson 出的《长尾理论》一书)，将小众的“标的物”分发给喜欢该类“标的物”的用户。度量出推荐系统挖掘长尾的能力，对促进长尾“标的物”的“变现”及更好地满足用户的小众需求从而提升用户的惊喜度非常有价值。</p></li>
<li><p><strong>实时性</strong>：用户的兴趣是随着时间变化的，推荐系统怎么能够更好的反应用户兴趣变化，做到近实时推荐用户需要的“标的物”是特别重要的问题。</p>
<ul>
<li><p>特别像新闻资讯、短视频等满足用户碎片化时间需求的产品，做到近实时推荐更加重要。</p></li>
</ul>
</li>
<li><p><strong>响应及时稳定性</strong>：用户通过触达推荐模块，触发推荐系统为用户提供推荐服务，推荐服务的响应时长，推荐服务是否稳定(服务正常可访问，不挂掉)也是非常关键的。</p></li>
</ul>
<p><strong>指标</strong></p>
<ul>
<li><p>ILS衡量推荐列表的多样性</p>
<p><span class="math notranslate nohighlight">\(I L S(L)=\frac{\sum_{b_{i} \in L} \sum_{b_{j} \in L, b_{j}=b_{i}} S\left(b_{i}, b_{j}\right)}{\sum_{b_{i} \in L} \sum_{b_{j} \in L, b_{j}=b_{i}} 1}\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(S\left(b_{i}, b_{j}\right)\)</span> 计算的是 <span class="math notranslate nohighlight">\(i\)</span> 和 <span class="math notranslate nohighlight">\(j\)</span> 两个物品的相似性</p></li>
<li><p>如果推荐列表中的物品越不相似⇒ILS越小⇒推荐结果的多样性越好</p></li>
</ul>
</li>
<li><p>Hit Rate
$<span class="math notranslate nohighlight">\(
\mathrm{HR}=\frac{\text { number of hits }}{\text { number of users }}
\)</span>$</p>
<ul class="simple">
<li><p>#users是用户总 数, 而#hits是测试集中的item出现在Top- N推荐列表中的用户数量。</p></li>
</ul>
</li>
<li><p>Average Precision：在位置K的Average Precision用来衡量一个相关商品在所有ranks的精度。
$<span class="math notranslate nohighlight">\(
A P(R)_{k}=\frac{1}{\min (|R|, k)} \sum_{i=1}^{k} \delta(i \in R) \operatorname{Prec}(R)_{i}
\)</span>$</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">AP</span><span class="p">(</span><span class="n">ranked_list</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the average precision (AP) of a list of ranked items</span>
<span class="sd">    ground_truth 表示是否正确的标识</span>
<span class="sd">    hits 表示 score （预测结果分值）倒排，从第0个到当前个的累计预测正确样本数</span>
<span class="sd">    sum_precs 表示每个 ground_truth = 1 的位置的 precision 的累加</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">hits</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">sum_precs</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">ranked_list</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">ranked_list</span><span class="p">[</span><span class="n">n</span><span class="p">]</span> <span class="ow">in</span> <span class="n">ground_truth</span><span class="p">:</span>
            <span class="n">hits</span> <span class="o">+=</span> <span class="mi">1</span>
            <span class="n">sum_precs</span> <span class="o">+=</span> <span class="n">hits</span> <span class="o">/</span> <span class="p">(</span><span class="n">n</span> <span class="o">+</span> <span class="mf">1.0</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">hits</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">sum_precs</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">ground_truth</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="mi">0</span>
</pre></div>
</div>
<ul class="simple">
<li><p>那么对于MAP(Mean Average Precision)：所有用户 <span class="math notranslate nohighlight">\(u\)</span> 的AP再取均值</p></li>
</ul>
</li>
<li><p><strong>Normalized Discounted Cummulative Gain(NDCG)</strong></p>
<ul>
<li><p><strong>累积增益CG</strong>，表示将每个推荐结果相关性的分值累加后作为整个推荐列表的得分。</p>
<p><span class="math notranslate nohighlight">\(C G_{k}=\sum_{i=1}^{k} r e l_{i}\)</span> , <span class="math notranslate nohighlight">\(r e l_{i}\)</span> 表示处于位置 <span class="math notranslate nohighlight">\(i\)</span> 的推荐结果的相关性, <span class="math notranslate nohighlight">\(k\)</span> 表示所要考察的推荐列表的大小</p>
<p>缺点：</p>
<ul class="simple">
<li><p>CG没有考虑每个推荐结果处于不同位置对整个推荐结果的影响，例如，我们总是希望相关性大的结果排在前面，相关性低的排在前面会影响用户体验。</p></li>
</ul>
</li>
<li><p><strong>DCG</strong>(Discounted Cummulative Gain)在CG的基础上引入了位置影响因素</p>
<p><span class="math notranslate nohighlight">\(D C G_{k}=\sum_{i=1}^{k} \frac{2^{r e l_{i}}-1}{\log _{2}(i+1)}\)</span></p>
<ul class="simple">
<li><p>分子部分 <span class="math notranslate nohighlight">\(2^{r e l_{i}}-1\)</span>：<span class="math notranslate nohighlight">\(r e l_{i}\)</span> 越大, 即推荐结果 <span class="math notranslate nohighlight">\(i\)</span> 的相关性越大，推荐效果越好，DCG越大。</p></li>
<li><p>分母部分 <span class="math notranslate nohighlight">\(\log _{2}(i+1)\)</span>：<span class="math notranslate nohighlight">\(i\)</span> 表示推荐结果的位置, <span class="math notranslate nohighlight">\(i\)</span> 越大, 则推荐结果在推荐列表中排名越靠后，推荐效果越差，DCG越 小。</p></li>
</ul>
<p>缺点：DCG针对<strong>不同的推荐列表之间很难进行横向评估</strong>，而我们评估一个推荐系统不可能仅使用一个用户的推荐列表及相应结果进行评估，而是对整个测试集中的用户及其推荐列表结果进行评估。</p>
</li>
<li><p>那么，不同用户的推荐列表的评估分数就需要进行归一化，也就是<strong>NDCG</strong>。</p></li>
</ul>
</li>
<li><p><strong>Mean Reciprocal Rank(MRR)</strong></p>
<p><span class="math notranslate nohighlight">\(M R R=\frac{1}{Q} \sum_{i=1}^{|Q|} \frac{1}{r a n k_{i}}\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(|Q|\)</span> 是用户的个数, <span class="math notranslate nohighlight">\(r a n k_{i}\)</span> 是对于第 <span class="math notranslate nohighlight">\(i\)</span> 个用户, 推荐列表中第一个在ground-truth结果中的item所在的排列位置。</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="id13">
<h2>参考<a class="headerlink" href="#id13" title="Permalink to this headline">¶</a></h2>
<ol class="simple">
<li><p>周志华 西瓜书</p></li>
<li><p>李航 统计学习方法</p></li>
<li><p><a class="reference external" href="https://baike.baidu.com/item/CVR/20215345">https://baike.baidu.com/item/CVR/20215345</a></p></li>
<li><p><a class="reference external" href="https://baike.baidu.com/item/CTR/10653699?fr=aladdin">https://baike.baidu.com/item/CTR/10653699?fr=aladdin</a></p></li>
<li><p><a class="reference external" href="https://www.cnblogs.com/shenxiaolin/p/9309749.html">https://www.cnblogs.com/shenxiaolin/p/9309749.html</a></p></li>
<li><p><a class="reference external" href="https://www.cnblogs.com/wqbin/p/11105186.html">https://www.cnblogs.com/wqbin/p/11105186.html</a></p></li>
<li><p><a class="reference external" href="https://blog.csdn.net/xiedelong/article/details/112500657">CSDN博主｜xiedelong｜推荐系统中的 MAP 评估指标</a></p></li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ML"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="../Causal_Inference/2_methods.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">因果推理方法</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="SupervisedML.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">有监督学习</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jace Yang<br/>
    
        &copy; Copyright 2021.<br/>
      <div class="extra_footer">
        Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
      </div>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>