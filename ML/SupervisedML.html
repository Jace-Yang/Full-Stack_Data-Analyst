
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>æœ‰ç›‘ç£å­¦ä¹  &#8212; Towards a Full-stack DA</title>
    
  <link href="../_static/css/theme.css" rel="stylesheet">
  <link href="../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="åŸºç¡€" href="../DL/Basics/README.html" />
    <link rel="prev" title="åŸºç¡€" href="README.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../_static/logo2.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Towards a Full-stack DA</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../intro.html">
   Jaceå…­è¾¹å½¢DAç¬”è®°åº“
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  å¤šå…ƒåˆ†æ
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/Business.html">
   å•†ä¸šåˆ†æ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/DA.html">
   æ•°æ®åˆ†æ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Analysis/STAT.html">
   ç»Ÿè®¡åˆ†æ
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  å› æœæ¨æ–­
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/README.html">
   åŸºç¡€
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/1_AB_testing.html">
   AB Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../Causal_Inference/2_methods.html">
   å› æœæ¨ç†æ–¹æ³•
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  æœºå™¨å­¦ä¹ 
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="README.html">
   åŸºç¡€
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   æœ‰ç›‘ç£å­¦ä¹ 
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  æ·±åº¦å­¦ä¹ 
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DL/Basics/README.html">
   åŸºç¡€
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/Basics/DL_hyperparameter.html">
     DLå¸¸è§è¶…å‚åŠè°ƒæ•´ç­–ç•¥
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/Basics/Optimizer.html">
     ä¼˜åŒ–å™¨
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/Basics/Trained_by_GPU.html">
     GPUè®­ç»ƒ
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DL/NLP/README.html">
   NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/basics.html">
     åŸºç¡€æ¦‚å¿µ
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/Self-attention.html">
     Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/Transformer.html">
     Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DL/NLP/BERT.html">
     BERT
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DL/NN_compression/README.html">
   ç¥ç»ç½‘ç»œå‹ç¼©
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../DL/NN_compression/KD.html">
     çŸ¥è¯†è’¸é¦
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
    <label for="toctree-checkbox-4">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../DL/NN_compression/Distill_Bert.html">
       Distill Bert
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="../DL/NN_compression/Quantize.html">
     é‡åŒ–
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="../DL/NN_compression/QBert.html">
       Q-BERT
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  æ•°æ®ä»“åº“
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../DE/README.html">
   åŸºç¡€æ¦‚å¿µ
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../DE/SQL.html">
   SQL
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../DE/Data_cleaning/README.html">
   æ•°æ®æ¸…æ´—ä¸å¤„ç†
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
  <label for="toctree-checkbox-6">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../DE/Data_cleaning/Regex.html">
     æ­£åˆ™è¡¨è¾¾å¼
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../DE/Data_cleaning/pandas.html">
     Pandas
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  è”ç³»æ–¹å¼
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference external" href="https://www.linkedin.com/in/jinhang-yang/">
   LinkedIn
  </a>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/ML/SupervisedML.md"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.md</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst/issues/new?title=Issue%20on%20page%20%2FML/SupervisedML.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst/edit/master/ML/SupervisedML.md"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   æœ‰ç›‘ç£å­¦ä¹ 
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     æ•´ä½“æ¡†æ¶
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-preprocessing">
       Data Preprocessing
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#missing-data">
         Missing Data
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#categorical-data">
         categorical data
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#numerical-feature-scaling">
         Numerical Feature Scaling
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#outliers">
         Outliers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         å¤„ç†æ ·æœ¬ä¸å¹³è¡¡
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       æ¨¡å‹è®­ç»ƒæ­¥éª¤
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn">
     KNN
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     çº¿æ€§å›å½’ç±»
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#simple-linear-regression">
       Simple Linear Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ridge-regression">
       Ridge Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lasso-regression">
       Lasso Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#elastic-net-regression">
       Elastic-Net regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#l1l2">
       L1å’ŒL2çš„åŒºåˆ«
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic Regression
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#setup">
       æ¨¡å‹Setup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       <strong>
        å¤šåˆ†ç±»é—®é¢˜å¸¸è§„è§£å†³æ–¹æ¡ˆ
       </strong>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#logistics">
       <strong>
        Logisticsè§£å†³å¤šåˆ†ç±»é—®é¢˜
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm">
     SVM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-hard-margin">
       Primal + Hard-margin
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-dual">
       Primal + Dual
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-soft-margin">
       Primal + Soft- margin
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dual-soft-margin">
       Dual + Soft-margin
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensemble-methods">
     Ensemble Methods
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging">
       Bagging
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#boosting">
       Boosting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#baggingboosting">
       Baggingå’ŒBoostingçš„åŒºåˆ«
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stacking">
       Stacking
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trees">
     Trees
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#decision-trees">
       Decision Trees
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-boosting">
       Gradient Boosting
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gbdt">
         <strong>
          GBDT
         </strong>
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gradientboostingclassifier">
         GradientBoostingClassiï¬er
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#histgradientboostingclassifier">
         HistGradientBoostingClassiï¬er
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboost">
       XGBoost
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lightgbm">
       LightGBM
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboostlightgbm">
       XGBoostå’ŒLightGBMçš„åŒºåˆ«
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#catboost">
       CatBoost
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>æœ‰ç›‘ç£å­¦ä¹ </h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   æœ‰ç›‘ç£å­¦ä¹ 
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id2">
     æ•´ä½“æ¡†æ¶
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#data-preprocessing">
       Data Preprocessing
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#missing-data">
         Missing Data
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#categorical-data">
         categorical data
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#numerical-feature-scaling">
         Numerical Feature Scaling
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#outliers">
         Outliers
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id3">
         å¤„ç†æ ·æœ¬ä¸å¹³è¡¡
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id4">
       æ¨¡å‹è®­ç»ƒæ­¥éª¤
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#knn">
     KNN
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id5">
     çº¿æ€§å›å½’ç±»
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#simple-linear-regression">
       Simple Linear Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#ridge-regression">
       Ridge Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lasso-regression">
       Lasso Regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#elastic-net-regression">
       Elastic-Net regression
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#l1l2">
       L1å’ŒL2çš„åŒºåˆ«
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#logistic-regression">
     Logistic Regression
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#setup">
       æ¨¡å‹Setup
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id6">
       <strong>
        å¤šåˆ†ç±»é—®é¢˜å¸¸è§„è§£å†³æ–¹æ¡ˆ
       </strong>
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#logistics">
       <strong>
        Logisticsè§£å†³å¤šåˆ†ç±»é—®é¢˜
       </strong>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#svm">
     SVM
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-hard-margin">
       Primal + Hard-margin
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-dual">
       Primal + Dual
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#primal-soft-margin">
       Primal + Soft- margin
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#dual-soft-margin">
       Dual + Soft-margin
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#ensemble-methods">
     Ensemble Methods
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging">
       Bagging
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#boosting">
       Boosting
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#baggingboosting">
       Baggingå’ŒBoostingçš„åŒºåˆ«
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#stacking">
       Stacking
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#trees">
     Trees
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#decision-trees">
       Decision Trees
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#gradient-boosting">
       Gradient Boosting
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gbdt">
         <strong>
          GBDT
         </strong>
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#gradientboostingclassifier">
         GradientBoostingClassiï¬er
        </a>
       </li>
       <li class="toc-h4 nav-item toc-entry">
        <a class="reference internal nav-link" href="#histgradientboostingclassifier">
         HistGradientBoostingClassiï¬er
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboost">
       XGBoost
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#lightgbm">
       LightGBM
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#xgboostlightgbm">
       XGBoostå’ŒLightGBMçš„åŒºåˆ«
      </a>
     </li>
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#catboost">
       CatBoost
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#reference">
   Reference
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>æœ‰ç›‘ç£å­¦ä¹ <a class="headerlink" href="#id1" title="Permalink to this headline">Â¶</a></h1>
<div class="section" id="id2">
<h2>æ•´ä½“æ¡†æ¶<a class="headerlink" href="#id2" title="Permalink to this headline">Â¶</a></h2>
<p><strong>æœ€ç»ˆè¾“å‡ºï¼šè¶…å‚æ•°è®¾å®šâ•æ¨¡å‹â•æ¨¡å‹è¡¨ç°</strong></p>
<ul class="simple">
<li><p>Development-test splitã€Hyperparameter tuning ã€Optimal model trainingã€Model evaluationã€Model deployment</p></li>
</ul>
<p><img alt="img" src="../_images/(null)-20220724153653287.(null)" /></p>
<ul>
<li><p>evaluationå¾ˆé‡è¦ï¼šå› ä¸ºæˆ‘ä»¬éœ€è¦çŸ¥é“æ¯ä¸ªå¤æ‚åº¦çš„æ¨¡å‹å¯¹åº”çš„è¡¨ç°æ˜¯å¤šå°‘ï¼Œæ¥åˆ¤æ–­æœ‰æ²¡æœ‰å¿…è¦ç”¨å¤æ‚çš„æ¨¡å‹ï¼</p>
<p>å› æ­¤ï¼šä¸å¯ä»¥ç”¨æ•´ä¸ªdatasetå‡ºè¶…å‚æ•°è€Œæ”¾å¼ƒevaluation</p>
</li>
</ul>
<div class="section" id="data-preprocessing">
<h3>Data Preprocessing<a class="headerlink" href="#data-preprocessing" title="Permalink to this headline">Â¶</a></h3>
<div class="section" id="missing-data">
<h4>Missing Data<a class="headerlink" href="#missing-data" title="Permalink to this headline">Â¶</a></h4>
<ul>
<li><p>ä¸å¤„ç†ï¼ˆå½“æˆä¸€ç§å€¼ï¼‰ç„¶åç”¨ç¡®å®ä¸æ•æ„Ÿçš„æ ‘æ¨¡å‹</p></li>
<li><p>å‰”é™¤</p>
<ul class="simple">
<li><p>Drop column (typically used as baseline)ï¼šç¼ºå¤±å¤ªå¤šçš„æ—¶å€™</p></li>
<li><p>Drop rows (if there are only a few with missing values)</p></li>
</ul>
</li>
<li><p>å¡«å……ï¼ˆImputeï¼‰/ä¼°ç®—(estimation)ï¼š</p>
<ul class="simple">
<li><p>mean or median (SimpleImputer in sklearn API) æ²¡æœ‰å……åˆ†è€ƒè™‘æ•°æ®ä¸­å·²æœ‰çš„ä¿¡æ¯ï¼Œè¯¯å·®å¯èƒ½è¾ƒå¤§</p></li>
<li><p>kNN (neighbors are found using nan_euclidean_distance  metric)</p></li>
<li><p>Regression modelsæ ¹æ®è°ƒæŸ¥å¯¹è±¡å¯¹å…¶ä»–é—®é¢˜çš„ç­”æ¡ˆï¼Œé€šè¿‡å˜é‡ä¹‹é—´çš„ç›¸å…³åˆ†ææˆ–é€»è¾‘æ¨è®ºè¿›è¡Œä¼°è®¡ã€‚ä¾‹å¦‚ï¼ŒæŸä¸€äº§å“çš„æ‹¥æœ‰æƒ…å†µå¯èƒ½ä¸å®¶åº­æ”¶å…¥æœ‰å…³ï¼Œå¯ä»¥æ ¹æ®è°ƒæŸ¥å¯¹è±¡çš„å®¶åº­æ”¶å…¥æ¨ç®—æ‹¥æœ‰è¿™ä¸€äº§å“çš„å¯èƒ½æ€§</p></li>
</ul>
</li>
<li><p>Add a binary additional indicator column (è·Ÿä¸Šä¸€æ­¥ä¸€è‡´)</p>
<p>(often captured by adding missing indicator columns)</p>
<ul class="simple">
<li><p>Missing in not random! It will add value to the model</p></li>
<li><p>æ¯”å¦‚ï¼æœ‰ä¸ªclass is always missingï¼å°±åƒ16å²ä»¥ä¸‹çš„è¿™ä¸ªç»„æ²¡æœ‰é©¾ç…§å¹´é™,è¿™ä¸ªå¯ä»¥æ˜¯predictive columnsï¼ï¼</p></li>
</ul>
</li>
<li><p>Matrix factorizationï¼šå°†ä¸€ä¸ªå«<em>ç¼ºå¤±</em>å€¼çš„çŸ©é˜µ X åˆ†è§£ä¸ºä¸¤ä¸ª(æˆ–å¤šä¸ª)çŸ©é˜µ,ç„¶åè¿™äº›åˆ†è§£åçš„çŸ©é˜µç›¸ä¹˜å°± å¯ä»¥å¾—åˆ°åŸçŸ©é˜µçš„è¿‘ä¼¼ X</p></li>
</ul>
</div>
<div class="section" id="categorical-data">
<h4>categorical data<a class="headerlink" href="#categorical-data" title="Permalink to this headline">Â¶</a></h4>
<p>æ³¨æ„ï¼šéƒ½æ˜¯å¯¹åˆ†å¼€ä¹‹åçš„æ•°æ®ï¼åªé’ˆå¯¹train data æ¥fit</p>
<ul class="simple">
<li><p>Ordinal encoding</p>
<ul>
<li><p>Missing valueå¯ä»¥ç†è§£ä¸ºæœ€ä¸é‡è¦çš„classç„¶åç»™0ï¼Œä¹Ÿå¯ä»¥ç†è§£ä¸ºæœ€é‡è¦çš„ç»™maxï¼æˆ–è€…imputeæˆmode</p></li>
</ul>
</li>
<li><p>One-hot encoding: no information loss.</p>
<ul>
<li><p>ç‰¹ç‚¹</p>
<ul>
<li><p>å¤„ç†ç¼ºå¤±ï¼šmissingçš„æ—¶å€™å¯ä»¥æŠŠmissingå½“ä½œä¸€ç§category</p></li>
<li><p>æµ‹è¯•é›†é‡åˆ°æ–°çš„ç±»åˆ«çš„æ—¶å€™ï¼šåŠ å…¥<code class="docutils literal notranslate"><span class="pre">handle_unkown</span> <span class="pre">=</span> <span class="pre">&quot;ignore&quot;</span></code>å¯ä»¥</p></li>
</ul>
</li>
<li><p>åœºæ™¯ï¼š</p>
<ul>
<li><p>One-hot encoding introduces <strong>multi-collinearity</strong></p>
<ul>
<li><p>For e.g., x3 = 1 - x1 - x2 (in case when we have three categories)</p></li>
<li><p>Possible to remove one feature, because itâ€™s a <strong>linear combination of the other columns</strong>, could be problematic for some non-regularized regression models</p></li>
<li><p>Has <strong>implications</strong> on model interpretation</p>
<ul>
<li><p>å¯ä»¥dropè¿™ä¸ªä¹Ÿå¯ä»¥dropåˆ«çš„ï¼Œè¿™æ ·çš„è¯feature importanceå°±ä¸åŒäº†</p></li>
<li><p>æœ‰äººå¯ä»¥keep all columns, and apply regulariazation to take care of during the training process, then get insights into the model</p></li>
</ul>
</li>
</ul>
</li>
<li><p>æœ‰çš„æ¨¡å‹ æ¯”å¦‚treesï¼Œå¯ä»¥split on categorical variables, so it will automatically handles categorical variablesï¼š</p>
<ul>
<li><p>Tree-based models</p></li>
<li><p>Naive Bayes models</p></li>
</ul>
</li>
</ul>
</li>
<li><p>é—®é¢˜ï¼šLeads to high-dimensional datasets</p></li>
</ul>
</li>
<li><p>Target encodingï¼šä¸æ˜¯introduce 1 column for 1 category, è€Œæ˜¯summarize the information for each category and convert into 1 column</p>
<ul>
<li><p>Generally applicable for high <strong>cardinality</strong> categorical features</p></li>
<li><p>å…·ä½“encodeçš„æ–¹å¼å–å†³äºæ¨¡å‹é—®é¢˜ï¼š</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Regression</span></code>: Average target value for each category</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Classification</span></code>: Average of æ¦‚ç‡â€”â€”è¿™ä¸ªæ¯”ç›´æ¥mapåˆ°labelå¥½ï¼Œå› ä¸ºä¾ç„¶å¯ä»¥æ ¹æ®probabilityåŒºåˆ†å‡ºä¸åŒçš„classå¯¹yçš„å½±å“</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Binary</span> <span class="pre">classiï¬cation</span></code>: Probability of being in class 1</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Multiclass</span> <span class="pre">classiï¬cation</span></code>: <em>One feature per class</em> that gives the probability distribution</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="numerical-feature-scaling">
<h4>Numerical Feature Scaling<a class="headerlink" href="#numerical-feature-scaling" title="Permalink to this headline">Â¶</a></h4>
<ul class="simple">
<li><p>scalingä¸ä¼šæ”¹å˜åŸå§‹æ•°æ®ï¼Œä½†æ˜¯ä¼šè®©æ¨¡å‹å˜å¾—å¥½</p></li>
<li><p>è®°å¾—è¦fit_transform(è®­ç»ƒé›†)ï¼Œç„¶åtransform(æµ‹è¯•é›†)è€Œä¸æ˜¯fit_transform(æµ‹è¯•é›†)ï¼Œå› ä¸ºæˆ‘ä»¬ä¸çŸ¥é“æµ‹è¯•é›†çš„meanå’Œstdç­‰</p></li>
</ul>
<p><img src="../images/(null)-20220724215527501.(null)" alt="img" style="width:50%;" /><img src="../images/(null)-20220724215537886.(null)" alt="img" style="width:50%;" /></p>
<ul>
<li><p>å…·ä½“çš„æ–¹å¼ï¼š</p>
<p>æ ‡å‡†åŒ–ï¼šæœ€å¤§æœ€å°æ ‡å‡†åŒ–ã€zæ ‡å‡†åŒ–â€”â€”StandardScaler()ã€MinMaxScaler()ã€MaxAbsScaler()ï¼ˆé™¤ä»¥æœ€å¤§å€¼çš„è¯è´Ÿæ•°è¿˜ä¼šæ˜¯è´Ÿæ•°ï¼‰ã€RobustScaler()ã€Nomalizer()ï¼ˆå˜æˆåœ†å½¢ï¼‰</p>
<p>å½’ä¸€åŒ–ï¼šå¯¹äºæ–‡æœ¬æˆ–è¯„åˆ†ç‰¹å¾ï¼Œä¸åŒæ ·æœ¬ä¹‹é—´å¯èƒ½æœ‰æ•´ä½“ä¸Šçš„å·®å¼‚ï¼Œå¦‚aæ–‡æœ¬å…±20ä¸ªè¯ï¼Œbæ–‡æœ¬30000ä¸ªè¯ï¼Œbæ–‡æœ¬ä¸­å„ä¸ªç»´åº¦ä¸Šçš„é¢‘æ¬¡éƒ½å¾ˆå¯èƒ½è¿œè¿œé«˜äºaæ–‡æœ¬</p>
</li>
<li><p>æ³¨æ„åº”è¯¥åšfitçš„æ•°æ®é›†è·Ÿåº”è¯¥åšfitçš„æ¨¡å‹æ˜¯ä¸€è‡´çš„</p>
<ul>
<li><p>æ¯”å¦‚hyper parameter tuningçš„æ—¶å€™  scalerä¸åº”è¯¥ç¢°validation data</p>
<img src="../images/(null)-20220724215547062.(null)" alt="img" style="width:50%;" />
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="outliers">
<h4>Outliers<a class="headerlink" href="#outliers" title="Permalink to this headline">Â¶</a></h4>
<ul class="simple">
<li><p>æ£€æµ‹æ–¹å¼ï¼šIQRã€LRä¹‹åçœ‹cookè·ç¦»</p></li>
</ul>
</div>
<div class="section" id="id3">
<h4>å¤„ç†æ ·æœ¬ä¸å¹³è¡¡<a class="headerlink" href="#id3" title="Permalink to this headline">Â¶</a></h4>
<p><strong>Change data</strong></p>
<ul>
<li><p>Random Undersampling</p></li>
<li><p>Random Oversampling</p></li>
<li><p>Ensemble Resampling</p>
<ul class="simple">
<li><p>A random re-sample of majority class is used for training each instance in an ensemble</p></li>
<li><p>The minority class is retained while training the instance.</p></li>
</ul>
</li>
<li><p>Synthetic Minority Oversampling Technique (SMOTE)</p>
<img src="../images/image-20220726111730712.png" alt="image-20220726111730712" style="width:50%;" />
<ul class="simple">
<li><p>Synthetic Minority Oversampling Technique (SMOTE) is a popular method to handle training with imbalanced datasets</p></li>
<li><p>SMOTE <strong>adds synthetic interpolated sample</strong>s to minority class</p></li>
<li><p>The following procedure is repeated for every original data point in minority class:</p>
<ul>
<li><p>Pick a neighbor from <span class="math notranslate nohighlight">\(k\)</span> nearest neighbors</p></li>
<li><p><strong>Sample a point randomly from the line</strong> joining the two data points.</p></li>
<li><p>Add the point to the minority class</p></li>
</ul>
</li>
<li><p>Leads to large datasets (due to oversampling)</p></li>
</ul>
</li>
</ul>
<p><strong>Change training procedure</strong></p>
<ul class="simple">
<li><p>assighing Class weightsï¼šmake sure the penalty of predicting minority wrong is more high!</p>
<ul>
<li><p>Reweight each sample during training</p>
<ul>
<li><p>Modify the loss function to account for class weights</p></li>
<li><p>Similar effect as oversampling (except that this is not random)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ä¿®æ”¹æ¨¡å‹çš„æŸå¤±å‡½æ•°ï¼šä¸æ˜¯F1äº†è€Œæ˜¯æ›´ä¸åŒçš„</p></li>
</ul>
<p><strong>é‡æ–°é€‰æ‹©è¯„ä»·æŒ‡æ ‡</strong>ï¼š</p>
<ul class="simple">
<li><p>AP</p></li>
</ul>
<p><strong>é‡æ„é—®é¢˜</strong></p>
<ul class="simple">
<li><p>ä»”ç»†å¯¹ä½ çš„é—®é¢˜è¿›è¡Œåˆ†æä¸æŒ–æ˜ï¼Œæ˜¯å¦å¯ä»¥å°†ä½ çš„é—®é¢˜åˆ’åˆ†æˆå¤šä¸ªæ›´å°çš„é—®é¢˜ï¼Œè€Œè¿™äº›å°é—®é¢˜æ›´å®¹æ˜“è§£å†³ã€‚</p></li>
</ul>
</div>
</div>
<div class="section" id="id4">
<h3>æ¨¡å‹è®­ç»ƒæ­¥éª¤<a class="headerlink" href="#id4" title="Permalink to this headline">Â¶</a></h3>
<p>Development-test split</p>
<ul>
<li><p>Random split</p>
<ul class="simple">
<li><p>æ¯”ä¾‹å–å†³äºå®é™…é—®é¢˜</p>
<ul>
<li><p>Large Sample Sizeï¼šä¸¤è¾¹éƒ½å¤Ÿ éšä¾¿</p></li>
<li><p>è®­ç»ƒé›†å°çš„ æ¯”å¦‚åªæœ‰100ä¸ªçš„æ—¶å€™å¯èƒ½éœ€è¦put asideå°‘ä¸€ç‚¹</p></li>
<li><p>æœ‰æ—¶å€™å¤ªå¤šäº†ï¼Œåªéœ€è¦è®­ç»ƒ50%çš„æ•°æ®å°±å¤Ÿäº†æ¥èŠ‚çœæ—¶é—´ï¼Œåé¢æ‹¿50%å»æµ‹è¯•ï¼Œtraining procures is shorten without comprimising the quality of model</p></li>
</ul>
</li>
<li><p>æœ€åè¾“å‡ºå„ä¸ªtargetçš„ä¸ä¸€å®šæ˜¯å æ¯”ä¸€æ ·çš„</p></li>
</ul>
</li>
<li><p>Stratiï¬ed Splitting</p>
<ul>
<li><p>The stratiï¬ed splitting ensures that the <strong>ratio of classes in development</strong> and <strong>test datasets</strong> equals that of the original dataset.</p></li>
<li><p>Generally employed when performing classiï¬cation tasks on highly imbalanced datasets</p></li>
<li><p>indexæ˜¯class</p>
<img src="../images/(null)-20220724221510415.(null)" alt="img" style="width: 33%;" />
</li>
<li><p>æ˜¯SK learnçš„é»˜è®¤å€¼ï¼</p></li>
</ul>
</li>
<li><p>Structured Splitting</p>
<ul class="simple">
<li><p>The structured splitting is generally employed to prevent data leakage.</p></li>
<li><p>Examplesï¼šStock price predictionsã€Time-series predictions</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220724221513024.(null)" alt="img" style="width: 33%;" />
<p>Hyper-parameter tuning</p>
<p>æ ¸å¿ƒç›®æ ‡ï¼šTraining data â‡’ Select Best Parameters</p>
<img src="../images/(null)-20220724221503960.(null)" alt="img" style="width:25%;" />
<p>è¶…å‚çš„æ³¨æ„äº‹é¡¹â€”â€”æ³¨æ„å¤æ‚åº¦</p>
<ul>
<li><p>å¯¹æ¨¡å‹å¤æ‚åº¦çš„ç†è§£ï¼šå¯¹æ¨¡å‹å˜å¤æ‚ï¼Œæˆ‘ä»¬åœ¨åšBias-Varianceçš„Tradeoï¬€.æ¨¡å‹çš„é¢„æµ‹è¯¯å·®å¯ä»¥åˆ†è§£ä¸ºä¸‰ä¸ªéƒ¨åˆ†: åå·®(bias)ï¼Œ æ–¹å·®(variance) å’Œå™ªå£°(noise).</p>
<ul>
<li><p>the conflict in trying to simultaneously minimize these two sources of <a class="reference external" href="https://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics">error</a> that prevent supervised learning algorithms from generalizing beyond their training set</p>
<ul>
<li><p><strong>The</strong> <em><strong><a class="reference external" href="https://en.wikipedia.org/wiki/Bias_of_an_estimator">bias</a></strong></em> <strong>error</strong> is an error from erroneous assumptions in the learning <a class="reference external" href="https://en.wikipedia.org/wiki/Algorithm">algorithm</a>. High bias can cause an algorithm to <em>miss the relevant relations between features and target outputs</em> (underfitting). åå·®åº¦é‡äº†æ¨¡å‹çš„æœŸæœ›é¢„æµ‹ä¸çœŸå®ç»“æœçš„åç¦»ç¨‹åº¦ï¼Œ å³åˆ»ç”»äº†å­¦ä¹ ç®—æ³•æœ¬èº«çš„æ‹Ÿåˆèƒ½åŠ›ã€‚åå·®åˆ™è¡¨ç°ä¸ºåœ¨ç‰¹å®šåˆ†å¸ƒä¸Šçš„é€‚åº”èƒ½åŠ›ï¼Œåå·®è¶Šå¤§è¶Šåç¦»çœŸå®å€¼ã€‚</p></li>
<li><p><strong>The</strong> <em><strong><a class="reference external" href="https://en.wikipedia.org/wiki/Variance">variance</a></strong></em> is an error from <strong>sensitivity</strong> to <strong>small fluctuations in the training set</strong>. High variance may result from an algorithm modeling the random <a class="reference external" href="https://en.wikipedia.org/wiki/Noise_(signal_processing)">noise</a> in the training data (<a class="reference external" href="https://en.wikipedia.org/wiki/Overfitting">overfitting</a>). æ–¹å·®åº¦é‡äº†åŒæ ·å¤§å°çš„è®­ç»ƒé›†çš„å˜åŠ¨æ‰€å¯¼è‡´çš„å­¦ä¹ æ€§èƒ½çš„å˜åŒ–ï¼Œ å³åˆ»ç”»äº†æ•°æ®æ‰°åŠ¨æ‰€é€ æˆçš„å½±å“ã€‚æ–¹å·®è¶Šå¤§ï¼Œè¯´æ˜æ•°æ®åˆ†å¸ƒè¶Šåˆ†æ•£</p></li>
<li><p>å™ªå£°ï¼šå™ªå£°è¡¨è¾¾äº†åœ¨å½“å‰ä»»åŠ¡ä¸Šä»»ä½•æ¨¡å‹æ‰€èƒ½è¾¾åˆ°çš„æœŸæœ›æ³›åŒ–è¯¯å·®çš„ä¸‹ç•Œï¼Œ å³åˆ»ç”»äº†å­¦ä¹ é—®é¢˜æœ¬èº«çš„éš¾åº¦ ã€‚</p>
<p><img src="../images/(null)-20220724221505235.(null)" alt="img" style="width:45%;" /><img src="../images/(null)-20220724221443081.(null)" alt="img" style="width:45%;" /></p>
<ul class="simple">
<li><p>æˆ‘ä»¬æƒ³è¦å·¦ä¸Šè§’ï¼šéƒ½å¾ˆå‡†ç¡®</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>è¿‡æ‹Ÿåˆé—®é¢˜</strong></p>
<img src="../images/(null)-20220724221442702.(null)" alt="img" style="width: 50%;" />
<ul class="simple">
<li><p>underfittingæ˜¯low variance high biasï¼šæ²¡æœ‰varianceä½†éƒ½é¢„æµ‹å‡ºåå·®äº†</p>
<ul>
<li><p>å½“ç®—æ³•ä»æ•°æ®é›†å­¦ä¹ çœŸå®ä¿¡å·çš„<strong>çµæ´»æ€§æœ‰é™</strong>æ—¶ï¼Œå°±ä¼šå‡ºç°åå·®ã€‚( æƒ³çš„å¤ªè¿‡ç®€å•ï¼Œæ¬ æ‹Ÿåˆ), æ‰€ä»¥æ¨¡å‹æ•´ä½“äº§ç”Ÿåå·®ã€‚</p></li>
<li><p>æ¬ æ‹ŸåˆæŒ‡çš„æ˜¯æ¨¡å‹æ²¡æœ‰å¾ˆå¥½åœ°å­¦ä¹ åˆ°æ•°æ®ç‰¹å¾ï¼Œä¸èƒ½å¤Ÿå¾ˆå¥½åœ°æ‹Ÿåˆæ•°æ®ï¼Œåœ¨è®­ç»ƒæ•°æ®å’ŒæœªçŸ¥æ•°æ®ä¸Šè¡¨ç°éƒ½å¾ˆå·®ã€‚</p></li>
<li><p>æ¬ æ‹Ÿåˆçš„åŸå› åœ¨äºï¼š</p>
<ul>
<li><p>ç‰¹å¾é‡è¿‡å°‘ï¼›</p></li>
<li><p>æ¨¡å‹å¤æ‚åº¦è¿‡ä½</p></li>
</ul>
</li>
</ul>
</li>
<li><p>è§£å†³ï¼š</p>
<ul>
<li><p>å¢åŠ æ–°ç‰¹å¾ï¼Œå¯ä»¥è€ƒè™‘åŠ å…¥è¿›ç‰¹å¾ç»„åˆã€é«˜æ¬¡ç‰¹å¾ï¼Œæ¥å¢å¤§å‡è®¾ç©ºé—´ï¼›</p></li>
<li><p>æ·»åŠ <strong>å¤šé¡¹å¼ç‰¹å¾</strong>ï¼Œè¿™ä¸ªåœ¨æœºå™¨å­¦ä¹ ç®—æ³•é‡Œé¢ç”¨çš„å¾ˆæ™®éï¼Œä¾‹å¦‚å°†çº¿æ€§æ¨¡å‹é€šè¿‡æ·»åŠ äºŒæ¬¡é¡¹æˆ–è€…ä¸‰æ¬¡é¡¹ä½¿æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ›´å¼ºï¼›</p></li>
<li><p><strong>å‡å°‘æ­£åˆ™åŒ–å‚æ•°</strong>ï¼Œæ­£åˆ™åŒ–çš„ç›®çš„æ˜¯ç”¨æ¥é˜²æ­¢è¿‡æ‹Ÿåˆçš„ï¼Œä½†æ˜¯æ¨¡å‹å‡ºç°äº†æ¬ æ‹Ÿåˆï¼Œåˆ™éœ€è¦å‡å°‘æ­£åˆ™åŒ–å‚æ•°ï¼›</p></li>
<li><p>ä½¿ç”¨<strong>éçº¿æ€§æ¨¡å‹</strong>ï¼Œæ¯”å¦‚æ ¸SVM ã€å†³ç­–æ ‘ã€æ·±åº¦å­¦ä¹ ç­‰æ¨¡å‹ï¼›</p></li>
<li><p>è°ƒæ•´<strong>æ¨¡å‹çš„å®¹é‡(capacity)</strong>ï¼Œé€šä¿—åœ°ï¼Œæ¨¡å‹çš„å®¹é‡æ˜¯æŒ‡å…¶æ‹Ÿåˆå„ç§å‡½æ•°çš„èƒ½åŠ›ï¼›</p></li>
<li><p>å®¹é‡ä½çš„æ¨¡å‹å¯èƒ½å¾ˆéš¾æ‹Ÿåˆè®­ç»ƒé›†ã€‚</p></li>
</ul>
</li>
<li><p>overfittingæ˜¯high variance low biasï¼šå¹³å‡æ¥çœ‹çš„è¯ æ˜¯center the plot means doing well! ä½†varianceéå¸¸é«˜</p>
<ul>
<li><p>å¤ªå…³æ³¨è®­ç»ƒé›†ä¸­ä¸ªä½“æ³¢åŠ¨ï¼Œè¿‡æ‹Ÿåˆ</p></li>
<li><p>é«˜æ–¹å·®æ¨¡å‹ï¼Œå¯¹ç‰¹å®šè®­ç»ƒæ•°æ®é›†çš„çµæ´»æ€§æé«˜ã€‚</p></li>
<li><p>é«˜æ–¹å·®æ¨¡å‹éå¸¸å…³æ³¨è®­ç»ƒæ•°æ®ï¼Œè€Œå¯¹ä»¥å‰æ²¡æœ‰è§è¿‡çš„æ•°æ®ä¸è¿›è¡Œæ³›åŒ–generalizabilityã€‚å› æ­¤ï¼Œè¿™æ ·çš„æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šè¡¨ç°å¾—å¾ˆå¥½ï¼Œä½†åœ¨æµ‹è¯•æ•°æ®ä¸Šå´æœ‰å¾ˆé«˜çš„é”™è¯¯ç‡ã€‚</p></li>
<li><p>è¿‡æ‹Ÿåˆçš„åŸå› åœ¨äºï¼š</p>
<ul>
<li><p><strong>å‚æ•°å¤ªå¤š</strong>ï¼Œæ¨¡å‹å¤æ‚åº¦è¿‡é«˜ï¼›</p></li>
<li><p>å»ºæ¨¡<strong>æ ·æœ¬é€‰å–æœ‰è¯¯</strong>ï¼Œå¯¼è‡´é€‰å–çš„æ ·æœ¬æ•°æ®ä¸è¶³ä»¥ä»£è¡¨é¢„å®šçš„åˆ†ç±»è§„åˆ™ï¼›</p></li>
<li><p><strong>æ ·æœ¬å™ªéŸ³å¹²æ‰°è¿‡å¤§</strong>ï¼Œä½¿å¾—æœºå™¨å°†éƒ¨åˆ†å™ªéŸ³è®¤ä¸ºæ˜¯ç‰¹å¾ä»è€Œæ‰°ä¹±äº†é¢„è®¾çš„åˆ†ç±»è§„åˆ™ï¼›</p></li>
<li><p>å‡è®¾çš„<strong>æ¨¡å‹æ— æ³•åˆç†å­˜åœ¨</strong>ï¼Œæˆ–è€…è¯´æ˜¯å‡è®¾æˆç«‹çš„æ¡ä»¶å®é™…å¹¶ä¸æˆç«‹ã€‚</p></li>
<li></li>
</ul>
</li>
<li><p>æ€ä¹ˆè§£å†³è¿‡æ‹Ÿåˆï¼ˆé‡ç‚¹ï¼‰ğŸŒŸğŸŒŸğŸŒŸ</p>
<ul>
<li><p>è·å–å’Œä½¿ç”¨<strong>æ›´å¤šçš„æ•°æ®</strong>ï¼ˆæ•°æ®é›†å¢å¼ºï¼‰â€”â€”è§£å†³è¿‡æ‹Ÿåˆçš„æ ¹æœ¬æ€§æ–¹æ³•</p></li>
<li><p><strong>ç‰¹å¾é™ç»´</strong>:äººå·¥é€‰æ‹©ä¿ç•™ç‰¹å¾çš„æ–¹æ³•å¯¹ç‰¹å¾è¿›è¡Œé™ç»´</p></li>
<li><p>åŠ å…¥æ­£åˆ™åŒ–ï¼Œæ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦</p>
<ul>
<li><p>ä¸ºä»€ä¹ˆå‚æ•°è¶Šå°ä»£è¡¨æ¨¡å‹è¶Šç®€å•ï¼Ÿ</p>
<ul>
<li><p>å› ä¸ºå‚æ•°çš„ç¨€ç–ï¼Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šå®ç°äº†ç‰¹å¾çš„é€‰æ‹©ã€‚</p></li>
<li><p>è¶Šå¤æ‚çš„æ¨¡å‹ï¼Œè¶Šæ˜¯ä¼šå°è¯•å¯¹æ‰€æœ‰çš„æ ·æœ¬è¿›è¡Œæ‹Ÿåˆï¼Œç”šè‡³åŒ…æ‹¬ä¸€äº›å¼‚å¸¸æ ·æœ¬ç‚¹ï¼Œè¿™å°±å®¹æ˜“é€ æˆåœ¨è¾ƒå°çš„åŒºé—´é‡Œé¢„æµ‹å€¼äº§ç”Ÿè¾ƒå¤§çš„æ³¢åŠ¨ï¼Œè¿™ç§è¾ƒå¤§çš„æ³¢åŠ¨ä¹Ÿåæ˜ äº†åœ¨è¿™ä¸ªåŒºé—´é‡Œçš„å¯¼æ•°å¾ˆå¤§ï¼Œè€Œ<strong>åªæœ‰è¾ƒå¤§çš„å‚æ•°å€¼æ‰èƒ½äº§ç”Ÿè¾ƒå¤§çš„å¯¼æ•°ã€‚å› æ­¤å¤æ‚çš„æ¨¡å‹ï¼Œå…¶å‚æ•°å€¼ä¼šæ¯”è¾ƒå¤§</strong>ã€‚ å› æ­¤å‚æ•°è¶Šå°‘ä»£è¡¨æ¨¡å‹è¶Šç®€å•</p></li>
</ul>
</li>
</ul>
</li>
<li><p><strong>Dropout</strong></p></li>
<li><p>Early stopping</p></li>
<li><p>äº¤å‰éªŒè¯</p></li>
<li><p>å¢åŠ å™ªå£°</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>å‚æ•°å’Œè¶…å‚æ•°çš„åŒºåˆ«ï¼šparameteræ˜¯learn from dataçš„ hyperparameteræ˜¯ä½ å®šçš„</p>
<ul class="simple">
<li><p>ä¹Ÿå¯ä»¥è®©æ•°æ®å‡ºhyperparameterï¼Œä½†è¿™æ ·çš„è¯å°±optimization problemä¼šå˜å¾—å¤æ‚ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç®€å•çš„å¯ä»¥solveçš„convex optimizationï¼Œæ‰€ä»¥æˆ‘ä»¬ä¼šfixå®ƒ</p></li>
</ul>
<p>è¶…å‚æ•°æœç´¢æ–¹æ³•</p>
<img src="../images/(null)-20220724221446494.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>Grid: there are really three distinct values of one parameter and three distinct values of another parameter, so there are only 3 x 3, 6 different values tried.</p></li>
<li><p>Random: probably there are nine different values, and in this case there are nine different values. when you actually doing random search, youâ€™re actually <strong>trying different values more than the search itself, which has a finite set of values</strong></p>
<ul>
<li><p>å¥½å¤„ï¼š<strong>å¯¹dominatingçš„parameterå¯ä»¥å°è¯•æ›´å¤šçš„å€¼</strong></p></li>
</ul>
</li>
<li><p>Bayesian optimizationï¼šgiven search, figure out the best next point to search</p>
<ul>
<li><p>Bayesian optimization works by constructing a probability distribution of possible functions (gaussian process) that best describe the function you want to optimize.</p>
<ul>
<li><p>Gaussian processæŠŠæ‰€æœ‰æœç´¢è¿‡çš„ç‚¹æ‹Ÿåˆæˆä¸€ä¸ªå‡½æ•°</p></li>
</ul>
</li>
<li><p>A utility function helps explore the parameter space by trading between exploration and exploitation.</p></li>
<li><p>The probability distribution of functions is <em>updated (bayesian) based on observations so far.</em></p></li>
<li><p>åŒºåˆ«ï¼šä¸æ˜¯pre determinedçš„ï¼Œç„¶ågrid å’Œrandomä¸éœ€è¦ä½¿ç”¨æˆ‘ä»¬è¾“å…¥çš„ç»“æœ</p></li>
</ul>
</li>
<li><p>ä¸¤è€…ç»“åˆâ€”â€”Evolutionary optimization</p></li>
<li><p>è¶…å‚é€‰æ‹©æ–¹æ³•ï¼ˆmodel selectionï¼‰ï¼šå¯¹æ¯ä¸ªè¶…å‚strategyï¼Œæˆ‘ä»¬éœ€è¦çŸ¥é“è¿™ä¸ªè¶…å‚æ•°è¡¨ç°æ€ä¹ˆæ ·</p>
<ul>
<li><p>å¦‚æœä½¿ç”¨test dataçš„è¯ï¼Œä¼šå¯¼è‡´overfittingï¼Œæ‰€ä»¥æˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªvalidation datasetæ¥è¡¡é‡effectiveness of a hyperparameter valueï¼Œä»è€Œå®ç°model selectionï¼</p></li>
<li><p>Three-way holdoutï¼šè·Ÿä¹‹å‰çš„split testsetçš„æ–¹æ³•ä¸€æ ·do another splitï¼Œå¯ä»¥random stratifiedä¹‹ç±»çš„</p>
<ul>
<li><p>æ•ˆæœï¼šgive reasonable approximation of test performance on large balanced datasets</p></li>
</ul>
</li>
<li><p>K-fold cross validation (CV)ï¼š æ•°æ®åˆ†æˆkä»½ï¼Œæ‰§è¡Œkæ¬¡ï¼ˆk-1ä»½å½“æ¨¡å‹ å‰©ä¸€ä»½è¯„ä¼°ï¼‰â‡’å¹³å‡è¡¨ç°</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220724221503787.(null)" alt="img" style="width:50%;" />
<ul>
<li><p>Leave-one-out CVï¼šk = nï¼Œ<strong>æ‰€æœ‰çš„æ ·æœ¬éƒ½å•ç‹¬è¢«æ‹¿èµ°ä¸€æ¬¡</strong></p>
<ul class="simple">
<li><p>High variance é€‚ç”¨äºå°æ•°æ®ï¼</p></li>
</ul>
</li>
<li><p>Repeated stratiï¬ed K-fold CVï¼šK-foldçš„åŸºç¡€ä¸Š æ¯æ¬¡development data is <em>shuffled</em> before creating the training &amp; validation datasets</p></li>
<li><p>Stratiï¬ed K-fold CV</p>
<img src="../images/(null)-20220724221510330.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>Stratiï¬ed sampling is used when working with highly imbalanced datasets ï¼</p></li>
</ul>
</li>
<li><p>Random permutation CVï¼šgenerate a user defined number of independent train / test dataset splits. Samples are first shuffled and then split into a pair of train and test sets.</p></li>
<li><p>æ‰€ä»¥ä¼šæ˜¯ä¹±çš„ï¼</p></li>
</ul>
<p><strong>Optimal model training, model evaluation</strong>ï¼šDevelopment data = Training data + validation data â‡’ Model to evaluate</p>
<ul class="simple">
<li><p>The purpose of test dataset is to evaluate the <strong>performance of the ï¬nal optimal model</strong></p></li>
<li><p>Model evaluation is supposed to give a pulse on how the model would perform in the wild.  (æµ‹è¯•é›†çš„è¡¨ç°æ˜¯ä¸ºäº†è¡¡é‡åœ¨unseen data çš„è¡¨ç°ï¼æµ‹è¯•é›†ç›¸å½“äºæ˜¯ä¸€ä¸ªproxy)</p>
<ul>
<li><p>è¿™å°±æ˜¯ä¸ºä»€ä¹ˆåœ¨training processæˆ‘ä»¬å®Œå…¨ä¸touch test set</p></li>
</ul>
</li>
</ul>
<p><img src="../images/(null)-20220724221510063.(null)" alt="img" style="width:33%;" /><img src="../images/(null)-20220724221509687.(null)" alt="img" style="width:33%;" /></p>
<p><strong><code class="docutils literal notranslate"><span class="pre">Model</span> <span class="pre">deployment</span> <span class="pre">Dataset</span></code></strong> ï¼šTraining data + validation data + Test data â‡’ Deployed model</p>
<img src="../images/(null)-20220724222627619.(null)" alt="img" style="width:33%;" />
</div>
</div>
<div class="section" id="knn">
<h2>KNN<a class="headerlink" href="#knn" title="Permalink to this headline">Â¶</a></h2>
<blockquote>
<div><p><a class="reference external" href="https://blog.csdn.net/sinat_30353259/article/details/80901746">https://blog.csdn.net/sinat_30353259/article/details/80901746</a></p>
</div></blockquote>
<p>A simple <strong>non-parametric</strong> supervised learning methodï¼š Assigns the value of the nearest neighbor(s) to the unseen data point</p>
<ul class="simple">
<li><p>Prediction is computationally expensive, while training is trivial</p></li>
<li><p>Generally performs poorly at high dimensions</p></li>
</ul>
<img src="../images/(null)-20220724222726246.(null)" alt="img" style="width:25%;" />
<p>è®¡ç®—è¿™ä¸ªç‚¹è·Ÿæ‰€æœ‰ç‚¹çš„è·ç¦»</p>
<ul class="simple">
<li><p>K = 1çš„æ—¶å€™ ï¼Œç”¨ç¦»ä»–æœ€è¿‘çš„ä¸€ä¸ªçš„labelæ¥é¢„æµ‹</p></li>
</ul>
</div>
<div class="section" id="id5">
<h2>çº¿æ€§å›å½’ç±»<a class="headerlink" href="#id5" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="simple-linear-regression">
<h3>Simple Linear Regression<a class="headerlink" href="#simple-linear-regression" title="Permalink to this headline">Â¶</a></h3>
<p>Assumptions</p>
<ul class="simple">
<li><p>Linearity: Y are linearly dependent on each X variable. ( a linear (technically affine) function of x)</p></li>
<li><p>Independence: Observations are independent to each other. the xâ€™s are independently drawn, and not dependent on each other.</p>
<ul>
<li><p>åä¾‹ï¼šç”¨2å¤©å‰è‚¡ä»·ã€3å¤©å‰è‚¡ä»·é¢„æµ‹ä»Šå¤©çš„</p></li>
</ul>
</li>
<li><p>Homo<strong>scedas</strong>ticityï¼šthe Ïµâ€™s, and thus the yâ€™s, have constant variance.â€”â€”æ®‹å·® distributed arround 0</p></li>
<li><p>Normalityï¼šæ®‹å·®æ­£æ€the Ïµâ€™s are drawn from a Normal distribution (i.e. Normally-distributed errors)</p></li>
</ul>
<p>å…¬å¼</p>
<img src="../images/(null)-20220724222758272.(null)" alt="img" style="width:33%;" />
<p>é—®é¢˜ï¼šæœ‰highly-correlated variablesçš„æ—¶å€™ï¼Œcoefficientå¯èƒ½ä¼šflip</p>
<p>æ”¹è¿›</p>
<ul class="simple">
<li><p>outlierå¾ˆå¤šçš„æ—¶å€™å¯ä»¥è€ƒè™‘log transformation on Y</p></li>
</ul>
</div>
<div class="section" id="ridge-regression">
<h3>Ridge Regression<a class="headerlink" href="#ridge-regression" title="Permalink to this headline">Â¶</a></h3>
<img src="../images/(null)-20220724222758758.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>æ³¨æ„æ˜¯L2æ­£åˆ™åŒ–$<span class="math notranslate nohighlight">\(\operatorname{Min}_{w} \sum_{i=1}^{m}\left(\hat{y}_{i}-y_{i}\right)^{2}+\alpha\|w\|_{2}^{2} \)</span>$</p></li>
<li><p>è§£å‡ºæ¥æ˜¯åœ¨é‡Œé¢å¤šäº†ä¸€ä¸ª$<span class="math notranslate nohighlight">\(\alpha I\)</span><span class="math notranslate nohighlight">\(ï¼š\)</span><span class="math notranslate nohighlight">\(\boldsymbol{w}=(X^{T} X+\alpha I )^{-1} X^{T} y\)</span>$</p>
<ul>
<li><p>Î±è¶Šå¤§ï¼Œä¼šè¶Špush $<span class="math notranslate nohighlight">\(\boldsymbol{w}\)</span>$ to 0</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="lasso-regression">
<h3>Lasso Regression<a class="headerlink" href="#lasso-regression" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>å…¬å¼ï¼š</p></li>
</ul>
<img src="../images/(null)-20220724222758325.(null)" alt="img" style="width:33%;" />
<ul>
<li><p>è·ŸRidgeçš„åŒºåˆ«ï¼š</p>
<img src="../images/(null)-20220724222758875.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>Firstly hit one of the corner 4 points and 1 coefficient become 0 in lasso!</p>
<ul>
<li><p>nç»´åº¦çš„æ—¶å€™å°±ä¼šhit one of the colomn!</p></li>
</ul>
</li>
<li><p>Ridgeçš„æ—¶å€™æœ‰å¯èƒ½æ˜¯0ä½†å¤§éƒ¨åˆ†ä¸æ˜¯ï¼š<a class="reference external" href="https://stats.stackexchange.com/questions/176599/why-will-ridge-regression-not-shrink-some-coefficients-to-zero-like-lasso">https://stats.stackexchange.com/questions/176599/why-will-ridge-regression-not-shrink-some-coefficients-to-zero-like-lasso</a></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="elastic-net-regression">
<h3>Elastic-Net regression<a class="headerlink" href="#elastic-net-regression" title="Permalink to this headline">Â¶</a></h3>
<img src="../images/(null)-20220724222759130.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>Î±ï¼šon whole regularization constrain</p></li>
<li><p>Î»ï¼šcombination weight</p></li>
</ul>
<img src="../images/(null)-20220724222758490.(null)" alt="img" style="width:33%;" />
</div>
<div class="section" id="l1l2">
<h3>L1å’ŒL2çš„åŒºåˆ«<a class="headerlink" href="#l1l2" title="Permalink to this headline">Â¶</a></h3>
<p>L1ï¼ˆLassoï¼‰æ¯”L2ï¼ˆRidgeï¼‰æ›´å®¹æ˜“è·å¾—ç¨€ç–è§£ï¼ŒL2æ¯”L1æ›´å®¹æ˜“è·å¾—smoothè§£</p>
<p><img alt="img" src="../_images/(null)-20220724222758563.(null)" /></p>
<p><img alt="img" src="../_images/(null)-20220724222758573.(null)" /></p>
<p><img alt="img" src="../_images/(null)-20220724222758809.(null)" /></p>
<p>Logistic Regression</p>
</div>
</div>
<div class="section" id="logistic-regression">
<h2>Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="setup">
<h3>æ¨¡å‹Setup<a class="headerlink" href="#setup" title="Permalink to this headline">Â¶</a></h3>
<p><strong>Loss Function</strong></p>
<img src="../images/(null)-20220724223457758.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p><strong>Hinge losså’Œlog lossç›¸æ¯”0-1 losså¯ä»¥æ±‚å¯¼ï¼Œè¿™ä¸¤ä¸ªéƒ½æ˜¯upper bond of the loss functionï¼ˆé»‘è‰²é‚£ä¸ªï¼‰</strong></p></li>
<li><p>å‡è®¾ y = 1</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">0-1</span> <span class="pre">loss</span></code>ï¼šéœ€è¦ w.T &#64; x + b &gt;0 æ‰ä¼šæ˜¯0**</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Hinge</span> <span class="pre">loss</span></code>ï¼šå¦‚æœä½ é¢„æµ‹-4 æ­£ç¡®ä¸º1ï¼Œé‚£å°±æ˜¯1-(1 * (-4)) = 5ï½œå¦‚æœé¢„æµ‹4æ­£ç¡®ä¸º1ï¼Œlossæ˜¯1-1Ã—4 = -3 ç„¶åå†max(0, -3) = 0</p>
<ul>
<li><p><strong>æ€»ä¹‹æ­£ç¡®çš„æ—¶å€™é¢„æµ‹æ¦‚ç‡è¶Šæ¥è¿‘1ï¼Œlossè¶Šæ¥è¿‘0ï¼Œç„¶åè¶Šç¦»è°±çš„è¯ç»™çš„Hingeå°±ä¼šç»™è¶Šé«˜çš„lossï¼Œè€Œä¸æ˜¯0-1é‚£æ ·fixedä½</strong></p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">Logistic</span> <span class="pre">Loss</span></code>: è§ä¸‹æ–¹</p></li>
</ul>
</li>
</ul>
<p>å…·ä½“å…¬å¼ï¼š</p>
<img src="../images/(null)-20220724223457931.(null)" alt="img" style="width:33%;" />
<p>æ¨å¯¼è¿‡ç¨‹ï¼š</p>
<ul class="simple">
<li><p>é¦–å…ˆè¿™æ˜¯ä¸€ç§å¹¿ä¹‰çº¿æ€§æ¨¡å‹ï¼šæŠŠy=1çš„æ¦‚ç‡pç”¨$<span class="math notranslate nohighlight">\(log(\frac{p}{1-p})\)</span><span class="math notranslate nohighlight">\(çš„è”ç³»å‡½æ•°è·Ÿç³»ç»Ÿéƒ¨åˆ†\)</span><span class="math notranslate nohighlight">\(w^Tx + b\)</span>$ç»™è”ç³»åœ¨äº†ä¸€èµ·ï¼Œè¿™ä¸ªfunctionä¼šæ¨å¯¼å‡ºsigmoidï¼š</p></li>
</ul>
<img src="../images/(null)-20220724223457515.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>æ¥ç€æˆ‘ä»¬ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡æ¥optimizeæƒ³è¦æ±‚ï¼š$<span class="math notranslate nohighlight">\(p(y=1 \mid x)=\frac{1}{1+\exp \left(-\left(w^{T} x+b\right)\right)}\)</span>$</p></li>
<li><p><strong>ç„¶åå°±å¾—åˆ°äº†Log Likelihood</strong></p></li>
</ul>
<img src="../images/(null)-20220724223457224.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p><strong>äºæ˜¯æˆ‘ä»¬æŠŠæŸå¤±å‡½æ•°è®¾å®šæˆMin(-LL)</strong></p></li>
</ul>
<img src="../images/(null)-20220724223457293.(null)" alt="img" style="width:33%;" />
<ul>
<li><p>å†åŠ å…¥æ­£åˆ™é¡¹å°±å¾—åˆ°äº†ä¸€ç³»åˆ—ï¼š<strong>Loss function for regularized logistics regressionï¼š</strong></p>
<img src="../images/(null)-20220724223457754.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p>SK learné‡Œé¢æ˜¯Cï¼Œé«˜çš„$<span class="math notranslate nohighlight">\(C = \frac{1}{\alpha}\)</span>$ç›¸å½“äºæ²¡æœ‰å¯¹å‚æ•°é™åˆ¶è§æ•ˆ</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id6">
<h3><strong>å¤šåˆ†ç±»é—®é¢˜å¸¸è§„è§£å†³æ–¹æ¡ˆ</strong><a class="headerlink" href="#id6" title="Permalink to this headline">Â¶</a></h3>
<p><strong>å åŠ binary</strong></p>
<ul class="simple">
<li><p><strong>OVR (One vs Rest)</strong></p></li>
</ul>
<img src="../images/(null)-20220724223459288.(null)" alt="img" style="width:33%;" />
<ul class="simple">
<li><p><strong>OVO (One vs One)</strong></p></li>
</ul>
<img src="../images/(null)-20220724223458436.(null)" alt="img" style="width:33%;" />
<ul>
<li><p>å»ºå¥½å‡ ä¸ªbinary classificationï¼Œå¦‚æœå¤§å¤šæ•°modelè¯´ä½ æ˜¯class Xå°±æ˜¯é‚£ä¸ª</p></li>
<li><p>å¯¹æ¯”</p>
<img src="../images/(null)-20220724223458032.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>æ¯”å¦‚ä¸‰æ¡çº¿ä¸­é—´çš„åœ°æ–¹ï¼Œä¸€äººè¯´ä½ æ˜¯ä¸€ä¸ªclassï¼Œæ˜¯uncertainty</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="logistics">
<h3><strong>Logisticsè§£å†³å¤šåˆ†ç±»é—®é¢˜</strong><a class="headerlink" href="#logistics" title="Permalink to this headline">Â¶</a></h3>
<p>ç›´æ¥extend</p>
<img src="../images/(null)-20220724223459022.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>å› æ­¤å¯èƒ½ä¼šæ¯”ç”¨ovoå’Œovrçš„SVMè¦å¥½ï¼å› ä¸ºä»–ç›´æ¥globally optimize all the log odds of ratio. It actually solves it as a multiclass classification problem!</p></li>
</ul>
</div>
</div>
<div class="section" id="svm">
<h2>SVM<a class="headerlink" href="#svm" title="Permalink to this headline">Â¶</a></h2>
<ul class="simple">
<li><p>Hard/soft maginå«ä¹‰ï¼š</p></li>
</ul>
<img src="../images/(null)-20220724224339951.(null)" alt="img" style="width:50%;" />
<div class="section" id="primal-hard-margin">
<h3>Primal + Hard-margin<a class="headerlink" href="#primal-hard-margin" title="Permalink to this headline">Â¶</a></h3>
<img src="../images/(null)-20220724224337505.(null)" alt="img" style="width:50%;" />
<ul>
<li><p>**Objective functionçš„å«ä¹‰ï¼š**optimize åˆ’åˆ†è¶…å¹³é¢çš„ maximum margin ï¼ˆæœ€å¤§é—´éš”ï¼‰=$<span class="math notranslate nohighlight">\(\frac{2}{\|w\|_{2}^{2}}\)</span><span class="math notranslate nohighlight">\(ï¼Œä¹Ÿå°±æ˜¯minimize\)</span><span class="math notranslate nohighlight">\(\frac{\|w\|_{2}^{2}}{2}\)</span>$</p></li>
<li><p>é™åˆ¶æ¡ä»¶çš„å«ä¹‰ï¼š</p>
<ul>
<li><p>ç‚¹(xi, yi)åˆ°ç›´çº¿$<span class="math notranslate nohighlight">\(y=w^{T} x+b\)</span><span class="math notranslate nohighlight">\(çš„è·ç¦»\)</span><span class="math notranslate nohighlight">\(\frac{ |w^{T} x_{i}+b-yi|}{{\|w\|_{2}^{2}}} \geq 1\)</span>$</p>
<div class="math notranslate nohighlight">
\[\Rightarrow { |w^{T} x_{i}+b-yi|} \geq {{\|w\|_{2}^{2}}}\]</div>
<div class="math notranslate nohighlight">
\[\Rightarrow w^{T} x_{i}+b \geq y_i \text{ or } w^{T} x_{i}+b \leq -y_i\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\Rightarrow \begin{cases}\omega^{T} x_{i}+b \geq+1, &amp; y_{i}=+1 \\ \omega^{T} x_{i}+b \leq-1, &amp; y_{i}=-1\end{cases}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\Rightarrow y_{i}\left(w^{T} x_{i}+b\right) \geq 1\]</div>
<ul class="simple">
<li><p>ä»–ä¹‹ä¸Šé‚£ä¹ˆè¦&gt;1ï¼Œå¦‚æœåœ¨å®ƒä¹‹ä¸‹è¦&gt;-1ï¼Œä¹Ÿå°±æ˜¯*y1 &gt; 1</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="primal-dual">
<h3>Primal + Dual<a class="headerlink" href="#primal-dual" title="Permalink to this headline">Â¶</a></h3>
<img src="../images/(null)-20220724224339721.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>**Linkï¼š**é€šè¿‡å¯¹wå’Œbæ±‚å¯¼ æŠŠç»“æœä»£å›loss functionå°±å¾—åˆ°äº†å¯¹å¶é—®é¢˜</p></li>
<li><p>ç‰¹ç‚¹ï¼šä¹‹å‰éœ€è¦è§£wå’Œbã€ç°åœ¨åªéœ€è¦è§£Î±</p>
<ul>
<li><p>Î± ä¸€ä¸ªmç»´å‘é‡ï¼ˆmæ˜¯æ ·æœ¬çš„sizeï¼Œnæ˜¯å˜é‡ä¸ªæ•°ï¼‰</p></li>
<li><p>ä¹‹å‰è§£çš„æ˜¯<strong>ä¸€ä¸ªn_featureç»´é—®é¢˜ï¼ç°åœ¨å˜æˆn_sampleç»´é—®é¢˜</strong></p>
<ul>
<li><p>å¦‚æœå°‘é‡featureçš„æ—¶å€™ Primalé—®é¢˜è§£çš„æ›´å¿«ï¼ˆå¤§å¤šæ•°æƒ…å†µï¼‰</p></li>
<li><p>å¦‚æœæœ‰å¤§é‡featureçš„è¯ï¼ŒDualè§£çš„æ›´å¿«</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ç›®çš„</p>
<ul>
<li><p>dualå¯ä»¥æ›´å®¹æ˜“ç§»åŠ¨åˆ°non- linearçš„åœºæ™¯é‡Œ</p></li>
</ul>
</li>
<li><p>æ•ˆæœï¼šè¿™ä¸ªç­‰å¼ä¼šä¸€ç›´æ˜¯0 <span class="math notranslate nohighlight">\(\alpha_{i}\left(1-y_{i}\left(w^{T} x_{i}+b\right)\right)=0\)</span></p>
<ul>
<li><p>å¯¹äºéæ”¯æŒå‘é‡ï¼šÎ±i=0</p></li>
<li><p>åªæœ‰è§£å‡ºæ¥çš„æ”¯æŒå‘é‡æ»¡è¶³ï¼šÎ±i != 0,$<span class="math notranslate nohighlight">\(y_{i}\left(w^{T} x_{i}+b\right) = 1\)</span>$</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="primal-soft-margin">
<h3>Primal + Soft- margin<a class="headerlink" href="#primal-soft-margin" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>é¦–å…ˆÎ¾ introduce lossï¼Œç„¶åå†é€šè¿‡æ•°å­¦å˜æ¢æŠŠÎ¾è§£å‡ºæ¥ï¼Œç„¶åå¾—åˆ°çš„å°±æ˜¯Hinge loss</p></li>
</ul>
<p><img src="../images/(null)-20220724224337896.(null)" alt="img" style="width:50%;" /><img src="../images/(null)-20220724224336553.(null)" alt="img" style="width:50%;" /></p>
<ul class="simple">
<li><p>Cçš„ä½œç”¨ï¼šæ§åˆ¶errorçš„é‡è¦æ€§â€”â€”Cè¶Šå¤§ï¼Œmarginè¶Šä¸é‡è¦å°±è¶Šå°ï½œ<strong>Cè¶Šå°ï¼Œmarginè¶Šé‡è¦å°±è¶Šå¤§</strong></p></li>
</ul>
<img src="../images/(null)-20220724224337202.(null)" alt="img" style="width:50%;" />
</div>
<div class="section" id="dual-soft-margin">
<h3>Dual + Soft-margin<a class="headerlink" href="#dual-soft-margin" title="Permalink to this headline">Â¶</a></h3>
<img src="../images/(null)-20220724224337040.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>ä¹Ÿå¯ä»¥åŠ å…¥æ­£åˆ™åŒ–ï¼š</p></li>
</ul>
<img src="../images/(null)-20220724224337444.(null)" alt="img" style="width:50%;" />
<ul>
<li><p>é¢„æµ‹çš„æ–¹æ³•ï¼š$<span class="math notranslate nohighlight">\(\operatorname{sign}\left(\sum_{i} \alpha_{i} y_{i}\left(x \cdot x_{i}\right)+b\right)\)</span>$</p>
<ul>
<li><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}\alpha_i$$ï¼šç¬¬iä¸ªsupport vectorçš„dual coefficient
  - $$x_i, y_i$$ï¼šç¬¬iä¸ªsupport vectorçš„åæ ‡\\#### Kernel Function\\**Kernel function ğ•‚(ğ’™;ğ’™)** å¯ä»¥ **estimates inner product between two points in the projected space.**\\- å‡è®¾æœ‰ä¸€ä¸ªmagic function ğ“(ğ’™)ï¼Œå¯ä»¥ projects data to **high-dimensional space**\\  è¿˜æ˜¯ç»™ä¸¤ä¸ªç‚¹è¿”å›è·ç¦»ï¼ä½†æ˜¯è¿™ä¸ªè·ç¦»æ˜¯åœ¨é«˜ç»´ç©ºé—´ä¸Šçš„ æ‰€ä»¥å¯èƒ½åœ¨è¿™ä¸ªç»´ä¸Šçœ‹åˆ°çš„ä¸ä¸€æ ·\\&lt;img src=&quot;../images/(null)-20220724224338320.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- ä½†æˆ‘ä»¬å…³å¿ƒçš„æ˜¯ä¸¤ä¸ªğ“(ğ’™i) Ã— ğ“(ğ’™j) çš„ç»“æœï¼Œè€Œä¸æ˜¯ğ“æœ¬èº«ï¼Œæ‰€ä»¥å¯ä»¥ä½¿ç”¨ä¸€ä¸ªKernel trickï¼Œå‡è®¾**ğ•‚**æ˜¯ç›´æ¥ä½œç”¨åœ¨dot productä¸Šé¢çš„ï¼Œä»è€Œåªéœ€è¦assume ğ“çš„å­˜åœ¨å°±å¯ä»¥äº†\\&lt;img src=&quot;../images/(null)-20220724224337915.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- å› æ­¤è¿™ä¸ªé—®é¢˜å°±å˜æˆäº†ï¼š\\&lt;img src=&quot;../images/(null)-20220724224338928.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- ç±»å‹ï¼š\\&lt;img src=&quot;../images/(null)-20220724224338479.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- Linear Kernelï¼šæ²¡åšå•¥ï¼
- Polynomialï¼š
  - æ¯”å¦‚ä¸€ä¸ªä¸€ç»´æ˜ å°„åˆ°ä¸‰ç»´çš„å‡½æ•°$$\phi\left(x\right)=\left(x, \sqrt{2} x, 1\right)$$ï¼Œä»–çš„æ•ˆæœæ˜¯$$\phi\left(x_{i}\right) \cdot \phi\left(x_{j}\right)=\left(x_{i}, \sqrt{2} x_{i}, 1\right) \cdot \left(x_{j}, \sqrt{2} x_{j}, 1\right) = \left(x_{i} x_{j}+1\right)^{2}\end{aligned}\end{align} \]</div>
</li>
<li><p>ä»–å…¶å®ç­‰ä»·äºä¸€ä¸ªPolynomialçš„Kernel Function$<span class="math notranslate nohighlight">\(\mathbb{K}\left(x_{i}, x_{j}\right)=\left(x_{i} x_{j}+1\right)^{2}\)</span>$å°±å¯ä»¥ç»™å‡ºé«˜ç»´ç©ºé—´Ï†ä¸‹çš„ç‚¹ä¹˜ç»“æœäº†</p></li>
<li><p>è®¡ç®—å¤æ‚åº¦ä¹Ÿä½å¤šäº†ï¼</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220724224338277.(null)" alt="img" style="width:50%;" />
<ul>
<li><p>RBF(Radial Basis Function) Kernelï¼šå¦‚æœå……åˆ†tune Î³ enoughï¼ŒèƒŒåå®é™…ä¸Šæ˜¯ä¸€ä¸ªinfinite diminutionalçš„spaceï¼Œä»è€Œalwayså¯ä»¥separate dataï¼å¯ä»¥perfectly separate data.</p>
<p>RBDä¸»è¦ç”¨äºçº¿æ€§ä¸å¯åˆ†çš„æƒ…å½¢</p>
<ul class="simple">
<li><p>ä¸¤ä¸ªç‚¹åœ¨é«˜ç»´ç©ºé—´è¶Šæ¥è¿‘ï¼Œå°±ä¼šæœ‰è¶Šé«˜çš„valuesï½œSpread out çš„ç‚¹ä¼šsmaller</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">Î³</span></code>ä¼šæ§åˆ¶ how the function value decays with distanceï¼ˆÎ³è¶Šå¤§çš„è¯ï¼Œè·ç¦»è¶Šè¿œçš„sample å€¼ä¸‹é™å¾—è¶Šå¿«ï¼‰</p></li>
<li><p>e.g</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220724224338727.(null)" alt="img" style="width:50%;" />
<p><strong>Kernelé€‰æ‹©çš„æ€è·¯ï¼š</strong></p>
<p>ï¼ˆ1ï¼‰å¦‚æœç‰¹å¾ç»´æ•°å¾ˆé«˜ï¼Œå¾€å¾€çº¿æ€§å¯åˆ†ï¼ˆSVMè§£å†³éçº¿æ€§åˆ†ç±»é—®é¢˜çš„æ€è·¯å°±æ˜¯å°†æ ·æœ¬æ˜ å°„åˆ°æ›´é«˜ç»´çš„ç‰¹å¾ç©ºé—´ä¸­ï¼‰ï¼Œå¯ä»¥é‡‡ç”¨LRæˆ–è€…çº¿æ€§æ ¸çš„SVMï¼›</p>
<p>ï¼ˆ2ï¼‰å¦‚æœæ ·æœ¬æ•°é‡å¾ˆå¤šï¼Œç”±äºæ±‚è§£æœ€ä¼˜åŒ–é—®é¢˜çš„æ—¶å€™ï¼Œç›®æ ‡å‡½æ•°æ¶‰åŠä¸¤ä¸¤æ ·æœ¬è®¡ç®—å†…ç§¯ï¼Œä½¿ç”¨é«˜æ–¯æ ¸æ˜æ˜¾è®¡ç®—é‡ä¼šå¤§äºçº¿æ€§æ ¸ï¼Œæ‰€ä»¥æ‰‹åŠ¨æ·»åŠ ä¸€äº›ç‰¹å¾ï¼Œä½¿å¾—çº¿æ€§å¯åˆ†ï¼Œç„¶åå¯ä»¥ç”¨LRæˆ–è€…çº¿æ€§æ ¸çš„SVMï¼›</p>
<p>ï¼ˆ3ï¼‰å¦‚æœä¸æ»¡è¶³ä¸Šè¿°ä¸¤ç‚¹ï¼Œå³<strong>ç‰¹å¾ç»´æ•°å°‘ï¼Œæ ·æœ¬æ•°é‡æ­£å¸¸</strong>ï¼Œå¯ä»¥ä½¿ç”¨é«˜æ–¯æ ¸çš„SVMã€‚</p>
</div>
</div>
<div class="section" id="ensemble-methods">
<h2>Ensemble Methods<a class="headerlink" href="#ensemble-methods" title="Permalink to this headline">Â¶</a></h2>
<p>Baggingå’ŒBoostingéƒ½æ˜¯ensembleï¼Œå°±æ˜¯æŠŠå¼±åˆ†ç±»å™¨ç»„è£…æˆå¼ºåˆ†ç±»å™¨çš„æ–¹æ³•</p>
<p><strong>Motivation</strong></p>
<ul class="simple">
<li><p>The decision trees are highly <strong>unstable</strong> and can structurally change with slight variation in input data</p></li>
<li><p>Decision trees perform poorly on continuous outcomes (regression) due to limited model capacity.</p></li>
</ul>
<p><strong>å®šä¹‰</strong></p>
<ul class="simple">
<li><p>Several weak/simple learners are <strong>combined</strong> to make the ï¬nal prediction</p></li>
<li><p>ç›®çš„ï¼šGenerally ensemble methods aim to <strong>reduce model variance</strong></p>
<ul>
<li><p>Like have multiple such outputs and then you take an average of that.</p></li>
</ul>
</li>
<li><p>æ•ˆæœï¼šEnsemble methods improve performance especially if the individual learners are not correlated.</p>
<ul>
<li><p><strong>took a different or a different perspective</strong> of the data itself.</p></li>
<li><p>é‡‡æ ·ä¼šâ‡’æˆåŠŸ</p>
<ul>
<li><p>if you had one or two highly <strong>dominant features</strong> that probably is saying is highly correlated to your outcome.</p>
<ul>
<li><p>Suppose every tree that a building has access to that feature. Probably every tree is going to look very similar right now.</p></li>
<li><p>Assume that you actually had some trees <strong>not have access to that feature. Then theyâ€™ll start looking at the data from a different perspective and theyâ€™ll probably build trees that are giving you another notion of your data center. And itâ€™s not dominated by these one or two features that are are highly correlated to the outcome.</strong></p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ç±»å‹ï¼šDepending on training sample construction and output aggregation, there are two categories:</p>
<ul>
<li><p>Bagging (Bootstrap aggregation)</p></li>
<li><p>Boosting</p></li>
</ul>
</li>
</ul>
<div class="section" id="bagging">
<h3>Bagging<a class="headerlink" href="#bagging" title="Permalink to this headline">Â¶</a></h3>
<p>Baggingçš„ä¸»è¦ç›®çš„æ˜¯å‡å°‘æ–¹å·®</p>
<ul>
<li><p>å¤šæ¬¡é‡‡æ ·ï¼Œè®­ç»ƒå¤šä¸ªåˆ†ç±»å™¨Several training samples (of same size) are created by sampling the dataset <strong>with replacement</strong></p>
<ul>
<li><p>ä»åŸå§‹æ ·æœ¬é›†ä¸­æŠ½å–è®­ç»ƒé›†ã€‚æ¯è½®ä»åŸå§‹æ ·æœ¬é›†ä¸­ä½¿ç”¨Bootstrapingçš„æ–¹æ³•æŠ½å–nä¸ªè®­ç»ƒæ ·æœ¬ï¼ˆåœ¨è®­ç»ƒé›†ä¸­ï¼Œæœ‰äº›æ ·æœ¬å¯èƒ½è¢«å¤šæ¬¡æŠ½å–åˆ°ï¼Œè€Œæœ‰äº›æ ·æœ¬å¯èƒ½ä¸€æ¬¡éƒ½æ²¡æœ‰è¢«æŠ½ä¸­ï¼‰ã€‚å…±è¿›è¡Œkè½®æŠ½å–ï¼Œå¾—åˆ°kä¸ªè®­ç»ƒé›†ã€‚ï¼ˆkä¸ªè®­ç»ƒé›†ä¹‹é—´æ˜¯ç›¸äº’ç‹¬ç«‹çš„ï¼‰</p>
<p>there could be samples that are <strong>repeated</strong> and there are samples that <strong>do not get picked at all.</strong></p>
<img src="../images/(null)-20220725100730752.(null)" alt="img" style="width: 50%;" />
</li>
<li><p>æ¯æ¬¡ä½¿ç”¨ä¸€ä¸ªè®­ç»ƒé›†å¾—åˆ°ä¸€ä¸ªæ¨¡å‹ï¼Œkä¸ªè®­ç»ƒé›†å…±å¾—åˆ°kä¸ªæ¨¡å‹ã€‚ï¼ˆæ³¨ï¼šè¿™é‡Œå¹¶æ²¡æœ‰å…·ä½“çš„åˆ†ç±»ç®—æ³•æˆ–å›å½’æ–¹æ³•ï¼Œæˆ‘ä»¬å¯ä»¥æ ¹æ®å…·ä½“é—®é¢˜é‡‡ç”¨ä¸åŒçš„åˆ†ç±»æˆ–å›å½’æ–¹æ³•ï¼Œå¦‚å†³ç­–æ ‘ã€æ„ŸçŸ¥å™¨ç­‰ï¼‰</p></li>
</ul>
</li>
<li><p>åˆ†ç±»é—®é¢˜ï¼šå¯¹åˆ†ç±»é—®é¢˜ï¼šå°†ä¸Šæ­¥å¾—åˆ°çš„kä¸ªæ¨¡å‹é‡‡ç”¨æŠ•ç¥¨çš„æ–¹å¼å¾—åˆ°åˆ†ç±»ç»“æœ</p>
<p>å¯¹å›å½’é—®é¢˜ï¼Œè®¡ç®—ä¸Šè¿°æ¨¡å‹çš„å‡å€¼ä½œä¸ºæœ€åçš„ç»“æœã€‚ï¼ˆæ‰€æœ‰æ¨¡å‹çš„é‡è¦æ€§ç›¸åŒï¼‰</p>
</li>
</ul>
</div>
<div class="section" id="boosting">
<h3>Boosting<a class="headerlink" href="#boosting" title="Permalink to this headline">Â¶</a></h3>
<p>Boostingçš„ç›®çš„ä¸»è¦æ˜¯å‡å°‘åå·®</p>
<ul>
<li><p>Includes a family of ML algorithms that convert weak learners to strong ones.</p>
<ul>
<li><p>The weak learners are learned sequentially with early learners ï¬tting simple models to the data and then analysing data for errors.</p></li>
<li><p>When an input is misclassiï¬ed by one tree, its output is adjusted so that next tree is more likely to learn it correctly.</p>
<p>æ¯ä¸ªtreeçš„ç›®æ ‡æ˜¯do better on the misclassify samples of the previous.</p>
<ul class="simple">
<li><p>ä¹‹å‰åˆ†å¯¹çš„down weight</p></li>
<li><p>ä¹‹å‰åˆ†é”™çš„out weight</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220725100731093.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>æœ€å combined by a weighted average of each of those trees. ä½†è¿™ä¸ªæƒé‡è·Ÿæ¨¡å‹æœ‰å…³ï¼</p></li>
</ul>
<blockquote>
<div><p>Random Forestæ˜¯ç›´æ¥averageï¼</p>
</div></blockquote>
<ul class="simple">
<li><p>ç®—æ³•æµç¨‹ï¼š</p>
<ul>
<li><p>ç»™å®šåˆå§‹è®­ç»ƒæ•°æ®ï¼Œç”±æ­¤è®­ç»ƒå‡ºç¬¬ä¸€ä¸ªåŸºå­¦ä¹ å™¨ï¼›</p></li>
<li><p>æ ¹æ®åŸºå­¦ä¹ å™¨çš„è¡¨ç°å¯¹æ ·æœ¬è¿›è¡Œè°ƒæ•´ï¼Œåœ¨ä¹‹å‰å­¦ä¹ å™¨åšé”™çš„æ ·æœ¬ä¸ŠæŠ•å…¥æ›´å¤šå…³æ³¨ï¼›</p></li>
<li><p>ç”¨è°ƒæ•´åçš„æ ·æœ¬ï¼Œè®­ç»ƒä¸‹ä¸€ä¸ªåŸºå­¦ä¹ å™¨ï¼›</p></li>
<li><p>é‡å¤ä¸Šè¿°è¿‡ç¨‹Tæ¬¡ï¼Œå°†Tä¸ªå­¦ä¹ å™¨åŠ æƒç»“åˆã€‚</p></li>
</ul>
</li>
<li><p>é€šè¿‡æé«˜é‚£äº›åœ¨å‰ä¸€è½®è¢«å¼±åˆ†ç±»å™¨åˆ†é”™æ ·ä¾‹çš„æƒå€¼ï¼Œå‡å°å‰ä¸€è½®åˆ†å¯¹æ ·ä¾‹çš„æƒå€¼ï¼Œæ¥ä½¿å¾—åˆ†ç±»å™¨å¯¹è¯¯åˆ†çš„æ•°æ®æœ‰è¾ƒå¥½çš„æ•ˆæœã€‚</p></li>
<li><p>é€šè¿‡ä»€ä¹ˆæ–¹å¼æ¥ç»„åˆå¼±åˆ†ç±»å™¨ï¼Ÿ</p>
<ul>
<li><p>é€šè¿‡åŠ æ³•æ¨¡å‹å°†å¼±åˆ†ç±»å™¨è¿›è¡Œçº¿æ€§ç»„åˆï¼Œæ¯”å¦‚AdaBoosté€šè¿‡åŠ æƒå¤šæ•°è¡¨å†³çš„æ–¹å¼ï¼Œå³å¢å¤§é”™è¯¯ç‡å°çš„åˆ†ç±»å™¨çš„æƒå€¼ï¼ŒåŒæ—¶å‡å°é”™è¯¯ç‡è¾ƒå¤§çš„åˆ†ç±»å™¨çš„æƒå€¼ã€‚</p></li>
<li><p>è€Œæå‡æ ‘é€šè¿‡æ‹Ÿåˆæ®‹å·®çš„æ–¹å¼é€æ­¥å‡å°æ®‹å·®ï¼Œå°†æ¯ä¸€æ­¥ç”Ÿæˆçš„æ¨¡å‹å åŠ å¾—åˆ°æœ€ç»ˆæ¨¡å‹ã€‚</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="baggingboosting">
<h3>Baggingå’ŒBoostingçš„åŒºåˆ«<a class="headerlink" href="#baggingboosting" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>1ï¼‰æ ·æœ¬é€‰æ‹©ä¸Šï¼š</p>
<ul>
<li><p>Baggingï¼šè®­ç»ƒé›†æ˜¯åœ¨åŸå§‹é›†ä¸­æœ‰æ”¾å›é€‰å–çš„ï¼Œä»åŸå§‹é›†ä¸­é€‰å‡ºçš„å„è½®è®­ç»ƒé›†ä¹‹é—´æ˜¯ç‹¬ç«‹çš„ã€‚</p></li>
<li><p>Boostingï¼šæ¯ä¸€è½®çš„è®­ç»ƒé›†ä¸å˜ï¼Œåªæ˜¯è®­ç»ƒé›†ä¸­æ¯ä¸ªæ ·ä¾‹åœ¨åˆ†ç±»å™¨ä¸­çš„æƒé‡å‘ç”Ÿå˜åŒ–ã€‚è€Œæƒå€¼æ˜¯æ ¹æ®ä¸Šä¸€è½®çš„åˆ†ç±»ç»“æœè¿›è¡Œè°ƒæ•´ã€‚</p></li>
</ul>
</li>
<li><p>2ï¼‰æ ·ä¾‹æƒé‡ï¼š</p>
<ul>
<li><p>Baggingï¼šä½¿ç”¨å‡åŒ€å–æ ·ï¼Œæ¯ä¸ªæ ·ä¾‹çš„æƒé‡ç›¸ç­‰</p></li>
<li><p>Boostingï¼šæ ¹æ®é”™è¯¯ç‡ä¸æ–­è°ƒæ•´æ ·ä¾‹çš„æƒå€¼ï¼Œé”™è¯¯ç‡è¶Šå¤§åˆ™æƒé‡è¶Šå¤§ã€‚</p></li>
</ul>
</li>
<li><p>3ï¼‰é¢„æµ‹å‡½æ•°ï¼š</p>
<ul>
<li><p>Baggingï¼šæ‰€æœ‰é¢„æµ‹å‡½æ•°çš„æƒé‡ç›¸ç­‰ã€‚</p></li>
<li><p>Boostingï¼šæ¯ä¸ªå¼±åˆ†ç±»å™¨éƒ½æœ‰ç›¸åº”çš„æƒé‡ï¼Œå¯¹äºåˆ†ç±»è¯¯å·®å°çš„åˆ†ç±»å™¨ä¼šæœ‰æ›´å¤§çš„æƒé‡ã€‚</p></li>
</ul>
</li>
<li><p>4ï¼‰å¹¶è¡Œè®¡ç®—ï¼š</p>
<ul>
<li><p>Baggingï¼šå„ä¸ªé¢„æµ‹å‡½æ•°å¯ä»¥å¹¶è¡Œç”Ÿæˆ</p></li>
<li><p>Boostingï¼šå„ä¸ªé¢„æµ‹å‡½æ•°åªèƒ½é¡ºåºç”Ÿæˆï¼Œå› ä¸ºåä¸€ä¸ªæ¨¡å‹å‚æ•°éœ€è¦å‰ä¸€è½®æ¨¡å‹çš„ç»“æœã€‚</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="stacking">
<h3>Stacking<a class="headerlink" href="#stacking" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>å¤šæ¬¡é‡‡æ ·ï¼Œè®­ç»ƒå¤šä¸ªåˆ†ç±»å™¨ï¼Œå°†è¾“å‡ºä½œä¸ºæœ€åçš„è¾“å…¥ç‰¹å¾</p></li>
<li><p>å°†è®­ç»ƒå¥½çš„æ‰€æœ‰åŸºæ¨¡å‹å¯¹è®­ç»ƒé›†è¿›è¡Œé¢„æµ‹ï¼Œç¬¬ä¸ª<span class="math notranslate nohighlight">\(i\)</span>åŸºæ¨¡å‹å¯¹ç¬¬<span class="math notranslate nohighlight">\(i\)</span>ä¸ªè®­ç»ƒæ ·æœ¬çš„é¢„æµ‹å€¼å°†ä½œä¸ºæ–°çš„è®­ç»ƒé›†ä¸­ç¬¬<span class="math notranslate nohighlight">\(i\)</span>ä¸ªæ ·æœ¬çš„ç¬¬<span class="math notranslate nohighlight">\(i\)</span>ä¸ªç‰¹å¾å€¼ï¼Œæœ€ååŸºäºæ–°çš„è®­ç»ƒé›†è¿›è¡Œè®­ç»ƒã€‚åŒç†ï¼Œé¢„æµ‹çš„è¿‡ç¨‹ä¹Ÿè¦å…ˆç»è¿‡æ‰€æœ‰åŸºæ¨¡å‹çš„é¢„æµ‹å½¢æˆæ–°çš„æµ‹è¯•é›†ï¼Œæœ€åå†å¯¹æµ‹è¯•é›†è¿›è¡Œé¢„æµ‹ã€‚</p></li>
<li><p>stackingå¸¸è§çš„ä½¿ç”¨æ–¹å¼ï¼š</p>
<ul>
<li><p>ç”±k-NNã€éšæœºæ£®æ—å’Œæœ´ç´ è´å¶æ–¯åŸºç¡€åˆ†ç±»å™¨ç»„æˆï¼Œå®ƒçš„é¢„æµ‹ç»“æœç”±ä½œä¸ºå…ƒåˆ†ç±»å™¨çš„é€»å›å½’ç»„åˆã€‚</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="trees">
<h2>Trees<a class="headerlink" href="#trees" title="Permalink to this headline">Â¶</a></h2>
<div class="section" id="decision-trees">
<h3>Decision Trees<a class="headerlink" href="#decision-trees" title="Permalink to this headline">Â¶</a></h3>
<p><strong>ç‰¹ç‚¹</strong></p>
<ul class="simple">
<li><p>Greedy algorithm</p></li>
<li><p>Applicable to both classiï¬cation &amp; regression problems</p>
<ul>
<li><p>Regressionçš„è¯åªèƒ½æ˜¯finiteçš„æ•°å€¼</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220724230711129.(null)" alt="img" style="width:67%;" />
<ul class="simple">
<li><p>Easy to interpret &amp; deployï¼šå¯ä»¥è®©åˆ«äººhandwrite</p></li>
<li><p>Non-linear decision boundary</p>
<ul>
<li><p>treeç›¸å½“äºæ˜¯åœ¨é«˜ç»´ç©ºé—´çš„å¥½å‡ ä¸ªç»´åº¦ä¸Šå»splitting up the space</p></li>
</ul>
</li>
<li><p>Minimal preprocessing</p>
<ul>
<li><p>missing å’Œ categoricalå¯ä»¥handleï¼</p></li>
</ul>
</li>
<li><p>Invariant to scale of data</p>
<ul>
<li><p>Invariant to the scale of the data because it is it is <em>not really looking at at absolute values of the of the features</em>. More on the ranges of the features.</p></li>
</ul>
</li>
</ul>
<p><strong>Framework</strong></p>
<img src="../images/(null)-20220724230711222.(null)" alt="img" style="width:67%;" />
<p><strong>Loss</strong></p>
<p>åˆ†ç±»ä»»åŠ¡ï¼š</p>
<ul>
<li><p>Impurityè¡¡é‡ï¼š<span class="math notranslate nohighlight">\(Entropy(node)=-\sum_{i=1}^{K} p_{i} \log _{2} p_{i} \)</span> ï½œ <span class="math notranslate nohighlight">\(Gini Index(node)=1-\sum_{i=1}^{K} p_{i}^{2}\)</span>$</p>
<ul>
<li><div class="math notranslate nohighlight">
\[p_{i}=\text{probability of beloing to a class} =\frac{\text{number of samples of the class}}{\text{total number of samples in that node}}\]</div>
</li>
<li><p>ä¾‹å­</p>
<p><img src="../images/(null)-20220724230710858.(null)" alt="img" style="width:33%;" /><img src="../images/(null)-20220724230711014.(null)" alt="img" style="width:33%;" /></p>
</li>
<li><p>ä¸¤è€…åŒºåˆ«ä¸å¤§â€”â€”giniçš„æœ€å¤§å€¼æ˜¯1ï¼Œentropyçš„æœ€å¤§å€¼æ˜¯0.5</p></li>
</ul>
</li>
<li><p>Information Gainï¼ˆè¯„ä¼°ä¿¡æ¯å¢ç›ŠInformation Gainå¯¹ç¡®å®šçš„featureå’Œç¡®å®šçš„split thresholdï¼‰</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Expectation_value">Expected</a> information gain $<span class="math notranslate nohighlight">\(IG(T, a)=H(T)-H(T \mid a)\)</span>$ is the reduction in <a class="reference external" href="https://en.wikipedia.org/wiki/Information_entropy">information entropy</a> <em>Î—</em> from a prior state to a state that takes some information as given. ä¹Ÿå°±æ˜¯ä¸çº¯åº¦çš„ä¸‹é™</p>
<ul>
<li><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}H(T)$$ï¼ša priori Shannon entropy 
  - $$H(T\mid a) = \sum_{v \in vals(a)} \frac{\left|S_{a}(v)\right|}{|T|}  H\left(S_{a}(v)\right)$$ï¼šæ ·æœ¬å æ¯”ä¸ºæƒçš„åŠ æƒå¹³å‡entropy
    - $$\frac{\left|S_{a}(v)\right|}{|T|} $$: å…¶å®åˆ†åˆ°açš„å æ¯”ï¼ˆæƒé‡ï¼‰ï¼Œæ‹¿è¿™ä¸ªå»åŠ æƒå¹³å‡
      - $$S_{a}(v)=\left\{x \in T \mid x_{a}=v\right\}$$è¡¨ç¤ºTä¸­åˆ†è£‚åˆ°aé‡Œé¢çš„nodeç»„æˆçš„é›†åˆ
    - $$H\left(S_{a}(v)\right)$$ï¼š$$S_{a}(v)$$çš„Entropy
  - e.g\\  &lt;img src=&quot;../images/(null)-20220724231640012.(null)&quot; alt=&quot;img&quot; style=&quot;width:33%;&quot; /&gt;\\  - Numericalçš„ï¼š An exhaustive **search across all features and values** to ï¬nd the (feature, threshold) combination with the highest information gain (IG).\\  &lt;img src=&quot;../images/(null)-20220724231943423.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\  - Categoricalçš„ï¼š\\    - An exhaustive **search across all categorical features** and their categories to ï¬nd the(feature, subsets) combination with the highest information gain (IG).\\      &lt;img src=&quot;../images/(null)-20220724231943637.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\    - Use **target encoding** to reduce time complexity by only evaluating O(L)  splits of the ordered categories.\\      - é¦–å…ˆï¼šThe categories are ordered by mean response rate \\      - æ¥ç€æŒ‰é¡ºåºä¸€ä¸ªä¸€ä¸ªinclude feature\\      - è¿™æ ·æ‰¾å‡ºæ¥çš„ä¼šæ˜¯optimalçš„ï¼\\        &lt;img src=&quot;../images/(null)-20220724231943028.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\#### å†³ç­–æ ‘Overfittingçš„è§£å†³\\&gt; ä¸è®­ç»ƒåˆ°å®Œæ•´çš„tree\\- `Pruning`ï¼šstart from the bottom and start chopping off parts of the tree that don't make sense.
  - Reduced error
    - Starting at the leaves, each node is replaced with its most popular class (chopping)
    - If the validation metric is not negatively aï¬€ected, then the change is kept, else it is reverted.
    - Reduced error pruning has the advantage of speed and simplicity.
    
  - Cost complexity
    - The node with the least $$\alpha_{eff}=\frac{R(t)-R_{\alpha}\left(T_{t}\right)}{T-1}$$is pruned
    
    - Î±ç›¸å½“äºä¸€ä¸ªæ­£åˆ™é¡¹çš„ç³»æ•°ï¼Œä»è€Œ$$R_{\alpha}(T)=R(T)+\alpha|T|\end{aligned}\end{align} \]</div>
<ul>
<li><div class="math notranslate nohighlight">
\[ \begin{align}\begin{aligned}R\left(T_{t}\right)=\sum_{i \in \text { leaf nodes }} R(i)$$, sum of impurities for all leaf nodes t of a tree rooted at node t.
    - Î±è¶Šé«˜ï¼Œæƒ©ç½šè¶Šå¤§ï¼Œä¼šä»overfitting -&gt; sweetspot -&gt; underfitting. éšç€alphaæé«˜ï¼Œæ€»impurityä¼šæœ‰steep change\\&lt;img src=&quot;../images/(null)-20220724230711183.(null)&quot; alt=&quot;img&quot; style=&quot;width:40%;&quot; /&gt;&lt;img src=&quot;../images/(null)-20220724230711425.(null)&quot; alt=&quot;img&quot; style=&quot;width:40%;&quot; /&gt;\\- `Early stopping`ï¼šbuild up to a point and then you stop.\\  - Maximum depthï¼šonly build it to a certain depth which prevents you from going very deep.
    - æ¯”å¦‚ç”¨DFSï¼Œé‚£å°±æ˜¯å¾€ä¸‹splitç›´åˆ°å˜æˆpure node or reach max_depth
  - Maximum leaf nodesï¼šonly have a certain number of leaf nodes
  - Minimum samples splitï¼šthere are a minimum number of samples before I consider it a split
  - Minimum impurity decrease
  
  \\#### Feature Importance\\probability of sample reaching that nodeï¼š the (normalized) total reduction of the criterion brought by that feature\\### Random Forests\\éšæœºä¸€ç§åŸºäºæ ‘æ¨¡å‹çš„Baggingçš„ä¼˜åŒ–ç‰ˆæœ¬ï¼Œä¸€æ£µæ ‘çš„ç”Ÿæˆè‚¯å®šè¿˜æ˜¯ä¸å¦‚å¤šæ£µæ ‘ï¼Œå› æ­¤å°±æœ‰äº†éšæœºæ£®æ—ï¼Œè§£å†³å†³ç­–æ ‘æ³›åŒ–èƒ½åŠ›å¼±çš„ç‰¹ç‚¹ã€‚\\- å¤šæ¬¡éšæœºå–æ ·ï¼Œå¤šæ¬¡éšæœºå–å±æ€§ï¼Œé€‰å–æœ€ä¼˜åˆ†å‰²ç‚¹ï¼Œæ„å»ºå¤šä¸ª(CART)åˆ†ç±»å™¨ï¼ŒæŠ•ç¥¨è¡¨å†³\\- ç®—æ³•æµç¨‹ï¼š\\  - è¾“å…¥ä¸ºæ ·æœ¬é›†$D={(xï¼Œy_1)ï¼Œ(x_2ï¼Œy_2) \dots (x_mï¼Œy_m)}$ï¼Œå¼±åˆ†ç±»å™¨è¿­ä»£æ¬¡æ•°$T$ã€‚\\  - è¾“å‡ºä¸ºæœ€ç»ˆçš„å¼ºåˆ†ç±»å™¨$f(x)$\\  - å¯¹äº$t=1ï¼Œ2 \dots T$\\    - å¯¹è®­ç»ƒé›†è¿›è¡Œç¬¬$t$æ¬¡éšæœºé‡‡æ ·ï¼Œå…±é‡‡é›†$m$æ¬¡ï¼Œå¾—åˆ°åŒ…å«$m$ä¸ªæ ·æœ¬çš„é‡‡æ ·é›†Dt\\    - ç”¨é‡‡æ ·é›†$D_t$è®­ç»ƒç¬¬$t$ä¸ªå†³ç­–æ ‘æ¨¡å‹$G_t(x)$ï¼Œåœ¨è®­ç»ƒå†³ç­–æ ‘æ¨¡å‹çš„èŠ‚ç‚¹çš„æ—¶å€™ï¼Œåœ¨èŠ‚ç‚¹ä¸Šæ‰€æœ‰çš„æ ·æœ¬ç‰¹å¾ä¸­é€‰æ‹©ä¸€éƒ¨åˆ†æ ·æœ¬ç‰¹å¾ï¼Œåœ¨è¿™äº›éšæœºé€‰æ‹©çš„éƒ¨åˆ†æ ·æœ¬ç‰¹å¾ä¸­é€‰æ‹©ä¸€ä¸ªæœ€ä¼˜çš„ç‰¹å¾æ¥åšå†³ç­–æ ‘çš„å·¦å³å­æ ‘åˆ’åˆ†\\  - å¦‚æœæ˜¯åˆ†ç±»ç®—æ³•é¢„æµ‹ï¼Œåˆ™$T$ä¸ªå¼±å­¦ä¹ å™¨æŠ•å‡ºæœ€å¤šç¥¨æ•°çš„ç±»åˆ«æˆ–è€…ç±»åˆ«ä¹‹ä¸€ä¸ºæœ€ç»ˆç±»åˆ«\\    å¦‚æœæ˜¯å›å½’ç®—æ³•ï¼Œ$T$ä¸ªå¼±å­¦ä¹ å™¨å¾—åˆ°çš„å›å½’ç»“æœè¿›è¡Œç®—æœ¯å¹³å‡å¾—åˆ°çš„å€¼ä¸ºæœ€ç»ˆçš„æ¨¡å‹è¾“å‡ºã€‚\\- éšæœºæ£®æ—ä¸ºä»€ä¹ˆä¸å®¹æ˜“è¿‡æ‹Ÿåˆï¼Ÿ\\  - éšæœºæ£®æ—ä¸­çš„æ¯ä¸€é¢—æ ‘éƒ½æ˜¯è¿‡æ‹Ÿåˆçš„ï¼Œæ‹Ÿåˆåˆ°éå¸¸å°çš„ç»†èŠ‚ä¸Š
    - éšæœºæ£®æ—é€šè¿‡å¼•å…¥éšæœºæ€§ï¼Œä½¿æ¯ä¸€é¢—æ ‘æ‹Ÿåˆçš„ç»†èŠ‚ä¸åŒ\\  - æ‰€æœ‰æ ‘ç»„åˆåœ¨ä¸€èµ·ï¼Œè¿‡æ‹Ÿåˆçš„éƒ¨åˆ†å°±ä¼šè‡ªåŠ¨è¢«æ¶ˆé™¤æ‰ã€‚\\**ç®—æ³•**ï¼š\\&lt;img src=&quot;../images/(null)-20220725101113336.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- Applicable to both classiï¬cation and regression problems
- Smarter bagging for trees
- Motivated by theory that generalization **improves with uncorrelated trees**
- Bootstrapped samples and random subset of features are used to train each tree
  - sample rows and columns, æ¯ä¸ªå»train decision tree
  - highly dominate çš„å˜é‡ RF ä¼šå»debiased features
- The outputs from each of the models are averaged to make the ï¬nal prediction.\\è¶…**å‚æ•°**ï¼š\\- Random Forest hyperparameters:
  - \# of trees
  - \# of features
    - Classiï¬cation - sqrt(# of features) æ˜¯ general guideline
    - Regression - # of featuresï¼Œä¸€èˆ¬ä¸sample feature
- Decision Tree hyperparameters (splitting criteria, maximum depth, etc. ) \\**RandomForestä¸éœ€è¦CVçš„åŸå› **\\- æ¯æ¬¡è®­ç»ƒçš„æ—¶å€™ éƒ½åªçœ‹äº†bootstrap sampleï¼Œæœ‰ä¸€éƒ¨åˆ†çš„æ•°æ®æ˜¯æ²¡æœ‰touchçš„
- Uses `out-of-bag (OOB)` error for model selection
  - OOB error is the **average error of** **a data point** calculated using predictions from the trees that do not contain it in their respective bootstrap sample
  - æ¯ä¸ªdata point çš„ error = æ ·æœ¬å¤–é¢„æµ‹çš„errorçš„å¹³å‡
    - å¦‚æœæœ‰ä¸€ä¸ªsampleå»äº†æ‰€æœ‰çš„treeï¼Œé‚£ä¹ˆå®ƒå°±ä¸ä¼šåŠ å…¥out-of-bagçš„è®¡ç®—
    - å¦‚æœæœ‰ä¸€ä¸ªsampleåªå»äº†ä¸€ä¸ªtreeï¼Œé‚£ä¹ˆè¿™ä¸ªtreeçš„errorå°±æ˜¯è¿™ä¸ªdata pointçš„oob error
      - If I built 100 trees and 99 trees used 1 sample and one tree did not use that sample, then that one tree will make a prediction on this, and you can calculate the error from that.\\ **Feature Importances**\\- RFæœ‰ä¸¤ç§æ–¹æ³•ï¼š\\  - é€šè¿‡è®¡ç®—Giniç³»æ•°çš„å‡å°‘é‡VIm=GIâˆ’(GIL+GIR)åˆ¤æ–­ç‰¹å¾é‡è¦æ€§ï¼Œè¶Šå¤§è¶Šé‡è¦ã€‚\\  - å¯¹äºä¸€é¢—æ ‘ï¼Œå…ˆä½¿ç”¨è¢‹å¤–é”™è¯¯ç‡(OOB)æ ·æœ¬è®¡ç®—æµ‹è¯•è¯¯å·®aï¼Œå†éšæœºæ‰“ä¹±OOBæ ·æœ¬ä¸­ç¬¬iä¸ªç‰¹å¾ï¼ˆä¸Šä¸‹æ‰“ä¹±ç‰¹å¾çŸ©é˜µç¬¬iåˆ—çš„é¡ºåºï¼‰åè®¡ç®—æµ‹è¯•è¯¯å·®bï¼Œaä¸bå·®è·è¶Šå¤§ç‰¹å¾iè¶Šé‡è¦ã€‚\\    - è¢‹å¤–æ•°æ®(OOB)ï¼š å¤§çº¦æœ‰1/3çš„è®­ç»ƒå®ä¾‹æ²¡æœ‰å‚ä¸ç¬¬kæ£µæ ‘çš„ç”Ÿæˆï¼Œå®ƒä»¬ç§°ä¸ºç¬¬$k$æ£µæ ‘çš„è¢‹å¤–æ•°æ®æ ·æœ¬ã€‚\\    - åœ¨éšæœºæ£®æ—ä¸­æŸä¸ªç‰¹å¾$X$çš„é‡è¦æ€§çš„è®¡ç®—æ–¹æ³•å¦‚ä¸‹ï¼š\\    - å¯¹äºéšæœºæ£®æ—ä¸­çš„æ¯ä¸€é¢—å†³ç­–æ ‘ï¼Œä½¿ç”¨ç›¸åº”çš„OOB(è¢‹å¤–æ•°æ®)æ¥è®¡ç®—å®ƒçš„è¢‹å¤–æ•°æ®è¯¯å·®ï¼Œè®°ä¸º$err_{OOB1}$ã€‚\\    - éšæœºåœ°å¯¹è¢‹å¤–æ•°æ®OOBæ‰€æœ‰æ ·æœ¬çš„ç‰¹å¾$X$åŠ å…¥å™ªå£°å¹²æ‰°(å°±å¯ä»¥éšæœºçš„æ”¹å˜æ ·æœ¬åœ¨ç‰¹å¾Xå¤„çš„å€¼)ï¼Œå†æ¬¡è®¡ç®—å®ƒçš„è¢‹å¤–æ•°æ®è¯¯å·®ï¼Œè®°ä¸º$err_{OOB2}$ã€‚\\    - å‡è®¾éšæœºæ£®æ—ä¸­æœ‰$N$æ£µæ ‘ï¼Œé‚£ä¹ˆå¯¹äºç‰¹å¾$X$çš„é‡è¦æ€§ä¸º$(err_{OOB2}-err_{OOB1}/N)$ï¼Œä¹‹æ‰€ä»¥å¯ä»¥ç”¨è¿™ä¸ªè¡¨è¾¾å¼æ¥ä½œä¸ºç›¸åº”ç‰¹å¾çš„é‡è¦æ€§çš„åº¦é‡å€¼æ˜¯å› ä¸ºï¼šè‹¥ç»™æŸä¸ªç‰¹å¾éšæœºåŠ å…¥å™ªå£°ä¹‹åï¼Œè¢‹å¤–çš„å‡†ç¡®ç‡å¤§å¹…åº¦é™ä½ï¼Œåˆ™è¯´æ˜è¿™ä¸ªç‰¹å¾å¯¹äºæ ·æœ¬çš„åˆ†ç±»ç»“æœå½±å“å¾ˆå¤§ï¼Œä¹Ÿå°±æ˜¯è¯´å®ƒçš„é‡è¦ç¨‹åº¦æ¯”è¾ƒé«˜ã€‚\\- Feature importance is calculated as the **decrease in node impurity** weighted by the *probability of samples in node*s that are reaching that node.
  - The node probability can be calculated by the **number of samples that reach the node**, divided by the total number of samples.
  - æœ‰æ—¶å€™ä¼šé€‰å°‘çš„number of trees ç‰¹åˆ«æ˜¯æå‡ä¸æ˜¾è‘—çš„æ—¶å€™ï¼Œæ¯”å¦‚100ä¸ªtreeå¯èƒ½åªç”¨äº†5ä¸ªfeaturesï¼Œé‚£ä¹ˆåé¢æˆ‘å°±å¯ä»¥åªmaintainè¿™5ä¸ªfeatures
- The higher the value the more important the feature.\\&lt;img src=&quot;../images/(null)-20220725101112347.(null)&quot; alt=&quot;img&quot; style=&quot;width:50%;&quot; /&gt;\\- SKLearnä¸­çš„ `warm_start`
  - When fitting an estimator repeatedly on the same dataset, but for multiple parameter values (such as to find the value maximizing performance as in [grid search](https://scikit-learn.org/stable/modules/grid_search.html#grid-search)), it may be possible to reuse aspects of the model learned from the previous parameter value, saving time. When `warm_start` is true, the existing [fitted](https://scikit-learn.org/stable/glossary.html#term-fitted) model [attributes](https://scikit-learn.org/stable/glossary.html#term-attributes) are used to initialize the new model in a subsequent call to [fit](https://scikit-learn.org/stable/glossary.html#term-fit).
  - Note that this is only applicable for some models and some parameters, and even some orders of parameter values. For example, `warm_start` may be used when building random forests to add more trees to the forest (increasing `n_estimators`) but not to reduce their number.\\### Adaptive Boosting\\Adaboostç®—æ³•åˆ©ç”¨åŒä¸€ç§åŸºåˆ†ç±»å™¨ï¼ˆå¼±åˆ†ç±»å™¨ï¼‰ï¼ŒåŸºäºåˆ†ç±»å™¨çš„é”™è¯¯ç‡åˆ†é…ä¸åŒçš„æƒé‡å‚æ•°ï¼Œæœ€åç´¯åŠ åŠ æƒçš„é¢„æµ‹ç»“æœä½œä¸ºè¾“å‡ºã€‚\\**æµç¨‹**ï¼š\\- æ ·æœ¬èµ‹äºˆæƒé‡ï¼Œå¾—åˆ°ç¬¬ä¸€ä¸ªåˆ†ç±»å™¨ã€‚\\  Initially, a decision stump classiï¬er (just splits the data into two regions) is ï¬t to the data\\- è®¡ç®—è¯¥åˆ†ç±»å™¨çš„é”™è¯¯ç‡ï¼Œæ ¹æ®**é”™è¯¯ç‡èµ‹äºˆåˆ†ç±»å™¨æƒé‡ï¼ˆ**æ³¨æ„è¿™é‡Œæ˜¯åˆ†ç±»å™¨çš„æƒé‡ï¼‰\\- &lt;u&gt;å¢åŠ åˆ†é”™æ ·æœ¬çš„æƒé‡ï¼Œå‡å°åˆ†å¯¹æ ·æœ¬çš„æƒé‡&lt;/u&gt;ï¼ˆæ³¨æ„è¿™é‡Œæ˜¯æ ·æœ¬çš„æƒé‡ï¼‰\\  The data points correctly classiï¬ed are given less weightage while misclassiï¬ed data points are given higher weightage in the next iteration\\- ç„¶åå†ç”¨æ–°çš„æ ·æœ¬æƒé‡è®­ç»ƒæ•°æ®ï¼Œå¾—åˆ°æ–°çš„åˆ†ç±»å™¨\\  A decision stump classiï¬er is now ï¬t to the data with weights determined in previous iteration\\- å¤šæ¬¡è¿­ä»£ï¼Œç›´åˆ°**åˆ†ç±»å™¨é”™è¯¯ç‡ä¸º0æˆ–è€…æ•´ä½“å¼±åˆ†ç±»å™¨é”™è¯¯ä¸º0ï¼Œæˆ–è€…åˆ°è¾¾è¿­ä»£æ¬¡æ•°ã€‚**\\- å°†**æ‰€æœ‰å¼±åˆ†ç±»å™¨çš„ç»“æœåŠ æƒæ±‚å’Œ**ï¼Œå¾—åˆ°ä¸€ä¸ªè¾ƒä¸ºå‡†ç¡®çš„åˆ†ç±»ç»“æœã€‚é”™è¯¯ç‡ä½çš„åˆ†ç±»å™¨è·å¾—æ›´é«˜çš„å†³å®šç³»æ•°ï¼Œä»è€Œåœ¨å¯¹æ•°æ®è¿›è¡Œé¢„æµ‹æ—¶èµ·å…³é”®ä½œç”¨ã€‚\\  Weights (ğ†) for each classiï¬er (estimated during the training process) are used to combine the outputs and make the ï¬nal prediction.\\&lt;img src=&quot;../images/(null)-20220725101132539.(null)&quot; alt=&quot;img&quot; style=&quot;width: 50%;&quot; /&gt;\\**ç®—æ³•ï¼š**\\1. Initialize the observation weights $w_{i}=1 / N, i=1,2, \ldots, N$.\\   æœ€å¼€å§‹æ‰€æœ‰è§‚æµ‹éƒ½æ˜¯equal weights\\2. For $m=1$ to $M$ è®­ç»ƒMä¸ªclassifier:\\   1. Fit a classifier $G_{m}(x)$ to the training data using weights $w_{i}$.\\   2. è®¡ç®—å®ƒçš„weighted error = $\frac{é”™è¯¯æ ·æœ¬çš„æ€»æƒé‡}{æ€»æƒé‡}$ï¼š\\      $$\operatorname{err}_{m}=\frac{\sum_{i=1}^{N} w_{i} I\left(y_{i} \neq G_{m}\left(x_{i}\right)\right)}{\sum_{i=1}^{N} w_{i}} \end{aligned}\end{align} \]</div>
</li>
</ul>
<ol class="simple">
<li><p>Compute <span class="math notranslate nohighlight">\(\alpha_{m}=\log \left(\left(1-\operatorname{err}_{m}\right) / \operatorname{err}_{m}\right)\)</span> å¾—åˆ°classifierçš„æƒé‡</p></li>
<li><p>Set <span class="math notranslate nohighlight">\(w_{i} \leftarrow w_{i} \cdot \exp \left[\alpha_{m} \cdot I\left(y_{i} \neq G_{m}\left(x_{i}\right)\right)\right], i=1,2, \ldots, N\)</span></p></li>
</ol>
</li>
</ul>
</li>
</ul>
<ol class="simple">
<li><p>Output <span class="math notranslate nohighlight">\(G(x)=\operatorname{sign}\left[\sum_{m=1}^{M} \alpha_{m} G_{m}(x)\right]\)</span>: æ‰€æœ‰çš„Classifierçš„ç»“æœæ ¹æ®$<span class="math notranslate nohighlight">\(\alpha_m\)</span>$ä¸ºæƒåŠ æƒå¹³å‡ï¼</p></li>
</ol>
<p><strong>æ•°å­¦ç†è§£</strong></p>
<ul>
<li><p>ç®—æ³•çš„Assumed Formula $<span class="math notranslate nohighlight">\(G(x)=\sum_{m} \alpha_{m} G_{m}(x)\)</span>$</p>
<ul>
<li><p>Assume the Loss function is a exponentially loss function:$<span class="math notranslate nohighlight">\(L_{e x p}(x, y)=\exp (-y G(x))\)</span>$</p></li>
<li><p>æ‰€ä»¥ç›®æ ‡å˜æˆäº†<span class="math notranslate nohighlight">\(E=\operatorname{Min}_{\alpha_{m}, G_{m}}\left(\sum_{i} \exp \left(-y_{i} \sum_{m} \alpha_{m} G_{m}\left(x_{i}\right)\right)\right)\)</span></p>
<ul>
<li><p>æ±‚$<span class="math notranslate nohighlight">\(\frac{\partial E}{\partial \alpha_{m}}=0\)</span>$:</p>
<div class="math notranslate nohighlight">
\[\alpha_{m}=\ln \left(\frac{1-e r r_{m}}{e r r_{m}}\right)\]</div>
<div class="math notranslate nohighlight">
\[\operatorname{err}_{m}=\frac{\sum_{i=1}^{N} w_{i} I\left(y_{i} \neq G_{m}\left(x_{i}\right)\right)}{\sum_{i=1}^{N} w_{i}}\]</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>è¶…å‚æ•°</strong></p>
<ul class="simple">
<li><p>Classiï¬cation:</p>
<ul>
<li><p># estimators</p></li>
<li><p>learning rateï¼šæ¯æ¬¡åŠ å…¥a fraction of the value</p></li>
<li><p>base estimatorï¼šå¯ä»¥æ¢æˆåˆ«çš„æ¨¡å‹ï¼Œè€Œä¸æ˜¯<code class="docutils literal notranslate"><span class="pre">decision</span> <span class="pre">stump</span> <span class="pre">classiï¬er</span></code></p></li>
</ul>
</li>
<li><p>Regressionï¼š</p>
<ul>
<li><p>loss function</p></li>
<li><p>learning rate</p></li>
<li><p># of estimators</p></li>
<li><p>base estimator</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="gradient-boosting">
<h3>Gradient Boosting<a class="headerlink" href="#gradient-boosting" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>åˆ†ç±»å›å½’éƒ½å¯ä»¥ï¼ˆåˆ†ç±»çš„è¯ ä¹Ÿæ˜¯æ‹¿probabilityå»regressionï¼‰</p></li>
<li><p>Trains regression trees in a sequential manner on <strong>modiï¬ed versions of the datasets.</strong></p></li>
<li><p>Every tree is trained on the residuals of the data points obtained by subtracting the predictions from the previous tree</p>
<ul>
<li><p><strong>weights</strong> for each classiï¬er (estimated during the training process) are used to combine the outputs and make the ï¬nal prediction.</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220725101152441.(null)" alt="img" style="width:50%;" />
<p><strong>ç®—æ³•</strong></p>
<p>Input: training set <span class="math notranslate nohighlight">\(\left\{\left(x_{i}, y_{i}\right)\right\}_{i=1}^{n}\)</span>, a differentiable loss function <span class="math notranslate nohighlight">\(L(y, F(x))\)</span>, number of iterations <span class="math notranslate nohighlight">\(M\)</span>.
Algorithm:</p>
<ol class="simple">
<li><p>Initialize model with a constant value ç¬¬ä¸€æ­¥å…ˆç”¨ä¸€ä¸ªlossæœ€å°çš„å¸¸æ•°æ¥é¢„æµ‹:
$<span class="math notranslate nohighlight">\(
F_{0}(x)=\underset{\gamma}{\arg \min } \sum_{i=1}^{n} L\left(y_{i}, \gamma\right) .
\)</span>$</p></li>
<li><p>For <span class="math notranslate nohighlight">\(m=1\)</span> to <span class="math notranslate nohighlight">\(M\)</span> :</p>
<ol class="simple">
<li><p>Compute so-called pseudo-residuals è®¡ç®—ä¸€ä¸ªæ®‹å·® å…¶å®ä¹Ÿå°±æ˜¯æ¢¯åº¦ï¼:
$<span class="math notranslate nohighlight">\(
r_{i m}=-\left[\frac{\partial L\left(y_{i}, F\left(x_{i}\right)\right)}{\partial F\left(x_{i}\right)}\right]_{F(x)=F_{m-1}(x)} \text { for } i=1, \ldots, n \text {. }
\)</span>$</p></li>
</ol>
</li>
<li><p>Fit a base learner (or weak learner, e.g. tree) <span class="math notranslate nohighlight">\(h_{m}(x)\)</span> to pseudo-residuals, i.e. train it using the training set <span class="math notranslate nohighlight">\(\left\{\left(x_{i}, r_{i m}\right)\right\}_{i=1}^{n}\)</span></p></li>
<li><p>Compute multiplier <span class="math notranslate nohighlight">\(\gamma_{m}\)</span> by solving the following one-dimensional optimization problem:
$<span class="math notranslate nohighlight">\(
\gamma_{m}=\underset{\gamma}{\arg \min } \sum_{i=1}^{n} L\left(y_{i}, F_{m-1}\left(x_{i}\right)+\gamma h_{m}\left(x_{i}\right)\right) .
\)</span>$</p></li>
<li><p>Update the model:
$<span class="math notranslate nohighlight">\(
F_{m}(x)=F_{m-1}(x)+\gamma_{m} h_{m}(x) .
\)</span>$</p></li>
<li><p>Output <span class="math notranslate nohighlight">\(F_{M}(x)\)</span>.</p></li>
</ol>
<p><strong>ä¸ºä»€ä¹ˆå«gradient boostingï¼Ÿ</strong></p>
<ul class="simple">
<li><p>Gradient Descent</p></li>
</ul>
<img src="../images/(null)-20220725101152792.(null)" alt="img" style="width:50%;" />
<ul class="simple">
<li><p>Gradient Boostingï¼šThe gradient in Gradient boosting is nothing but the residual. As every tree we are boosting the residual (fit a model that does well on that that residual), we are actually boosting the gradient</p></li>
<li><p>ç›®æ ‡å‡½æ•°<span class="math notranslate nohighlight">\(E=\operatorname{Min}_{\gamma_{m}, F_{m}}\left(\frac{1}{2} \sum_{i}\left(y_{i}-F\left(x_{i}\right)\right)^{2}\right)\)</span></p>
<ul>
<li><p>å‡è®¾Functionçš„å½¢å¼æ˜¯$<span class="math notranslate nohighlight">\(F(x)=\sum_{m} \gamma_{m} F_{m}(x)\)</span><span class="math notranslate nohighlight">\(ï¼Œ ç”¨squared error\)</span><span class="math notranslate nohighlight">\(L(x, y)=\frac{1}{2}(y-F(x))^{2}\)</span>$</p></li>
<li><p>å¯ä»¥è®¡ç®—åœ¨mè¿™ä¸ªæ¨¡å‹å‡ºæ¥çš„æ—¶å€™è®¡ç®—çš„Gradient = $<span class="math notranslate nohighlight">\( \frac{\partial E}{\partial F_{m-1}(x)} = - (y - F_{m-1}(x))=\)</span>$ç¬¬m-1è½®çš„residualç›¸åæ•°</p></li>
<li><p>ç„¶åå°±å¾—åˆ°äº†æ›´æ–°è§„åˆ™ï¼š$<span class="math notranslate nohighlight">\(F_{m}(x)=F_{m-1}(x)-\gamma \frac{\partial E}{\partial F_{m-1}(x)}\)</span>$</p>
<ul>
<li><p>Gradient = $<span class="math notranslate nohighlight">\( \frac{\partial E}{\partial F_{m-1}(x)} = y - F_{m-1}(x) =\)</span>$ç¬¬mè½®è®­ç»ƒæ—¶é¢å¯¹çš„ä¸Šä¸€è½®çš„residual</p></li>
</ul>
</li>
</ul>
</li>
<li><p>åœ¨MSEçš„æƒ…æ³ä¸‹ï¼Œè´ŸGradientåˆšå¥½æ˜¯residualï¼Œè€Œåœ¨å…¶å®ƒæƒ…å†µä¸‹ï¼Œgradient descentçš„æ—¶å€™ä¾ç„¶æ˜¯åœ¨æ²¿ç€gradientçš„æ–¹å‘å­¦ä¹ ä¼˜åŒ–</p></li>
</ul>
<p><strong>è¶…å‚æ•°</strong></p>
<ul class="simple">
<li><p># of estimators</p></li>
<li><p>Learning rate</p></li>
<li><p>Decision tree parameters (max depth, min number of samples etc.)</p></li>
<li><p>Regularization parameters</p></li>
<li><p>Row sampling / Column sampling: Pass tree from one to anotherçš„æ—¶å€™å¯ä»¥åªpass a sample of samples.</p></li>
</ul>
<hr class="docutils" />
<p>å„ç§Implementation</p>
<hr class="docutils" />
<div class="section" id="gbdt">
<h4><strong>GBDT</strong><a class="headerlink" href="#gbdt" title="Permalink to this headline">Â¶</a></h4>
<ul class="simple">
<li><p>é¦–å…ˆä»‹ç»Adaboost Treeï¼Œæ˜¯ä¸€ç§boostingçš„æ ‘é›†æˆæ–¹æ³•ã€‚åŸºæœ¬æ€è·¯æ˜¯ä¾æ¬¡è®­ç»ƒå¤šæ£µæ ‘ï¼Œæ¯æ£µæ ‘è®­ç»ƒæ—¶å¯¹åˆ†é”™çš„æ ·æœ¬è¿›è¡ŒåŠ æƒã€‚æ ‘æ¨¡å‹ä¸­å¯¹æ ·æœ¬çš„åŠ æƒå®é™…æ˜¯å¯¹æ ·æœ¬é‡‡æ ·å‡ ç‡çš„åŠ æƒï¼Œåœ¨è¿›è¡Œæœ‰æ”¾å›æŠ½æ ·æ—¶ï¼Œåˆ†é”™çš„æ ·æœ¬æ›´æœ‰å¯èƒ½è¢«æŠ½åˆ°</p></li>
<li><p>GBDTæ˜¯Adaboost Treeçš„æ”¹è¿›ï¼Œæ¯æ£µæ ‘éƒ½æ˜¯CARTï¼ˆåˆ†ç±»å›å½’æ ‘ï¼‰ï¼Œæ ‘åœ¨å¶èŠ‚ç‚¹è¾“å‡ºçš„æ˜¯ä¸€ä¸ªæ•°å€¼ï¼Œåˆ†ç±»è¯¯å·®å°±æ˜¯çœŸå®å€¼å‡å»å¶èŠ‚ç‚¹çš„è¾“å‡ºå€¼ï¼Œå¾—åˆ°æ®‹å·®ã€‚GBDTè¦åšçš„å°±æ˜¯ä½¿ç”¨æ¢¯åº¦ä¸‹é™çš„æ–¹æ³•å‡å°‘åˆ†ç±»è¯¯å·®å€¼ã€‚</p></li>
<li><p>åœ¨GBDTçš„è¿­ä»£ä¸­ï¼Œå‡è®¾æˆ‘ä»¬å‰ä¸€è½®è¿­ä»£å¾—åˆ°çš„å¼ºå­¦ä¹ å™¨æ˜¯ftâˆ’1(x), æŸå¤±å‡½æ•°æ˜¯L(y,ftâˆ’1(x)), æˆ‘ä»¬æœ¬è½®è¿­ä»£çš„ç›®æ ‡æ˜¯æ‰¾åˆ°ä¸€ä¸ªCARTå›å½’æ ‘æ¨¡å‹çš„å¼±å­¦ä¹ å™¨ht(x)ï¼Œè®©æœ¬è½®çš„æŸå¤±æŸå¤±L(y,ft(x)=L(y,ftâˆ’1(x)+ht(x))æœ€å°ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œæœ¬è½®è¿­ä»£æ‰¾åˆ°å†³ç­–æ ‘ï¼Œè¦è®©æ ·æœ¬çš„æŸå¤±å°½é‡å˜å¾—æ›´å°ã€‚</p></li>
<li><p>å¾—åˆ°å¤šæ£µæ ‘åï¼Œæ ¹æ®æ¯é¢—æ ‘çš„åˆ†ç±»è¯¯å·®è¿›è¡ŒåŠ æƒæŠ•ç¥¨</p></li>
<li><p>GBDTçš„æ€æƒ³å¯ä»¥ç”¨ä¸€ä¸ªé€šä¿—çš„ä¾‹å­è§£é‡Šï¼Œå‡å¦‚æœ‰ä¸ªäºº30å²ï¼Œæˆ‘ä»¬é¦–å…ˆç”¨20å²å»æ‹Ÿåˆï¼Œå‘ç°æŸå¤±æœ‰10å²ï¼Œè¿™æ—¶æˆ‘ä»¬ç”¨6å²å»æ‹Ÿåˆå‰©ä¸‹çš„æŸå¤±ï¼Œå‘ç°å·®è·è¿˜æœ‰4å²ï¼Œç¬¬ä¸‰è½®æˆ‘ä»¬ç”¨3å²æ‹Ÿåˆå‰©ä¸‹çš„å·®è·ï¼Œå·®è·å°±åªæœ‰ä¸€å²äº†ã€‚å¦‚æœæˆ‘ä»¬çš„è¿­ä»£è½®æ•°è¿˜æ²¡æœ‰å®Œï¼Œå¯ä»¥ç»§ç»­è¿­ä»£ä¸‹é¢ï¼Œæ¯ä¸€è½®è¿­ä»£ï¼Œæ‹Ÿåˆçš„å²æ•°è¯¯å·®éƒ½ä¼šå‡å°ã€‚</p></li>
</ul>
</div>
<div class="section" id="gradientboostingclassifier">
<h4>GradientBoostingClassiï¬er<a class="headerlink" href="#gradientboostingclassifier" title="Permalink to this headline">Â¶</a></h4>
<p>Early implementation of Gradient Boosting in sklearn</p>
<ul class="simple">
<li><p>Most important parametersï¼š</p>
<ul>
<li><p>of estimators</p></li>
<li><p>learning rate</p></li>
</ul>
</li>
<li><p>å¥½ç”¨æ€§ï¼š</p>
<ul>
<li><p>Supports both binary &amp; multi-class classiï¬cation</p></li>
<li><p>Supports sparse data</p></li>
</ul>
</li>
<li><p>ç¼ºç‚¹ï¼š</p>
<ul>
<li><p>Typical slow on large datasets</p></li>
</ul>
</li>
<li><p>ç‰¹å¾é‡è¦æ€§ï¼š</p>
<ul>
<li><p>æ‰€æœ‰å›å½’æ ‘ä¸­é€šè¿‡ç‰¹å¾iåˆ†è£‚å<strong>å¹³æ–¹æŸå¤±çš„å‡å°‘å€¼</strong>çš„å’Œ/å›å½’æ ‘æ•°é‡ å¾—åˆ°ç‰¹å¾é‡è¦æ€§ã€‚</p></li>
<li><p>åœ¨sklearnä¸­ï¼ŒGBDTå’ŒRFçš„ç‰¹å¾é‡è¦æ€§è®¡ç®—æ–¹æ³•æ˜¯ç›¸åŒçš„ï¼Œéƒ½æ˜¯åŸºäºå•æ£µæ ‘è®¡ç®—æ¯ä¸ªç‰¹å¾çš„é‡è¦æ€§ï¼Œæ¢ç©¶æ¯ä¸ªç‰¹å¾åœ¨æ¯æ£µæ ‘ä¸Šåšäº†å¤šå°‘çš„è´¡çŒ®ï¼Œå†å–ä¸ªå¹³å‡å€¼ã€‚</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="histgradientboostingclassifier">
<h4>HistGradientBoostingClassiï¬er<a class="headerlink" href="#histgradientboostingclassifier" title="Permalink to this headline">Â¶</a></h4>
<ul class="simple">
<li><p>Orders of magnitude <strong>faster</strong> than GradientBoostingClassiï¬er on large datasets</p></li>
<li><p>Inspired by LightGBM implementation</p></li>
<li><p>Histogram-based split ï¬nding in tree learning</p></li>
<li><p>ç¼ºç‚¹ï¼š</p>
<ul>
<li><p>Does not support sparse data</p></li>
<li><p>Does not support monotonicity constraintsï¼šæ¯”å¦‚enforceä¸€ä¸ªå˜é‡çš„ç³»æ•°ä¸ºæ­£/è´Ÿçš„ï¼</p>
<ul>
<li><p>the true relationship has some quality, constraints can be used to improve the predictive performance of the model.</p></li>
</ul>
</li>
</ul>
</li>
<li><p>ä¼˜ç‚¹ï¼š</p>
<ul>
<li><p>Supports both binary &amp; multi-class classiï¬cation</p></li>
<li><p>Natively supports categorical featuresï¼ˆä¸éœ€è¦Preprocessï¼‰</p></li>
<li><p>Bin the value into less bins (1000 uniqueæ•°å€¼ -&gt; 10)</p></li>
</ul>
</li>
</ul>
<img src="../images/(null)-20220725101152501.(null)" alt="img" style="width:50%;" />
</div>
</div>
<div class="section" id="xgboost">
<h3>XGBoost<a class="headerlink" href="#xgboost" title="Permalink to this headline">Â¶</a></h3>
<p>XGBoosté‡‡ç”¨çš„æ˜¯level-wiseï¼ˆBFSï¼‰ç”Ÿé•¿ç­–ç•¥ï¼Œèƒ½å¤ŸåŒæ—¶åˆ†è£‚åŒä¸€å±‚çš„å¶å­ï¼Œä»è€Œè¿›è¡Œå¤šçº¿ç¨‹ä¼˜åŒ–ã€‚</p>
<ul>
<li><p>åœ¨å†³ç­–æ ‘çš„ç”Ÿé•¿è¿‡ç¨‹ä¸­ï¼Œä¸€ä¸ªéå¸¸å…³é”®çš„é—®é¢˜æ˜¯å¦‚ä½•æ‰¾åˆ°å¶å­çš„èŠ‚ç‚¹çš„æœ€ä¼˜åˆ‡åˆ†ç‚¹â€Xgboost æ”¯æŒä¸¤ç§åˆ†è£‚èŠ‚ç‚¹çš„æ–¹æ³•â€”â€”è´ªå¿ƒç®—æ³•å’Œè¿‘ä¼¼ç®—æ³•</p>
<ul class="simple">
<li><p>è´ªå¿ƒç®—æ³•ï¼šé’ˆå¯¹æ¯ä¸ªç‰¹å¾ï¼ŒæŠŠå±äºè¯¥èŠ‚ç‚¹çš„è®­ç»ƒæ ·æœ¬æ ¹æ®è¯¥ç‰¹å¾å€¼è¿›è¡Œå‡åºæ’åˆ—ï¼Œé€šè¿‡çº¿æ€§æ‰«æçš„æ–¹å¼æ¥å†³å®šè¯¥ç‰¹å¾çš„æœ€ä½³åˆ†è£‚ç‚¹ï¼Œå¹¶è®°å½•è¯¥ç‰¹å¾çš„åˆ†è£‚æ”¶ç›Š</p></li>
<li><p>è¿‘ä¼¼ç®—æ³•ï¼šå¯¹äºæ¯ä¸ªç‰¹å¾ï¼Œé¦–å…ˆæ ¹æ®ç‰¹å¾åˆ†å¸ƒçš„åˆ†ä½æ•°æå‡ºå€™é€‰åˆ’åˆ†ç‚¹ï¼Œç„¶åå°†è¿ç»­å‹ç‰¹å¾æ˜ å°„åˆ°ç”±è¿™äº›å€™é€‰ç‚¹åˆ’åˆ†çš„æ¡¶ä¸­ï¼Œç„¶åèšåˆç»Ÿè®¡ä¿¡æ¯æ‰¾åˆ°æ‰€æœ‰åŒºé—´çš„æœ€ä½³åˆ†è£‚ç‚¹</p></li>
</ul>
</li>
<li><p>ä¼˜ç‚¹</p>
<ul>
<li><p>æŸå¤±å‡½æ•°è¿›è¡Œäº†äºŒé˜¶æ³°å‹’å±•å¼€ï¼š</p>
<ul>
<li><p>æ³°å‹’äºŒé˜¶è¿‘ä¼¼æ¯”GBDTä¸€é˜¶è¿‘ä¼¼æ›´æ¥è¿‘çœŸå®çš„Loss Fnctionï¼Œè‡ªç„¶ä¼˜åŒ–çš„æ›´å½»åº•äºŒé˜¶ä¿¡æ¯èƒ½å¤Ÿè®©æ¢¯åº¦æ”¶æ•›çš„æ›´å¿«ï¼Œç±»ä¼¼ç‰›é¡¿æ³•æ¯”SGDæ”¶æ•›æ›´å¿«ã€‚</p>
<p>äºŒé˜¶ä¿¡æ¯æœ¬èº«å°±èƒ½è®©æ¢¯åº¦æ”¶æ•›æ›´å¿«æ›´å‡†ç¡®ã€‚è¿™ä¸€ç‚¹åœ¨ä¼˜åŒ–ç®—æ³•é‡Œçš„<strong>ç‰›é¡¿æ³•</strong>ä¸­å·²ç»è¯å®ã€‚å¯ä»¥ç®€å•è®¤ä¸ºä¸€é˜¶å¯¼æŒ‡å¼•æ¢¯åº¦æ–¹å‘ï¼ŒäºŒé˜¶å¯¼æŒ‡å¼•æ¢¯åº¦æ–¹å‘å¦‚ä½•å˜åŒ–ã€‚ç®€å•æ¥è¯´ï¼Œç›¸å¯¹äºGBDTçš„ä¸€é˜¶æ³°å‹’å±•å¼€ï¼ŒXGBoosté‡‡ç”¨äºŒé˜¶æ³°å‹’å±•å¼€ï¼Œå¯ä»¥æ›´ä¸ºç²¾å‡†çš„é€¼è¿‘çœŸå®çš„æŸå¤±å‡½æ•°ã€‚</p>
</li>
<li><p>èƒ½å¤Ÿè‡ªå®šä¹‰æŸå¤±å‡½æ•°ï¼ŒäºŒé˜¶æ³°å‹’å±•å¼€å¯ä»¥è¿‘ä¼¼å¤§é‡æŸå¤±å‡½æ•°ï¼›</p></li>
<li><p>æ³¨æ„ï¼šGBDT+MSEçš„æ—¶å€™boostingæ‹Ÿåˆçš„æ‰æ˜¯æ®‹å·®ï¼Œ<strong>XGBoostæ‹Ÿåˆçš„ä¸æ˜¯æ®‹å·®è€Œæ˜¯ç›´æ¥åˆ©ç”¨äº†äºŒé˜¶å¯¼æ•°ä½œä¸ºæ‹Ÿåˆå¯¹è±¡ï¼Œæ‰¾åˆ°è¯¯å·®å‡½æ•°objå‡å°çš„å¹…åº¦</strong></p></li>
</ul>
</li>
<li><p>å¯ä»¥åœ¨ç‰¹å¾é¢—ç²’åº¦å¹¶è¡Œè®­ç»ƒ</p>
<ul class="simple">
<li><p>ä¸æ˜¯è¯´æ¯æ£µæ ‘å¯ä»¥å¹¶è¡Œè®­ç»ƒï¼Œ<span class="math notranslate nohighlight">\(XGBoost\)</span>æœ¬è´¨ä¸Šä»ç„¶é‡‡ç”¨<span class="math notranslate nohighlight">\(Boosting\)</span>æ€æƒ³ï¼Œæ¯æ£µæ ‘è®­ç»ƒå‰éœ€è¦ç­‰å‰é¢çš„æ ‘è®­ç»ƒå®Œæˆæ‰èƒ½å¼€å§‹è®­ç»ƒã€‚</p></li>
<li><p>å†³ç­–æ ‘çš„å­¦ä¹ æœ€è€—æ—¶çš„ä¸€ä¸ªæ­¥éª¤å°±æ˜¯å¯¹ç‰¹å¾çš„å€¼è¿›è¡Œæ’åºï¼ˆå› ä¸ºè¦ç¡®å®šæœ€ä½³åˆ†å‰²ç‚¹ï¼‰ï¼ŒXGBooståœ¨è®­ç»ƒä¹‹å‰ï¼Œæ¯ä¸ªç‰¹å¾æŒ‰ç‰¹å¾å€¼å¯¹æ ·æœ¬è¿›è¡Œé¢„æ’åº<strong>å¹¶å­˜å‚¨ä¸ºblockç»“æ„</strong></p></li>
<li><p>åœ¨åé¢æŸ¥æ‰¾ç‰¹å¾åˆ†å‰²ç‚¹æ—¶å¯ä»¥é‡å¤ä½¿ç”¨block</p></li>
<li><p>åªä¸è¿‡åœ¨è¿›è¡ŒèŠ‚ç‚¹çš„åˆ†è£‚æ—¶ï¼Œéœ€è¦è®¡ç®—æ¯ä¸ªç‰¹å¾çš„å¢ç›Šï¼Œæœ€ç»ˆé€‰å¢ç›Šæœ€å¤§çš„é‚£ä¸ªç‰¹å¾å»åšåˆ†è£‚ï¼Œè¿™é‡Œå„ä¸ªç‰¹å¾çš„å¢ç›Šè®¡ç®—ä¹Ÿå¯ä»¥å¤šçº¿ç¨‹è¿›è¡Œ</p></li>
</ul>
</li>
<li><p>ç›´æ–¹å›¾ï¼šFast approximate split ï¬nding based on histograms</p>
<ul>
<li><p><strong>xgbooståœ¨æ¯ä¸€å±‚éƒ½åŠ¨æ€æ„å»ºç›´æ–¹å›¾</strong>ï¼Œåˆ†æ¡¶çš„ä¾æ®æ˜¯æ ·æœ¬çš„äºŒçº§æ¢¯åº¦ï¼Œæ¯ä¸€å±‚éƒ½è¦é‡æ–°æ„å»º</p>
<p>lightgbmä¸­å¯¹æ¯ä¸ªç‰¹å¾éƒ½æœ‰ä¸€ä¸ªç›´æ–¹å›¾ï¼Œæ‰€ä»¥æ„å»ºä¸€æ¬¡ç›´æ–¹å›¾å°±å¤Ÿäº†</p>
</li>
</ul>
</li>
<li><p>åŠ å…¥æ­£åˆ™é¡¹<code class="docutils literal notranslate"><span class="pre">Adds</span> <span class="pre">l1</span> <span class="pre">and</span> <span class="pre">l2</span> <span class="pre">penalties</span> <span class="pre">on</span> <span class="pre">leaf</span> <span class="pre">weights</span></code>: åŠ å…¥äº†æ­£åˆ™é¡¹ï¼Œç”¨äºæ§åˆ¶æ¨¡å‹çš„å¤æ‚åº¦ã€‚æ­£åˆ™é¡¹é‡ŒåŒ…å«äº†æ ‘çš„å¶å­èŠ‚ç‚¹ä¸ªæ•°ã€å¶å­èŠ‚ç‚¹æƒé‡çš„ L2 èŒƒå¼ã€‚æ­£åˆ™é¡¹é™ä½äº†æ¨¡å‹çš„æ–¹å·®ï¼Œä½¿å­¦ä¹ å‡ºæ¥çš„æ¨¡å‹æ›´åŠ ç®€å•ï¼Œæœ‰åŠ©äºé˜²æ­¢è¿‡æ‹Ÿåˆï¼›</p></li>
<li><p>**Shrinkageï¼ˆç¼©å‡ï¼‰ï¼š**ç›¸å½“äºå­¦ä¹ é€Ÿç‡ã€‚XGBoost åœ¨è¿›è¡Œå®Œä¸€æ¬¡è¿­ä»£åï¼Œä¼šå°†å¶å­èŠ‚ç‚¹çš„æƒé‡ä¹˜ä¸Šè¯¥ç³»æ•°ï¼Œä¸»è¦æ˜¯ä¸ºäº†å‰Šå¼±æ¯æ£µæ ‘çš„å½±å“ï¼Œè®©åé¢æœ‰æ›´å¤§çš„å­¦ä¹ ç©ºé—´ï¼›</p></li>
<li><p>å¥½ç”¨çš„ç‚¹ï¼š</p>
<ul class="simple">
<li><p>Supports <code class="docutils literal notranslate"><span class="pre">GPU</span> <span class="pre">training</span></code>å—ç»“æ„å¯ä»¥å¾ˆå¥½çš„æ”¯æŒå¹¶è¡Œè®¡ç®—ï½œsparse dataï½œmissing valuesï½œWorks well with pipelines in sklearn due to a compatible interface</p>
<ul>
<li><p>ç¼ºå¤±å€¼çš„å¤„ç†ï¼ˆLight GBMä¸€æ ·ï¼‰ï¼šå…ˆä¸å¤„ç†é‚£äº›å€¼ç¼ºå¤±çš„æ ·æœ¬ï¼Œé‡‡ç”¨é‚£äº›æœ‰å€¼çš„æ ·æœ¬æå‡ºåˆ†è£‚ç‚¹ï¼Œåœ¨éå†æ¯ä¸ªæœ‰å€¼ç‰¹å¾çš„æ—¶å€™ï¼Œå°è¯•å°†ç¼ºå¤±æ ·æœ¬åˆ’å…¥å·¦å­æ ‘å’Œå³å­æ ‘ï¼Œé€‰æ‹©ä½¿æŸå¤±æœ€ä¼˜çš„å€¼ä½œä¸ºåˆ†è£‚ç‚¹</p></li>
</ul>
</li>
<li><p>Monotonicity &amp; feature interaction constraints</p>
<ul>
<li><p><strong>feature interaction constraints:</strong> when you consider one feature, you donâ€™t want to consider another feature in that branch itself. So we can impose such feature interaction constraints as well, in addition to monotonic relationships.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>ç¼ºç‚¹</p>
<ul class="simple">
<li><p>è™½ç„¶åˆ©ç”¨é¢„æ’åºå’Œè¿‘ä¼¼ç®—æ³•å¯ä»¥é™ä½å¯»æ‰¾æœ€ä½³åˆ†è£‚ç‚¹çš„è®¡ç®—é‡ï¼Œä½†åœ¨èŠ‚ç‚¹åˆ†è£‚è¿‡ç¨‹ä¸­ä»éœ€è¦éå†æ•°æ®é›†ï¼›</p></li>
<li><p>é¢„æ’åºè¿‡ç¨‹çš„ç©ºé—´å¤æ‚åº¦è¿‡é«˜ï¼Œä¸ä»…éœ€è¦å­˜å‚¨ç‰¹å¾å€¼ï¼Œè¿˜éœ€è¦å­˜å‚¨ç‰¹å¾å¯¹åº”æ ·æœ¬çš„æ¢¯åº¦ç»Ÿè®¡å€¼çš„ç´¢å¼•ï¼Œç›¸å½“äºæ¶ˆè€—äº†ä¸¤å€çš„å†…å­˜ã€‚</p></li>
<li><p>ä½†ä¸åŠ åŒºåˆ†çš„å¯¹å¾…åŒä¸€å±‚çš„å¶å­ï¼Œå¸¦æ¥äº†å¾ˆå¤šæ²¡å¿…è¦çš„å¼€é”€</p></li>
<li><p>Does not support categorical variables natively</p></li>
</ul>
</li>
</ul>
<p><strong>Feature importanceï¼š</strong></p>
<ul class="simple">
<li><p>importance_type=weightï¼ˆé»˜è®¤å€¼ï¼‰ï¼Œç‰¹å¾é‡è¦æ€§ä½¿ç”¨ç‰¹å¾åœ¨æ‰€æœ‰æ ‘ä¸­ä½œä¸ºåˆ’åˆ†å±æ€§çš„æ¬¡æ•°ã€‚</p></li>
<li><p>mportance_type=gainï¼Œç‰¹å¾é‡è¦æ€§ä½¿ç”¨ç‰¹å¾åœ¨ä½œä¸ºåˆ’åˆ†å±æ€§æ—¶losså¹³å‡çš„é™ä½é‡ã€‚</p></li>
<li><p>importance_type=coverï¼Œç‰¹å¾é‡è¦æ€§ä½¿ç”¨ç‰¹å¾åœ¨ä½œä¸ºåˆ’åˆ†å±æ€§æ—¶å¯¹æ ·æœ¬çš„è¦†ç›–åº¦</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">shap</span> <span class="pre">value</span></code>: Shapley Additive explanationsçš„ç¼©å†™</p>
<ul>
<li><p>è¾“å‡ºçš„å½¢å¼ï¼š</p>
<ul>
<li><p>æ¯ä¸ªæ ·æœ¬: å¯ä»¥çœ‹åˆ°æ¯ä¸ªç‰¹å¾çš„shap_valueè´¡çŒ®ï¼ˆæœ‰æ­£è´Ÿï¼‰</p></li>
<li><p>æ¯ä¸ªç‰¹å¾ï¼šå¯ä»¥çœ‹åˆ°æ•´ä½“æ ·æœ¬ä¸Šçš„Shapç»å¯¹å€¼å–å¹³å‡å€¼æ¥ä»£è¡¨è¯¥ç‰¹å¾çš„é‡è¦æ€§â€”â€”shapå‡å€¼è¶Šå¤§ï¼Œåˆ™ç‰¹å¾è¶Šé‡è¦</p></li>
</ul>
</li>
<li><p>è¾“å‡ºçš„å›¾æ ‡</p>
<ul>
<li><p>dependency</p></li>
<li><p>individual</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p><strong>å¤„ç†è¿‡æ‹Ÿåˆçš„æƒ…å†µ</strong>ï¼šé¦–å…ˆBFSçš„æ²¡é‚£ä¹ˆå®¹æ˜“è¿‡æ‹Ÿåˆ</p>
<ul class="simple">
<li><p>ç›®æ ‡å‡½æ•°ä¸­å¢åŠ äº†æ­£åˆ™é¡¹ï¼šä½¿ç”¨å¶å­ç»“ç‚¹çš„æ•°ç›®å’Œå¶å­ç»“ç‚¹æƒé‡çš„<span class="math notranslate nohighlight">\(L2\)</span>æ¨¡çš„å¹³æ–¹ï¼Œæ§åˆ¶æ ‘çš„å¤æ‚åº¦ã€‚</p></li>
<li><p>è®¾ç½®ç›®æ ‡å‡½æ•°çš„<strong>å¢ç›Šé˜ˆå€¼</strong>ï¼šå¦‚æœåˆ†è£‚åç›®æ ‡å‡½æ•°çš„å¢ç›Šå°äºè¯¥é˜ˆå€¼ï¼Œåˆ™ä¸åˆ†è£‚ã€‚</p></li>
<li><p>è®¾ç½®<strong>æœ€å°æ ·æœ¬æƒé‡å’Œ</strong>çš„é˜ˆå€¼ï¼šå½“å¼•å…¥ä¸€æ¬¡åˆ†è£‚åï¼Œé‡æ–°è®¡ç®—æ–°ç”Ÿæˆçš„å·¦ã€å³ä¸¤ä¸ªå¶å­ç»“ç‚¹çš„æ ·æœ¬æƒé‡å’Œã€‚å¦‚æœä»»ä¸€ä¸ªå¶å­ç»“ç‚¹çš„æ ·æœ¬æƒé‡ä½äºæŸä¸€ä¸ªé˜ˆå€¼ï¼ˆæœ€å°æ ·æœ¬æƒé‡å’Œï¼‰ï¼Œä¹Ÿä¼šæ”¾å¼ƒæ­¤æ¬¡åˆ†è£‚ã€‚</p></li>
<li><p>è®¾ç½®æ ‘çš„æœ€å¤§æ·±åº¦ï¼š<span class="math notranslate nohighlight">\(XGBoost\)</span> å…ˆä»é¡¶åˆ°åº•å»ºç«‹æ ‘ç›´åˆ°æœ€å¤§æ·±åº¦ï¼Œå†ä»åº•åˆ°é¡¶åå‘æ£€æŸ¥æ˜¯å¦æœ‰<strong>ä¸æ»¡è¶³åˆ†è£‚æ¡ä»¶çš„ç»“ç‚¹ï¼Œè¿›è¡Œå‰ªæã€‚</strong></p></li>
<li><p><strong>shrinkage</strong>: å­¦ä¹ ç‡æˆ–æ­¥é•¿é€æ¸ç¼©å°ï¼Œç»™åé¢çš„è®­ç»ƒç•™å‡ºæ›´å¤šçš„å­¦ä¹ ç©ºé—´</p></li>
<li><p>å­é‡‡æ ·ï¼š<u><em>æ¯è½®è®¡ç®—å¯ä»¥ä¸ä½¿ç”¨å…¨éƒ¨æ ·æœ¬ï¼Œä½¿ç®—æ³•æ›´åŠ ä¿å®ˆ</em></u></p></li>
<li><p><strong>åˆ—æŠ½æ ·</strong>ï¼šè®­ç»ƒçš„æ—¶å€™åªç”¨ä¸€éƒ¨åˆ†ç‰¹å¾ï¼ˆä¸è€ƒè™‘å‰©ä½™çš„blockå—å³å¯ï¼‰</p></li>
</ul>
<p><strong>å‚æ•°ï¼š</strong></p>
<ul class="simple">
<li><p>ç¬¬ä¸€ç±»å‚æ•°ï¼šç”¨äºç›´æ¥æ§åˆ¶å½“ä¸ªæ ‘æ¨¡å‹çš„å¤æ‚åº¦ã€‚åŒ…æ‹¬max_depthï¼Œmin_child_weightï¼Œgamma ç­‰å‚æ•°</p>
<ul>
<li><p>gammaï¼šåœ¨èŠ‚ç‚¹åˆ†è£‚æ—¶ï¼Œåªæœ‰åˆ†è£‚åæŸå¤±å‡½æ•°çš„å€¼ä¸‹é™äº†ï¼Œæ‰ä¼šåˆ†è£‚è¿™ä¸ªèŠ‚ç‚¹ã€‚GammaæŒ‡å®šäº†èŠ‚ç‚¹åˆ†è£‚æ‰€éœ€çš„æœ€å°æŸå¤±å‡½æ•°ä¸‹é™å€¼ã€‚ è¿™ä¸ªå‚æ•°çš„å€¼è¶Šå¤§ï¼Œç®—æ³•è¶Šä¿å®ˆ</p></li>
</ul>
</li>
<li><p>ç¬¬äºŒç±»å‚æ•°ï¼šç”¨äºå¢åŠ éšæœºæ€§ï¼Œä»è€Œä½¿å¾—æ¨¡å‹åœ¨è®­ç»ƒæ—¶å¯¹äºå™ªéŸ³ä¸æ•æ„Ÿã€‚åŒ…æ‹¬ï¼š</p>
<ul>
<li><p>subsample - æ¯æ£µæ ‘ï¼Œéšæœºé‡‡æ ·çš„æ¯”ä¾‹</p></li>
<li><p>colsample_bytree - æ§åˆ¶æ¯æ£µéšæœºé‡‡æ ·çš„åˆ—æ•°çš„å æ¯”</p></li>
</ul>
</li>
<li><p>è¿˜æœ‰å°±æ˜¯ç›´æ¥å‡å°learning rateï¼Œä½†éœ€è¦åŒæ—¶å¢åŠ estimator å‚æ•°ã€‚</p></li>
</ul>
</div>
<div class="section" id="lightgbm">
<h3>LightGBM<a class="headerlink" href="#lightgbm" title="Permalink to this headline">Â¶</a></h3>
<p>ä» LightGBM åå­—æˆ‘ä»¬å¯ä»¥çœ‹å‡ºå…¶æ˜¯è½»é‡çº§ï¼ˆLightï¼‰çš„æ¢¯åº¦æå‡æœºï¼ˆGBMï¼‰ï¼Œå…¶ç›¸å¯¹ XGBoost å…·æœ‰è®­ç»ƒé€Ÿåº¦å¿«ã€å†…å­˜å ç”¨ä½çš„ç‰¹ç‚¹ã€‚</p>
<p>LightGBMé‡‡ç”¨leaf-wiseç”Ÿé•¿ç­–ç•¥ï¼ˆDFSï¼‰ï¼šæ¯æ¬¡ä»å½“å‰æ‰€æœ‰å¶å­ä¸­æ‰¾åˆ°åˆ†è£‚å¢ç›Šæœ€å¤§ï¼ˆä¸€èˆ¬ä¹Ÿæ˜¯æ•°æ®é‡æœ€å¤§ï¼‰çš„ä¸€ä¸ªå¶å­ï¼Œç„¶ååˆ†è£‚ï¼Œå¦‚æ­¤å¾ªç¯ï¼›ä½†ä¼šç”Ÿé•¿å‡ºæ¯”è¾ƒæ·±çš„å†³ç­–æ ‘ï¼Œäº§ç”Ÿè¿‡æ‹Ÿåˆã€‚</p>
<ul>
<li><p>ä¼˜ç‚¹</p>
<ul>
<li><p><strong>Histogram</strong>ï¼šç›´æ–¹å›¾ç®—æ³•çš„åŸºæœ¬æ€æƒ³æ˜¯å…ˆæŠŠè¿ç»­çš„æµ®ç‚¹ç‰¹å¾å€¼ç¦»æ•£åŒ–æˆkä¸ªæ•´æ•°ï¼ˆå…¶å®åˆæ˜¯åˆ†æ¡¶çš„æ€æƒ³ï¼Œè€Œè¿™äº›æ¡¶ç§°ä¸ºbinï¼Œæ¯”å¦‚[0,0.1)â†’0, [0.1,0.3)â†’1ï¼‰ï¼ŒåŒæ—¶æ„é€ ä¸€ä¸ªå®½åº¦ä¸ºkçš„ç›´æ–¹å›¾</p>
<p>å°†å±äºè¯¥ç®±å­çš„æ ·æœ¬æ•°æ®æ›´æ–°ä¸ºç®±å­çš„å€¼ï¼Œç”¨ç›´æ–¹å›¾è¡¨ç¤º</p>
<ul class="simple">
<li><p>**å¯ä»¥å‡å°‘å†…å­˜æ¶ˆè€—ï¼š**å› ä¸ºä¸ç”¨é¢å¤–å­˜å‚¨é¢„æ’åºçš„ç»“æœï¼Œå¯ä»¥åªä¿å­˜ç‰¹å¾ç¦»æ•£åŒ–åçš„å€¼</p></li>
<li><p><strong>è®¡ç®—ä»£ä»·æ›´å°</strong>ï¼š</p>
<ul>
<li><p>é¢„æ’åºç®—æ³•æ¯éå†ä¸€ä¸ªç‰¹å¾å€¼å°±è¦è®¡ç®—ä¸€æ¬¡åœ¨è¿™é‡Œåˆ†è£‚çš„information gainï¼Œä½†ç›´æ–¹å›¾åªéœ€è¦è®¡ç®—kä¸ªç»Ÿçš„æ•°</p></li>
<li><p>åŒæ—¶ï¼Œä¸€ä¸ªå¶å­çš„ç›´æ–¹å›¾å¯ä»¥ç”±å®ƒçš„çˆ¶äº²èŠ‚ç‚¹çš„ç›´æ–¹å›¾ä¸å®ƒå…„å¼Ÿçš„ç›´æ–¹å›¾åšå·®å¾—åˆ°</p></li>
</ul>
</li>
</ul>
</li>
<li><p>å•è¾¹æ¢¯åº¦é‡‡æ · <code class="docutils literal notranslate"><span class="pre">Gradient-based</span> <span class="pre">One-Sided</span> <span class="pre">Sampling</span> <span class="pre">(GOSS)</span></code></p>
<ul class="simple">
<li><p>GBDT ç®—æ³•çš„æ¢¯åº¦å¤§å°å¯ä»¥ååº”æ ·æœ¬çš„æƒé‡ï¼Œæ¢¯åº¦è¶Šå°è¯´æ˜æ¨¡å‹æ‹Ÿåˆçš„è¶Šå¥½ï¼Œå•è¾¹æ¢¯åº¦æŠ½æ ·ç®—æ³•åˆ©ç”¨è¿™ä¸€ä¿¡æ¯å¯¹æ ·æœ¬è¿›è¡Œ**<u>æŠ½æ ·</u>**ï¼Œå‡å°‘äº†å¤§é‡æ¢¯åº¦å°çš„æ ·æœ¬ï¼Œåœ¨æ¥ä¸‹æ¥çš„è®¡ç®—é”…ä¸­åªéœ€å…³æ³¨æ¢¯åº¦é«˜çš„æ ·æœ¬ï¼Œæå¤§çš„å‡å°‘äº†è®¡ç®—é‡</p>
<ul>
<li><p>åœ¨å¯¹æ¯ä¸ªtreeåšsamplingä»è€ŒåŠ é€Ÿçš„æ—¶å€™ï¼š**å› ä¸ºæ¯ä¸€æ­¥çš„gradientå°±æ˜¯residualï¼Œæˆ‘å°±å¯ä»¥sample based on this residual. æŠŠæ¢¯åº¦å¤§çš„é€‰å‡ºæ¥ï¼Œ**æ¢¯åº¦å°çš„sample it out. å¯ä»¥è®¾ç½®ä¸€ä¸ªthresholdæŠŠä½çš„ç­›æ‰</p></li>
</ul>
</li>
<li><p>è¿™ä¸ªæ“ä½œåé¢ä¹Ÿä¼šç”¨æƒé‡å¹³è¡¡å›æ¥ï¼Œè®©<strong>ä¸€æ–¹é¢ç®—æ³•å°†æ›´å¤šçš„æ³¨æ„åŠ›æ”¾åœ¨è®­ç»ƒä¸è¶³çš„æ ·æœ¬ä¸Šï¼Œå¦ä¸€æ–¹é¢é€šè¿‡ä¹˜ä¸Šæƒé‡æ¥é˜²æ­¢é‡‡æ ·å¯¹åŸå§‹æ•°æ®åˆ†å¸ƒé€ æˆå¤ªå¤§çš„å½±å“</strong></p></li>
</ul>
</li>
<li><p>äº’æ–¥ç‰¹å¾æ†ç»‘Exclusive feature <code class="docutils literal notranslate"><span class="pre">bundling</span></code> to handle sparse features</p>
<ul class="simple">
<li><p>å¦‚æœä¸¤ä¸ªç‰¹å¾å¹¶ä¸å®Œå…¨äº’æ–¥ï¼ˆå¦‚åªæœ‰ä¸€éƒ¨åˆ†æƒ…å†µä¸‹æ˜¯ä¸åŒæ—¶å–éé›¶å€¼ï¼‰ï¼Œå¯ä»¥ç”¨äº’æ–¥ç‡è¡¨ç¤ºäº’æ–¥ç¨‹åº¦ã€‚äº’æ–¥ç‰¹å¾æ†ç»‘ç®—æ³•ï¼ˆExclusive Feature Bundling, EFBï¼‰æŒ‡å‡ºå¦‚æœå°†ä¸€äº›ç‰¹å¾è¿›è¡Œèåˆç»‘å®šï¼Œåˆ™å¯ä»¥é™ä½ç‰¹å¾æ•°é‡ã€‚</p></li>
<li><p>speed up the process of splitting</p></li>
<li><p>åœ¨å®é™…åº”ç”¨ä¸­ï¼Œé«˜ç»´åº¦ç‰¹å¾å…·æœ‰ç¨€ç–æ€§ï¼Œè¿™æ ·å¯ä»¥è®¾è®¡ä¸€ä¸ªå‡å°‘æœ‰æ•ˆç‰¹å¾æ•°é‡çš„æ— æŸçš„æ–¹æ³•ï¼Œç‰¹åˆ«æ˜¯åœ¨ç¨€ç–ç‰¹å¾ä¸­ï¼Œè®¸å¤šç‰¹å¾æ˜¯äº’æ–¥çš„ï¼Œå‡ºç°å¤§é‡0ï¼Œä¾‹å¦‚one-hotã€‚æˆ‘ä»¬å¯ä»¥æ†ç»‘äº’æ–¥çš„ç‰¹å¾ã€‚æœ€åæˆ‘ä»¬è¿˜åŸæ†ç»‘äº’æ–¥é—®é¢˜ä¸ºå›¾ç€è‰²é—®é¢˜ï¼Œä½¿ç”¨è´ªå¿ƒç®—æ³•è¿‘ä¼¼æ±‚è§£ã€‚</p></li>
</ul>
</li>
<li><p>**<u>LightGBM åŸç”Ÿæ”¯æŒç±»åˆ«ç‰¹å¾ï½œ</u>**Supports GPU training, sparse data &amp; missing valuesï½œGenerally faster than XGBoost on CPUsï½œSupports <strong>distributed training</strong> on diï¬€erent frameworks like Ray, Spark, Dask etc.</p></li>
<li><p>ç¼ºå¤±å€¼å¤„ç†ï¼šæ¯æ¬¡åˆ†å‰²çš„æ—¶å€™ï¼Œåˆ†åˆ«æŠŠç¼ºå¤±å€¼æ”¾åœ¨å·¦å³ä¸¤è¾¹å„è®¡ç®—ä¸€æ¬¡ï¼Œç„¶åæ¯”è¾ƒä¸¤ç§æƒ…å†µçš„å¢ç›Šï¼Œæ‹©ä¼˜å½•å–</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="xgboostlightgbm">
<h3>XGBoostå’ŒLightGBMçš„åŒºåˆ«<a class="headerlink" href="#xgboostlightgbm" title="Permalink to this headline">Â¶</a></h3>
<ul>
<li><p>æ ‘ç”Ÿé•¿ç­–ç•¥ä¸åŒ</p>
<ul class="simple">
<li><p>XGBé‡‡ç”¨level-wiseçš„åˆ†è£‚ç­–ç•¥ï¼šXGBå¯¹æ¯ä¸€å±‚æ‰€æœ‰èŠ‚ç‚¹åšæ— å·®åˆ«åˆ†è£‚ï¼Œä½†æ˜¯å¯èƒ½æœ‰äº›èŠ‚ç‚¹å¢ç›Šéå¸¸å°ï¼Œå¯¹ç»“æœå½±å“ä¸å¤§ï¼Œå¸¦æ¥ä¸å¿…è¦çš„å¼€é”€ã€‚</p></li>
<li><p>LGBé‡‡ç”¨leaf-wiseçš„åˆ†è£‚ç­–ç•¥ï¼šLeaf-wiseæ˜¯åœ¨æ‰€æœ‰å¶å­èŠ‚ç‚¹ä¸­é€‰å–åˆ†è£‚æ”¶ç›Šæœ€å¤§çš„èŠ‚ç‚¹è¿›è¡Œçš„ï¼Œä½†æ˜¯å¾ˆå®¹æ˜“å‡ºç°è¿‡æ‹Ÿåˆé—®é¢˜ï¼Œæ‰€ä»¥éœ€è¦å¯¹æœ€å¤§æ·±åº¦åšé™åˆ¶</p></li>
</ul>
</li>
<li><p>æ ‘å¯¹ç‰¹å¾åˆ†å‰²ç‚¹æŸ¥æ‰¾ç®—æ³•ä¸åŒï¼š</p>
<ul>
<li><p>XGBä½¿ç”¨ç‰¹å¾é¢„æ’åºç®—æ³•</p></li>
<li><p>LGBä½¿ç”¨åŸºäºç›´æ–¹å›¾çš„åˆ‡åˆ†ç‚¹ç®—æ³•ï¼š</p>
<ul class="simple">
<li><p>å‡å°‘å†…å­˜å ç”¨ï¼Œæ¯”å¦‚ç¦»æ•£ä¸º256ä¸ªbinæ—¶ï¼Œåªéœ€è¦ç”¨8ä½æ•´å½¢å°±å¯ä»¥ä¿å­˜ä¸€ä¸ªæ ·æœ¬è¢«æ˜ å°„ä¸ºå“ªä¸ªbin(è¿™ä¸ªbinå¯ä»¥è¯´å°±æ˜¯è½¬æ¢åçš„ç‰¹å¾)ï¼Œå¯¹æ¯”é¢„æ’åºçš„exact greedyç®—æ³•æ¥è¯´ï¼ˆç”¨int_32æ¥å­˜å‚¨ç´¢å¼•+ ç”¨float_32ä¿å­˜ç‰¹å¾å€¼ï¼‰ï¼Œå¯ä»¥èŠ‚çœ7/8çš„ç©ºé—´ã€‚</p></li>
<li><p>è®¡ç®—æ•ˆç‡æé«˜ï¼Œé¢„æ’åºçš„Exact greedyå¯¹æ¯ä¸ªç‰¹å¾éƒ½éœ€è¦éå†ä¸€éæ•°æ®ï¼Œå¹¶è®¡ç®—å¢ç›Šã€‚è€Œç›´æ–¹å›¾ç®—æ³•åœ¨å»ºç«‹å®Œç›´æ–¹å›¾åï¼Œåªéœ€è¦å¯¹æ¯ä¸ªç‰¹å¾éå†ç›´æ–¹å›¾å³å¯</p></li>
</ul>
</li>
<li><p>ç„¶åè¿™é‡Œä¹Ÿè·Ÿåˆ†è£‚æ–¹å¼æœ‰å…³</p>
<ul>
<li><p>XGB åœ¨æ¯ä¸€å±‚éƒ½åŠ¨æ€æ„å»ºç›´æ–¹å›¾ï¼Œ å› ä¸ºXGBçš„ç›´æ–¹å›¾ç®—æ³•ä¸æ˜¯é’ˆå¯¹æŸä¸ªç‰¹å®šçš„featureï¼Œè€Œæ˜¯æ‰€æœ‰featureå…±äº«ä¸€ä¸ªç›´æ–¹å›¾(æ¯ä¸ªæ ·æœ¬çš„æƒé‡æ˜¯äºŒé˜¶å¯¼)ï¼Œæ‰€ä»¥æ¯ä¸€å±‚éƒ½è¦é‡æ–°æ„å»ºç›´æ–¹å›¾ã€‚</p></li>
<li><p>LGBä¸­å¯¹æ¯ä¸ªç‰¹å¾éƒ½æœ‰ä¸€ä¸ªç›´æ–¹å›¾ï¼Œæ‰€ä»¥æ„å»ºä¸€æ¬¡ç›´æ–¹å›¾å°±å¤Ÿäº†</p>
<p>LGBè¿˜å¯ä»¥ä½¿ç”¨ç›´æ–¹å›¾åšå·®åŠ é€Ÿï¼Œä¸€ä¸ªèŠ‚ç‚¹çš„ç›´æ–¹å›¾å¯ä»¥é€šè¿‡çˆ¶èŠ‚ç‚¹çš„ç›´æ–¹å›¾å‡å»å…„å¼ŸèŠ‚ç‚¹çš„ç›´æ–¹å›¾å¾—åˆ°ï¼Œä»è€ŒåŠ é€Ÿè®¡ç®—</p>
</li>
</ul>
</li>
</ul>
</li>
<li><p>æ ·æœ¬é€‰æ‹©ï¼šä¼šåšå•è¾¹æ¢¯åº¦é‡‡æ ·ï¼ŒLightGBMä¼šå°†æ›´å¤šçš„æ³¨æ„åŠ›æ”¾åœ¨è®­ç»ƒä¸è¶³çš„æ ·æœ¬ä¸Š</p></li>
<li><p>è¿˜æœ‰ä¸€äº›å°çš„åŒºåˆ«ï¼š</p>
<ul class="simple">
<li><p>ç¦»æ•£å˜é‡å¤„ç†ä¸Šï¼šXGBæ— æ³•ç›´æ¥è¾“å…¥ç±»åˆ«å‹å˜é‡å› æ­¤éœ€è¦äº‹å…ˆå¯¹ç±»åˆ«å‹å˜é‡è¿›è¡Œç¼–ç ï¼ˆä¾‹å¦‚ç‹¬çƒ­ç¼–ç ï¼‰ï¼ŒLGBå¯ä»¥ç›´æ¥å¤„ç†ç±»åˆ«å‹å˜é‡</p></li>
<li><p>è¯†åˆ«ä¸€äº›äº’æ–¥çš„ç‰¹å¾ä¸Šï¼ŒLightGBMå¯ä»¥bundlingç­‰ç­‰</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="catboost">
<h3>CatBoost<a class="headerlink" href="#catboost" title="Permalink to this headline">Â¶</a></h3>
<ul class="simple">
<li><p>Optimized for <strong>categorical</strong> features</p></li>
<li><p>Uses <code class="docutils literal notranslate"><span class="pre">target</span> <span class="pre">encoding</span></code> to handle categorical features</p></li>
<li><p>Uses ordered boosting to build â€œsymmetircâ€ trees</p>
<ul>
<li><p>ç»™æ¯ä¸ª sampleç¼–ä¸€ä¸ªtime ï¼ˆ incorporate a sense of time on the data itself, which means that these samples have occurred before and these samples have occurred later.ï¼‰</p></li>
<li><p>Every three trains on a portion of the data based on that time and then it makes a prediction on the other part.</p></li>
</ul>
</li>
<li><p>Overfitting dertector</p></li>
<li><p>Supports GPU training, sparse data &amp; missing values</p></li>
<li><p>Monotonicity constraints</p></li>
</ul>
</div>
</div>
</div>
<div class="tex2jax_ignore mathjax_ignore section" id="reference">
<h1>Reference<a class="headerlink" href="#reference" title="Permalink to this headline">Â¶</a></h1>
<p><a class="reference external" href="https://www.zhihu.com/question/21883548/answer/205191440">çŸ¥ä¹|å°±æ˜¯æ¨å®—|SVMçš„æ ¸å‡½æ•°å¦‚ä½•é€‰å–ï¼Ÿ</a></p>
<p><a class="reference external" href="https://zhuanlan.zhihu.com/p/87885678">çŸ¥ä¹|é˜¿æ³½|ã€æœºå™¨å­¦ä¹ ã€‘å†³ç­–æ ‘ï¼ˆä¸‹ï¼‰â€”â€”XGBoostã€LightGBMï¼ˆéå¸¸è¯¦ç»†ï¼‰</a></p>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./ML"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="README.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">åŸºç¡€</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="../DL/Basics/README.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">åŸºç¡€</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jace Yang<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>