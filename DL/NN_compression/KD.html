
<!DOCTYPE html>

<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>知识蒸馏 &#8212; Towards a Full-stack DA</title>
    
  <link href="../../_static/css/theme.css" rel="stylesheet">
  <link href="../../_static/css/index.ff1ffe594081f20da1ef19478df9384b.css" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      

    
    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-book-theme.css?digest=c3fdc42140077d1ad13ad2f1588a4309" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../../_static/js/index.be7d3bbb2ef33a8344ce.js">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script async="async" kind="hypothesis" src="https://hypothes.is/embed.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/sphinx-book-theme.d59cb220de22ca1c485ebbdc042f0030.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Distill Bert" href="Distill_Bert.html" />
    <link rel="prev" title="神经网络压缩" href="README.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo2.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Towards a Full-stack DA</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        <ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../intro.html">
   Jace六边形DA笔记库
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  数据ETL流程
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Data_ETL/README.html">
   DE基础
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../../Data_ETL/Data_cleaning/README.html">
   数据清洗与处理
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Data_ETL/Data_cleaning/Regex.html">
     正则表达式
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../../Data_ETL/Data_cleaning/pandas.html">
     Pandas
    </a>
   </li>
  </ul>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  统计分析
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../STAT/README.html">
   基础
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  因果推断
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Inference/README.html">
   基础
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Inference/1_AB_testing.html">
   AB Test
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Causal_Inference/2_methods.html">
   因果推理方法
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  深度学习
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../Basics/README.html">
   基础
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/>
  <label for="toctree-checkbox-2">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/DL_hyperparameter.html">
     DL常见超参及调整策略
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/Optimizer.html">
     优化器
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../Basics/Trained_by_GPU.html">
     GPU训练
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="../NLP/README.html">
   NLP
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/>
  <label for="toctree-checkbox-3">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLP/basics.html">
     基础概念
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLP/Self-attention.html">
     Self-Attention
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLP/Transformer.html">
     Transformer
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="../NLP/BERT.html">
     BERT
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1 current active has-children">
  <a class="reference internal" href="README.html">
   神经网络压缩
  </a>
  <input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/>
  <label for="toctree-checkbox-4">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul class="current">
   <li class="toctree-l2 current active has-children">
    <a class="current reference internal" href="#">
     知识蒸馏
    </a>
    <input checked="" class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/>
    <label for="toctree-checkbox-5">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="Distill_Bert.html">
       Distill Bert
      </a>
     </li>
    </ul>
   </li>
   <li class="toctree-l2 has-children">
    <a class="reference internal" href="Quantize.html">
     量化
    </a>
    <input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/>
    <label for="toctree-checkbox-6">
     <i class="fas fa-chevron-down">
     </i>
    </label>
    <ul>
     <li class="toctree-l3">
      <a class="reference internal" href="QBert.html">
       Q-BERT
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
</ul>

    </div>
</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="topbar container-xl fixed-top">
    <div class="topbar-contents row">
        <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show"></div>
        <div class="col pl-md-4 topbar-main">
            
            <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
                data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
                aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
                title="Toggle navigation" data-toggle="tooltip" data-placement="left">
                <i class="fas fa-bars"></i>
                <i class="fas fa-arrow-left"></i>
                <i class="fas fa-arrow-up"></i>
            </button>
            
            
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../../_sources/DL/NN_compression/KD.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
                onclick="printPdf(this)" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

            <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst/issues/new?title=Issue%20on%20page%20%2FDL/NN_compression/KD.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        <a class="edit-button" href="https://github.com/Jace-Yang/Full-Stack_Data-Analyst/edit/master/DL/NN_compression/KD.ipynb"><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Edit this page"><i class="fas fa-pencil-alt"></i>suggest edit</button></a>
    </div>
</div>

            <!-- Full screen (wrap in <a> to have style consistency -->

<a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
        data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
        title="Fullscreen mode"><i
            class="fas fa-expand"></i></button></a>

            <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/Jace-Yang/Full-Stack_Data-Analyst/master?urlpath=tree/DL/NN_compression/KD.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

        </div>

        <!-- Table of contents -->
        <div class="d-none d-md-block col-md-2 bd-toc show noprint">
            
            <div class="tocsection onthispage pt-5 pb-3">
                <i class="fas fa-list"></i> Contents
            </div>
            <nav id="bd-toc-nav" aria-label="Page">
                <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#differences-betwwen-transfer-learning-and-knowledge-distillation">
   Differences betwwen transfer learning and knowledge distillation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   知识蒸馏原论文
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1. 为什么用知识蒸馏
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     2. 知识蒸馏基本框架
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#logits">
       2.1 Logits方法蒸馏
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#hard-target-soft-target">
         2.2.1 Hard-target 和 Soft-target
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id5">
         2.2.2 知识蒸馏的具体方法
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id6">
         2.2.3 知识蒸馏的训练
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   其他
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

            </nav>
        </div>
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>知识蒸馏</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#differences-betwwen-transfer-learning-and-knowledge-distillation">
   Differences betwwen transfer learning and knowledge distillation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id2">
   知识蒸馏原论文
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id3">
     1. 为什么用知识蒸馏
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#id4">
     2. 知识蒸馏基本框架
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#logits">
       2.1 Logits方法蒸馏
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#hard-target-soft-target">
         2.2.1 Hard-target 和 Soft-target
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id5">
         2.2.2 知识蒸馏的具体方法
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#id6">
         2.2.3 知识蒸馏的训练
        </a>
       </li>
      </ul>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id7">
   其他
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#references">
   References
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            
              <div>
                
  <div class="tex2jax_ignore mathjax_ignore section" id="id1">
<h1>知识蒸馏<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h1>
<p>Knowledge distillation aims at leveraging the prediction power of a large teacher model into effectiverly teaching a smaller student model. And this student model is better suited for production.</p>
<div class="section" id="differences-betwwen-transfer-learning-and-knowledge-distillation">
<h2>Differences betwwen transfer learning and knowledge distillation<a class="headerlink" href="#differences-betwwen-transfer-learning-and-knowledge-distillation" title="Permalink to this headline">¶</a></h2>
<center><img src="../../images/DL_KD_1.png" width="75%"/></center>
<ul>
<li><p>Transfer Learning: copy all the weights from one model to another</p></li>
<li><p>Knowledge distiilation: student can be very different from teacher in terms of model architecture, and second point is that what student is going to intake is the output  of the teacher model only</p></li>
<li><p>Motivation：Using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets</p></li>
<li><p>Objective function：We want student to learn a soft target:</p>
  <center><img src="../../images/DL_KD_2.png" width="75%"/></center>
</li>
<li><p><span class="math notranslate nohighlight">\(s_{i}=\frac{\exp \left(z_{i} / T\right)}{\sum_{j} \exp \left(z_{j} / T\right)}\)</span>, T is the additional</p>
<ul class="simple">
<li><p>When <span class="math notranslate nohighlight">\(T \rightarrow 0\)</span>, <span class="math notranslate nohighlight">\(s_{i} \rightarrow 1\left(z_{i}=\max \left(z_{j}\right)\right)\)</span> (Low temperature, we don’t want to learn in this case)</p></li>
<li><p>When <span class="math notranslate nohighlight">\(T \rightarrow +\infty\)</span>, <span class="math notranslate nohighlight">\(s_{i} \rightarrow \frac{1}{J}\)</span></p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="id2">
<h2>知识蒸馏原论文<a class="headerlink" href="#id2" title="Permalink to this headline">¶</a></h2>
<div class="section" id="id3">
<h3>1. 为什么用知识蒸馏<a class="headerlink" href="#id3" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Training &amp; Inference have different requirements</p>
<ul>
<li><p>训练模型的时候，可以</p>
<ul>
<li><p>training must extract structure from very large, highly redundant datasets</p></li>
<li><p>使用过参数化的深度神经网络，这类网络学习能力非常强，因此往往加上一定的正则化策略(如dropout)</p></li>
<li><p>ensemble models and get averaged prediction</p></li>
</ul>
</li>
<li><p>Deploy给用户的时候需要operate in real time</p></li>
</ul>
</li>
<li><p>一般地，大模型（复杂网络）拥有良好的性能和<strong>泛化能力</strong>，他们学习到的是mapping from input vectors to output vectors</p>
<ul>
<li><p>可以the trained model assigns probabilities to all of the incorrect answers and even when these probabilities are very small, the relative probabilities of incorrect answers tell us a lot about how the cumbersome model tends to generalize.</p>
<ul>
<li><p>例子：An image of a BMW, for example, may only have a very small chance of being mistaken for a garbage truck, but that mistake is still many times more probable than mistaking it for a carrot.</p></li>
</ul>
</li>
</ul>
</li>
</ul>
<p>从头训练一个小模型, 从经验上看是很难达到上述效果的, 小模型因为网络规模较小，表达能力有限(limited capacity)。也许我们能先训练一个大而强的模型, 然后将其包含的知识转移给小的模型去指导小模型训练，使得小模型具有与大模型相当的性能与泛化能力（generalize in the same way as the large model），但是参数数量大幅降低，从而实现模型压缩与加速。</p>
<p>那么如何做到呢? Hinton等人最早在文章《Distilling the Knowledge in a Neural Network》中提出了知识蒸馏这个概念，其核心思想是先训练一个复杂网络模型，然后使用这个<strong>复杂网络的输出probabilities produced by the cumbersome model(soft-label)</strong> 和 <strong>数据的真实标签(true label)</strong> 去训练一个更小的网络。训练和部署之间存在着一定的不一致性: :</p>
</div>
<div class="section" id="id4">
<h3>2. 知识蒸馏基本框架<a class="headerlink" href="#id4" title="Permalink to this headline">¶</a></h3>
<p>知识蒸馏是对模型的能力进行迁移，根据迁移的方法不同可以简单分为<strong>目标蒸馏</strong>（也称为Soft-target蒸馏或Logits方法蒸馏）和<strong>特征蒸馏</strong>的算法两个大的方向，下面我们对其进行介绍。</p>
<div class="section" id="logits">
<h4>2.1 Logits方法蒸馏<a class="headerlink" href="#logits" title="Permalink to this headline">¶</a></h4>
<p>Hinton的神作《Distilling the Knowledge in a Neural Network》即是logits蒸馏。</p>
<p>在这篇论文中，Hinton将问题限定在<strong>分类问题</strong>下，分类问题的共同点是模型最后会有一个softmax层，其输出值对应了相应类别的概率值。在知识蒸馏时，由于我们已经有了一个泛化能力较强的Teacher模型，我们在利用Teacher模型来蒸馏训练Student模型时，可以直接让Student模型去学习Teacher模型的泛化能力。一个很直白且高效的迁移泛化能力的方法就是：使用<strong>softmax层输出的类别的概率来作为“Soft-target”</strong> 。</p>
<ul class="simple">
<li><p>如果Teacher是ensemble of simpler models的话：we can use an arithmetic or geometric mean of their individual predictive distributions as the soft targets</p></li>
</ul>
<div class="section" id="hard-target-soft-target">
<h5>2.2.1 Hard-target 和 Soft-target<a class="headerlink" href="#hard-target-soft-target" title="Permalink to this headline">¶</a></h5>
<p>传统的神经网络训练方法是定义一个损失函数，目标是使预测值尽可能接近于真实值（<strong>Hard- target</strong>），损失函数就是使神经网络的损失值和尽可能小。这种训练过程是对ground truth求极大似然。</p>
<p><img alt="img" src="https://pic1.zhimg.com/80/v2-cfcc043e7b340b32fefd7f18338fdf57_1440w.png" /></p>
<ul class="simple">
<li><p><strong>Hard-target</strong>：原始数据集标注的 one-hot 标签，除了正标签为 1，其他负标签都是 0。</p></li>
<li><p><strong>Soft-target</strong>：Teacher模型softmax层输出的类别概率，每个类别都分配了概率，正标签的概率最高。</p></li>
</ul>
<p>为什么要用soft-target指导Student模型呢？这是因为softmax层的输出，除了正例之外，<strong>负标签也带有Teacher模型归纳推理的大量信息</strong>，比如某些负标签对应的概率远远大于其他负标签，则代表 Teacher模型在推理时认为该样本与该负标签有一定的相似性。而在传统的训练过程(Hard-target)中，所有负标签都被统一对待。也就是说，知识蒸馏的训练方式使得每个样本给Student模型带来的<strong>信息量大于传统的训练方式</strong>。</p>
<p>如在MNIST数据集中做手写体数字识别任务，左边输入的“2”更加形似”3”，softmax的输出值中”3”对应的概率会比其他负标签类别高；而右边的”2”更加形似”7”，则这个样本分配给”7”对应的概率会比其他负标签类别高。这两个”2”对应的Hard-target的值是相同的，但是它们的Soft-target却是不同的，由此我们可见Soft-target蕴含着比Hard-target更多的信息。</p>
<p><img alt="img" src="https://pic2.zhimg.com/80/v2-27bb8216af7646c515dfc56db7307e9c_1440w.png" /></p>
<p>同时，使用 Soft-target 训练时，梯度的方差会更小，训练时可以使用更大的学习率，<strong>所需要的样本也更少</strong>。这也解释了为什么通过蒸馏的方法训练出的Student模型相比使用完全相同的模型结构和训练数据只使用Hard-target的训练方法得到的模型，<strong>拥有更好的泛化能力</strong>。</p>
</div>
<div class="section" id="id5">
<h5>2.2.2 知识蒸馏的具体方法<a class="headerlink" href="#id5" title="Permalink to this headline">¶</a></h5>
<p>logits就是神经网络经过softmax之前的数值。Softmax数值highlights the larger value but while doing this it loses the relativeness with other values，但这种相对的关系很重要，所以我们要对logits在高温下做softmax，即：</p>
<div class="math notranslate nohighlight">
\[q_{i}=\frac{\exp \left(z_{i} / T\right)}{\sum_{j} \exp \left(z_{j} / T\right)}\]</div>
<p>T(温度)越高，softmax输出的distribution越趋于平滑，其分布的熵越大，<strong>负标签携带的信息会被相对地放大</strong>，模型训练将更加关注负标签。温度在正常设置的时候是1</p>
<ul>
<li><p>当想从负标签中学到一些信息量的时候，温度应调高一些；</p></li>
<li><p>当想减少负标签的干扰的时候，温度应调低一些；</p>
<blockquote>
<div><p>温度的作用原文 <br>For example, one version of a 2 may be given a probability of <span class="math notranslate nohighlight">\(10^{-6}\)</span> of being a 3 and <span class="math notranslate nohighlight">\(10^{-9}\)</span> of being a 7 whereas for another version it may be the other way around. This is valuable information that defines a rich similarity structure over the data (i. e. it says which 2’s look like 3’s and which look like 7’s) but it has very little influence on the cross-entropy cost function during the transfer stage because the probabilities are so close to zero.</p>
<ul class="simple">
<li><p>之前Caruana来处理这个问题的方法是using the logits (the inputs to the final softmax)然后再minimize the squared difference between the logits produced by the cumbersome model and the logits produced by the small model. 这种方法其实distillation的一个a special case</p></li>
</ul>
</div></blockquote>
</li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">logits</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span> <span class="c1"># the Z value</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">F</span><span class="s1">&#39;Original Z=∑w·x=</span><span class="si">{</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;——&#39;</span><span class="o">*</span><span class="mi">10</span><span class="p">,</span> <span class="s1">&#39;Apply Distillation&#39;</span><span class="p">,</span> <span class="s1">&#39;——&#39;</span><span class="o">*</span><span class="mi">10</span><span class="p">)</span>
<span class="k">for</span> <span class="n">T</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="mi">100</span><span class="p">]:</span>
    <span class="n">logits_normalized</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span><span class="o">/</span><span class="n">T</span><span class="p">)</span> <span class="o">/</span> <span class="nb">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">logits</span><span class="o">/</span><span class="n">T</span><span class="p">))</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Temperature </span><span class="si">{</span><span class="n">T</span><span class="si">}</span><span class="s1"> ⇒&#39;</span><span class="p">,</span> <span class="n">logits_normalized</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Original Z=∑w·x=[2.68811714e+43 2.20264658e+04 2.71828183e+00]
———————————————————— Apply Distillation ————————————————————
Temperature 1 ⇒ [1.00000000e+00 8.19401262e-40 1.01122149e-43]
Temperature 10 ⇒ [9.99826446e-01 1.23388386e-04 5.01659740e-05]
Temperature 50 ⇒ [0.76724295 0.12682441 0.10593265]
Temperature 100 ⇒ [0.56238341 0.22864803 0.20896856]
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>可以看到温度越高，各个class的概率就越来越接近（更加smooth）</p></li>
</ul>
<p><img alt="img" src="https://pic2.zhimg.com/80/v2-74e47375fffee4771456d3970daa4b13_1440w.png" /></p>
<ul class="simple">
<li><p>总的来说，T的选择和Student模型的大小有关，Student模型参数量比较小的时候，相对比较低的温度就可以了。因为参数量小的模型不能学到所有Teacher模型的知识，所以可以<strong>适当忽略掉</strong>一些负标签的信息。</p></li>
<li><p>最后，在整个知识蒸馏过程中，我们先使用一个高的温度去学习尽可能多的信息，然后在测试阶段恢复“低温“，从而将原模型中的知识提取出来，因此将其称为是蒸馏。</p></li>
</ul>
</div>
<div class="section" id="id6">
<h5>2.2.3 知识蒸馏的训练<a class="headerlink" href="#id6" title="Permalink to this headline">¶</a></h5>
<ol class="simple">
<li><p>训练一个好的Teacher模型；</p></li>
<li><p>在Teacher的输出logits上做高温下的softmax，产生 Soft-target；</p></li>
<li><p>用{soft_target, T_high}, {hard_target, T_1}同时训练 Student模型；</p></li>
<li><p>设置温度T=1，Student模型线上做inference。</p></li>
</ol>
<p>在训练student的时候，student的loss分为两部分：</p>
<p><span class="math notranslate nohighlight">\(L=\alpha L_{\text {soft }}+\beta L_{\text {hard }}\)</span></p>
<blockquote>
<div><center><img src="../../images/DL_KD_3.png" width="75%"/></center></div></blockquote>
<ul>
<li><p><span class="math notranslate nohighlight">\(L_{soft}=-\sum_{i} p_{i}^{T} \log q_{i}^{T}\)</span>, 其中 <span class="math notranslate nohighlight">\(q_{i}^{T}=\frac{\exp (z_{i} / T)}{\sum_{j} \exp(z_{j} / T)}, \quad p_{i}^{T}=\frac{\exp (v_{i} / T)}{\sum_{j} \exp (v_{j} / T)}\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{\partial L_{s o f t}}{\partial z_{i}}=\frac{1}{T}(q_{i}^{T}-p_{i}^{T})=\frac{1}{T}(\frac{\exp (z_{i} / T)}{\sum_{j} \exp(z_{j} / T)}-\frac{\exp (v_{i} / T)}{\sum_{j} \exp (v_{j} / T)})\)</span></p>
<p>对Teacher的输出logits做高温下的softmax得到一个distribution；对student的输出logits也在同样的高温下做softmax得到一个distribution，然后计算这两个distribution的KL散度。目的是让student从teacher那里学习尽可能多的信息。</p>
</li>
<li><p><span class="math notranslate nohighlight">\(L_{\text {hard }}=-\sum_{i} y_{i} \log q_{i}^{1}\)</span>, 其中 <span class="math notranslate nohighlight">\(q_{i}^{1}=\frac{\exp (z_{i})}{\sum_{j} \exp(z_{j})}\)</span></p>
<p><span class="math notranslate nohighlight">\(\frac{\partial L_{h a r d}}{\partial z_{i}}=(q_{i}^{1}-y_{i})=\frac{\exp (z_{i})}{\sum_{j} \exp(z_{j})}-y_{i}\)</span></p>
<p>这个就是平时用的交叉熵损失——在温度为1的时候做softmax对真实的label求交叉熵损失。这是因为Teacher模型也有一定的错误率，使用真实label可以有效错误被传播给Student模型的可能性。打个比喻，老师虽然学识远远超过学生，但是他仍然有出错的可能，而这时候如果学生在老师的教授之外，可以同时参考到<strong>标准答案</strong>，就可以有效地降低被老师偶尔的错误“带偏”的可能性。</p>
</li>
</ul>
<p>alpha和beta是L_soft和L_hard的权重。实验发现，当L_hard权重较小时，能产生最好的效果，这是一个经验性的结论：</p>
<ul class="simple">
<li><p>L_soft贡献的梯度大约为L_hard的 <span class="math notranslate nohighlight">\(\frac{1}{T^{2}}\)</span> ，因此在同时使用Soft-target和Hard-target的时候，需要在L_soft的权重上乘以T^2的系数，这样才能保证Soft-target和Hard-target贡献的梯度量基本一致。</p></li>
</ul>
<p>温度对模型整体效果的影响是这样的</p>
<ul>
<li><p>低温的时候：student会不会太care logits非常负的东西，好处在于大的模型在训练的时候可能是unconstrained by the cost function used的所以会很noisy</p></li>
<li><p>高温的时候可以更多的了解negative logits中的pattern</p>
<ul>
<li><p>同时，注意当T达到一定程度的时候，loss function求出来的梯度会接近这样的一个loss function的梯度：</p>
<p>对于每一条数据直接比较logits—— 记 Net-T 产生的某个logits是 <span class="math notranslate nohighlight">\(v_{i}\)</span>, Net-S 产生的 logits 是 <span class="math notranslate nohighlight">\(z_{i}\)</span>, 最小化<span class="math notranslate nohighlight">\(\frac{1}{2}\left(z_{i}-v_{i}\right)^{2}\)</span></p>
<p>这是因为T很大的时候<span class="math notranslate nohighlight">\(\frac{1}{\sum_{j} \exp \left(z_{i}\right)} \approx \frac{T}{\sum_{j} \exp \left(z_{i} / T\right)}\)</span> 所以soft项 <span class="math notranslate nohighlight">\(z_{i}, v_{i}\)</span> 为零均值化,于是有</p>
<p><span class="math notranslate nohighlight">\(\frac{\partial \mathcal{H}_{\text {soft }}}{\partial z_{i}}=\frac{1}{T}\left(\frac{1+z_{i} / T}{N+\sum_{j}\left(z_{j} / T\right)}-\frac{1+v_{i} / T}{N+\sum_{j}\left(v_{j} / T\right)}\right)=\frac{1}{N T^{2}}\left(z_{i}-v_{i}\right)\)</span></p>
<p>也就是这个公式的损失函数。因此——直接match logits的做法是知识蒸馏的特殊情形！</p>
</li>
</ul>
</li>
<li><p>当学生模型太简单的时候，中等的温度有好处，说明把那些非常非常小logits的输出直接ignore掉会比较有用</p></li>
</ul>
</div>
</div>
</div>
</div>
<div class="section" id="id7">
<h2>其他<a class="headerlink" href="#id7" title="Permalink to this headline">¶</a></h2>
<p>另外一种知识蒸馏思路是特征蒸馏方法，如下图所示。它不像Logits方法那样，Student只学习Teacher的Logits这种<strong>结果</strong>知识，而是学习Teacher网络结构中的<strong>中间层特征</strong>。最早采用这种模式的工作来自于论文《FITNETS：Hints for Thin Deep Nets》，它强迫Student某些中间层的网络响应，要去逼近Teacher对应的中间层的网络响应。这种情况下，Teacher中间特征层的响应，就是传递给Student的知识。在此之后，出了各种新方法，但是大致思路还是这个思路，本质是Teacher将特征级知识迁移给Student。因此，接下来我们以这篇论文为主，详细介绍特征蒸馏方法的原理。</p>
<p><img alt="img" src="https://pic1.zhimg.com/80/v2-a2fa7513a86946809a2be233e4ad7808_1440w.png" /></p>
<p>一个<strong>既宽又深</strong>的模型通常需要大量的乘法运算，部署起来难度比较大；那么，一个具有比Teacher网络更多的层但每层具有较少神经元数量的Student网络称为“<strong>thin deep network</strong>”，即：更深、更窄。</p>
<p><img alt="img" src="https://pic1.zhimg.com/80/v2-19b9d0f721a69f59e7240c086a092095_1440w.png" /></p>
<p>这个student模型的训练分为两阶段：</p>
<p><strong>第一阶段</strong>：对应上图(a)(b). 首先选择待蒸馏的中间层（即Teacher的Hint layer和Student的Guided layer），如图中绿框和红框所示。由于两者的输出<strong>尺寸可能不同</strong>，因此，在Guided layer后另外接一层卷积层（图b中蓝色框），使得输出尺寸与Teacher的Hint layer<strong>匹配</strong>。接着通过知识蒸馏的方式训练Student网络的Guided layer，使得Student网络的中间层学习到Teacher的Hint layer的输出，最小化两者网络输出的<strong>MSE</strong>差异作为损失（特征蒸馏）。</p>
<p><strong>第二阶段：</strong> 对应上图(c)在训练好Guided layer之后，将当前的参数作为网络的<strong>初始参数</strong>，来进行<strong>logits蒸馏</strong>。损失函数依然是两部分的加和：soft label的KL散度、真实label的交叉熵损失（和前文描述的一样）。</p>
</div>
<div class="section" id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this headline">¶</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/1503.02531.pdf">Distilling the Knowledge in a Neural Network</a></p></li>
<li><p><a class="reference external" href="https://github.com/hannawong/MLE-interview/tree/master/3.NLP%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">https://github.com/hannawong/MLE-interview/tree/master/3.NLP语言模型</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=b3zf-JylUus">Youtube - Knowledge Distillation</a></p></li>
<li><p><a class="reference external" href="https://www.youtube.com/watch?v=k63qGsH1jLo">YouTube - Distilling the Knowledge in a Neural Network</a></p></li>
<li><p><a class="reference external" href="https://zhuanlan.zhihu.com/p/144334502">知乎 - 知识蒸馏论文阅读笔记</a></p></li>
</ul>
</div>
<div class="toctree-wrapper compound">
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./DL/NN_compression"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            
                <!-- Previous / next buttons -->
<div class='prev-next-area'> 
    <a class='left-prev' id="prev-link" href="README.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">神经网络压缩</p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Distill_Bert.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Distill Bert</p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            
        </div>
    </div>
    <footer class="footer">
  <p>
    
      By Jace Yang<br/>
    
        &copy; Copyright 2021.<br/>
  </p>
</footer>
</main>


      </div>
    </div>
  
  <script src="../../_static/js/index.be7d3bbb2ef33a8344ce.js"></script>

  </body>
</html>