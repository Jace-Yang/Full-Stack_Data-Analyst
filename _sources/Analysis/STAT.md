# 统计分析



### 参数估计

https://blog.csdn.net/liuyuemaicha/article/details/52497512

- 用样本统计量去估计总体的参数。

- 分类

  - 点估计：依据样本估计总体分布中所含的未知参数或未知参数的函数。

  - 区间估计（置信区间的估计）：依据抽取的样本，根据一定的正确度与精确度的要求，构造出适当的区间，作为总体分布的未知参数或参数的函数的真值所在范围的估计。例如人们常说的有百分之多少的把握保证某值在某个范围内，即是区间估计的最简单的应用。

- 估计方法

  - 矩估计法：

    - 矩估计法的理论依据是大数定律，主要基于用样本矩估计总体矩的思想

    - 矩的理解：在数理统计学中一类**数字特征**称为矩。

  - 极大似然估计总结
    - 似然函数直接求导一般不太好求,一般得到似然函数L(θ)之后,都是先求它的对数,即ln L(θ),因为ln函数不会改变L的单调性
    - 对ln L(θ)求θ的导数,令这个导数等于0,得到驻点.在这一点,似然函数取到最大值,所以叫最大似然估计法
    - 本质原理：似然估计是已知结果去求未知参数，对于已经发生的结果（一般是一系列的样本值）既然他会发生说明在未知参数θ的条件下，这个结果发生的可能性很大。
      - 所以最大似然估计求的就是使这个结果发生的可能性最大的那个θ，这个有点后验的意思

- 置信度、置信区间

  - 置信区间是我们所计算出的变量存在的范围，置信水平就是我们对于这个数值存在于我们计算出的这个范围的可信程度。

    - 举例来讲，有95%的把握，真正的数值在我们所计算的范围里。

    - 在这里，95%是置信水平，而计算出的范围，就是置信区间。

    - 如果置信度为95%， 则抽取100个样本来估计总体的均值，由100个样本所构造的100个区间中，约有95个区间包含总体均值。



- 两类错误：

![img](../images/(null)-20220726102205440.(null))

### 假设检验

**思路：**通过“**小概率事件在少量实验中是几乎不可能出现的**”这一结论，去证明假设是错误的，从而反证假设的另一面很可能是正确的。

**概念：** 

- 原假设，也叫零假设H0一般是一个正命题，反面则是

- 备择命题H1，如果拒绝了原假设那么就证明了备择命题是正确的

- P值，P值就是当**原假设为真**时，比所得到的样本观察结果更极端的结果出现的概率。

  如果P值很小，说明原假设情况的发生的概率很小，而如果出现了，根据小概率原理，我们就有理由拒绝原假设，P值越小，我们拒绝原假设的理由越充分

### 

**跟参数估计的区别和联系：**参数估计和假设检验是统计推断的两个组成部分，都是利用样本对总体进行某种推断，但推断的角度不同。

- 参数估计讨论的是用样本估计总体参数的方法，总体参数μ在估计前是未知的。
- 在假设检验中，则是先对μ的值提出一个假设，然后利用样本信息去检验这个假设是否成立。

常用检验形式：

- T检验
  - 场景：不知道总体标准差需要用样本的标准差来代替、适用于小样本
- Z检验
  - 场景：知道总体的标准差、适用于大样本

p值：H0成立下出现这个统计量及它更极端情况的概率

- 例：双侧检验硬币公平得到8次正面：把八次正面的概率，与更极端的九次正面、十次正面的概率，以及012的加起来，在0.5的情况下只有0.1，这个就是p值

### **协方差与相关系数的区别和联系**

- 协方差：
  - 协方差表示的是两个变量的总体的误差，这与只表示一个变量误差的方差不同。 如果两个变量的变化趋势一致，也就是说如果其中一个大于自身的期望值，另外一个也大于自身的期望值，那么两个变量之间的协方差就是正值。 如果两个变量的变化趋势相反，即其中一个大于自身的期望值，另外一个却小于自身的期望值，那么两个变量之间的协方差就是负值。

- 相关系数：
  - 研究变量之间线性相关程度的量，取值范围是[-1,1]。相关系数也可以看成协方差：一种剔除了两个变量量纲影响、标准化后的特殊协方差。

- 可参考
  - [如何通俗易懂地解释「协方差」与「相关系数」的概念？（转）_至臻思想_新浪博客blog.sina.com.cn/s/blog_6aa3b1010102xkp5.html](https://link.zhihu.com/?target=http%3A//blog.sina.com.cn/s/blog_6aa3b1010102xkp5.html)

### 中心极限定理

- 中心极限定理定义：

  - （1）任何一个样本的平均值将会约等于其所在总体的平均值。

  - （2）不管总体是什么分布，任意一个总体的样本平均值都会围绕在总体的平均值周围，并且呈正态分布。

- 中心极限定理作用：

  - （1）在没有办法得到总体全部数据的情况下，我们可以用样本来估计总体。

  - （2）根据总体的平均值和标准差，判断某个样本是否属于总体。

- 可参考[怎样理解和区分中心极限定理与大数定律？1219 赞同 · 62 评论回答](https://www.zhihu.com/question/22913867/answer/250046834)



### p值的含义。

- 基本原理只有3个： 

  - 1、一个命题只能证伪，不能证明为真

  -  2、在一次观测中，小概率事件不可能发生

  - 3、在一次观测中，如果小概率事件发生了，那就是假设命题为假

- 证明逻辑就是：我要证明命题为真->证明该命题的否命题为假->在否命题的假设下，观察到小概率事件发生了->否命题被推翻->原命题为真->搞定。

- 结合这个例子来看：证明A是合格的投手-》证明“A不是合格投手”的命题为假-》观察到一个事件（比如A连续10次投中10环），而这个事件在“A不是合格投手”的假设下，概率为p，小于0.05->小概率事件发生，否命题被推翻。

- 可以看到p越小-》这个事件越是小概率事件-》否命题越可能被推翻-》原命题越可信



### 正态分布



- 怎么向小孩子解释正态分布

  - <img src="https://api2.mubu.com/v3/document_image/182889a5-df6f-49df-b7a8-118be10cf572-2600657.jpg" alt="img" style="zoom:33%;" />

  - （随口追问了一句小孩子的智力水平，面试官说七八岁，能数数）

  - 拿出小朋友班级的成绩表，每隔2分统计一下人数（因为小学一年级大家成绩很接近），画出钟形。然后说这就是正态分布，大多数的人都集中在中间，只有少数特别好和不够好

  - 拿出隔壁班的成绩表，让小朋友自己画画看，发现也是这样的现象

  - 然后拿出班级的身高表，发现也是这个样子的

  - 大部分人之间是没有太大差别的，只有少数人特别好和不够好，这是生活里普遍看到的现象，这就是正态分布



### Non-negative matrix factorization (NMF) 

一种利用矩阵因子化将高维离散矩阵分解为两个低维矩阵，从而实现降维、分层的算法

### 各种回归的形式

|  | Functional Form | Marginal Effect | Elasticity |
| :--- | :--- | :--- | :--- |
| Linear | Y=beta_(0)+beta_(1)X | beta_(1) | beta_(1)X//Y |
| Linear-log | Y=beta_(0)+beta_(1)ln X | beta_(1)//X | beta_(1)//Y |
| Quadratic | Y=beta_(0)+beta_(1)X+beta_(2)X2 | beta_(1)+2beta_(2)X | (beta_(1)+2beta_(2)X)X//Y |
| Log-linear | ln Y=beta_(0)+beta_(1)X | beta_(1)Y | beta_(1)X |
| Double-log | ln Y=beta_(0)+beta_(1)ln X | beta_(1)Y//X | beta_(1) |
| Logistic | ln[Y//(1-Y)]=beta_(0)+beta_(1)X | beta_(1)Y(1-Y) | beta_(1)(1-Y)X |

- Elasticity
    $$
    \eta_{y, x}=\frac{\% \Delta Y}{\% \Delta X}=\frac{\Delta Y / Y}{\Delta X / X}=\frac{\Delta Y}{\Delta X} \frac{X}{Y}
    $$
    \% change in $Y$ with respect to a $\%$ change in $X$ for a small change in $X$

- Marginal effect $=\Delta Y / \Delta X$
  the change in $Y$ per unit change in $X$

  $$
    \begin{array}{r}
    \ln \left(Y_{i t}\right)=Y_{b}-1 \\
    \ln \left(Y_{i t}\right)-\ln \left(Y_{i, t-1}\right)=\ln \left(\frac{Y_{i t}}{Y_{i, L-1}}\right) \\
    \frac{Y_{k,}-1}{Y_{i t-1}} \\
    \frac{Y_{i t}-Y_{i t-1}}{Y_{i, t-1}}
    \end{array}
  $$

    $\operatorname{Ln}(X)$ : The change in $Y$ (in units)related to a $1 \%$ increase in $X$
    $\operatorname{Ln}(Y)$ : The precent change in $Y$ related to a one-unit increate in $X$



### 格兰杰因果检验

检查X是否有助于Y的增长


### 时间序列分解

- Additive decomposition: $y_{t}=S_{t}+T_{t}+R_{t}$
- Multiplicative decomposition: $y_{t}=S_{t} \times T_{t} \times R_{t}$



### Spatial Panel data analysis
- Model specification could be a mixed structure of spatial lag and spatial error model.
- Unobserved heterogeneity could be fxed effects or random effects.
- OLS is biased and inconsistent; Consistent IV or 2SLS should be used, with robust inference.
- If normality assumption of the model is maintained, efficient ML estimation could be used but with computatlonal complexity.
- Efflclent GMM estimation is recommended.

- 案例：比如微信公众号流量影响微信视频号流量有溢出效应



### 相关系数

`皮尔森相关系数 (Pearson)` : 衡量了两个连续型变量之间的线性相关程度, 要求数据连续变量的取值服从正态分布
$$
\rho_{X, Y}=\frac{\operatorname{cov}(X, Y)}{\sigma_{X} \sigma_{Y}}=\frac{E\left[\left(X-\mu_{X}\right)\left(Y-\mu_{Y}\right)\right]}{\sigma_{X} \sigma_{Y}}
$$
- 要求：

  - 两个变量之间是线性关系，都是连续数据。

  - 两个变量的总体是正态分布，或接近正态的单峰分布。

  - 两个变量的观测值是成对的，每对观测值之间相互独立。

- 实验数据通常假设是**成对的**来自于**正态分布**的总体。为啥通常会假设为正态分布呢？因为我们在求皮尔森相关性系数以后，通常还会用t检验之类的方法来进行皮尔森相关性系数检验，而 t检验是基于数据呈正态分布的假设的实验数据之间的差距不能太大，或者说皮尔森相关性系数**受异常值的影响比较大**



`斯皮尔曼相关系数（Spearman）`：衡量两个变量之间秩次（排序的位置）的相关程度, 通常用于计算离散型数据、分类变量或等级变量之间的相关性, 对数据分布没有要求
$$
\rho=\frac{\sum_{i}\left(x_{i}-\bar{x}\right)\left(y_{i}-\bar{y}\right)}{\sqrt{\sum_{i}\left(x_{i}-\bar{x}\right)^{2} \sum_{i}\left(y_{i}-\bar{y}\right)^{2}}} .
$$
- 不用计算X和Y这两个变量具体的值到底差了多少，只需要算一下它们每个值所处的**排列位置的差值**，就可以求出相关性系数了
- 同时即便在**变量值没有变化**的情况下，也不会出现像皮尔森系数那样分母为0而无法计算的情况
- 由于**异常值的秩次通常不会有明显的变化**（比如过大或者过小，那要么排第一，要么排最后），所以对斯皮尔曼相关性系数的影响也非常小



`肯德尔相关系数 (Kendall's Tau-b)` : 用于计算有序的分类变量之间的相关系数, 和斯皮尔曼相关系数相似, 在样本较小时（比如小于12）更为精确
$$
\tau=\frac{(\text { number of concordant pairs })-(\text { number of discordant pairs })}{n(n-1) / 2} .
$$
也是一种秩相关系数，不过所计算的对象是**有序分类变量**,当样本已经按其中一个特征升序排列后，对于每个样本，我们可以简单的数一下该样本后续样本中另一特征大于该样本的特征的样本数量，作为该样本引入的一致对数 (该样本之前的样本与该样本也可能一致，但是已经算过一次了)
